WEBVTT

00:00:01.600 --> 00:00:02.633
ทำไมเปิดยิ่งใหญ่จัง

00:00:05.400 --> 00:00:08.433
โอเค ก็ขออนุญาต แนะนำตัวทุกคนนิดนึงนะครับ

00:00:08.500 --> 00:00:09.733
ผมก็ ผมโร่นะครับ

00:00:09.800 --> 00:00:12.933
ผมก็มาจาก เอ่อ Botnoi Group นะครับผม

00:00:13.700 --> 00:00:16.833
ปัจจุบันทำทำในส่วนของ AI engineer นะครับ

00:00:17.200 --> 00:00:21.333
เนื่องจากเนื้อหา วันนี้นะครับ เห็นว่าทุกคน ทุกคนน่าจะสนใจในเรื่องของ

00:00:21.400 --> 00:00:25.233
vector search vector database นะครับ

00:00:25.300 --> 00:00:28.133
ก็เลยแบบ ถ้าจะเอาเรื่อง LLM แล้ว

00:00:28.400 --> 00:00:29.633
ใครๆ ก็พูดเรื่อง LLM กันละ

00:00:29.700 --> 00:00:32.633
วันนี้เรา เรา change dimension นิดนึง

00:00:33.100 --> 00:00:35.333
LLM ธรรมดา มัน มันกระจอกไป

00:00:35.400 --> 00:00:37.333
วันนี้เรามาคุยกันเรื่องของ multi-modal กัน

00:00:38.100 --> 00:00:42.633
อ่า ว่า multi-modal คือ เป็นยังไง นะครับ เออ แล้วก็เพื่อความ

00:00:42.700 --> 00:00:47.533
อ่า ไม่ ไม่เหนื่อย ไม่น้ำลายยืดกันนิดนึงนะครับ ผมก็เลย

00:00:47.600 --> 00:00:52.333
นิดนึง ว่า วันนี้เราจะ เรียนไป เล่นไป อ่า

00:00:52.400 --> 00:00:57.633
เรียนยังไงให้รู้สึกไม่เครียดนะครับ โอเค ก่อนอื่นเลย มีใครในห้องนี้

00:00:57.700 --> 00:00:59.633
รู้จัก multimodal ไหมครับ ชูขึ้นหน่อย

00:01:01.100 --> 00:01:06.933
โอ้โห เอาแล้ว ความยากเกิดขึ้นแล้ว

00:01:07.000 --> 00:01:11.333
โอเค คำถามแรกเลย multimodal คืออะไร ทุกวันนี้ผมเชื่อว่าทุกคน

00:01:12.200 --> 00:01:17.133
ใช้แล้วก็รู้จัก multimodal อยู่แล้ว แต่ว่ามันอยู่ในรูปแบบของแอปพลิเคชันครับผม

00:01:17.200 --> 00:01:20.633
multimodal จริงๆ อ่ะ มันก็คือ LLM ตัวนึงแหละ

00:01:21.300 --> 00:01:25.633
คำถาม คำถามต่อจากนั้นคือ มันคือ LLM จริงไหม

00:01:26.300 --> 00:01:30.733
คำตอบคือ ไม่รู้ ไม่รู้ บางทีก็ใช่ บางที

00:01:30.800 --> 00:01:38.333
ก็ไม่ใช่ นะครับ ทำไมผมถึงพูดอย่างงี้ นะครับ เราย้อนกลับไปดูนิดนึงว่า ก่อนที่จะมาเราจะมารู้จักกับคำว่า LLM

00:01:38.800 --> 00:01:44.133
นะครับ ก่อนหน้านี้มันมีคำคำนึงที่เป็นคำที่ยอดฮิตกันก็คือคำว่า generative AI

00:01:44.500 --> 00:01:48.133
นะครับ คือเรามี input ที่เป็น text เข้ามา นะครับผม ผ่าน generative AI

00:01:48.500 --> 00:01:51.433
แล้ว generative AI ก็ สร้าง

00:01:51.700 --> 00:01:57.032
คำตอบขึ้นมา สร้าง สังเกตมั้ยคำว่า generative AI คือการสร้างขึ้นมา การสร้างสิ่งใหม่สักอย่างนึง

00:01:57.100 --> 00:02:01.833
ขึ้นมานะครับผม เนี่ยสิ่งนี้คือเรา input เป็นด้วย text แล้วมันก็สร้างออกมาเป็น

00:02:01.900 --> 00:02:06.233
text ได้อย่างนี้เป็น text to text เนาะ ทีนี้ ทีนี้ ทีนี้ ทีนี้

00:02:07.100 --> 00:02:12.433
แบบเนี้ย มันเป็น unimodel ก็คือมี input 1 type

00:02:12.500 --> 00:02:17.733
generate ออกมาเป็น input อีก 1 type อันนี้เป็น keyword เลย ก่อนที่จะมากับคำว่า multimodal นะ

00:02:17.800 --> 00:02:21.833
ให้เรารู้จักกับคำนี้ก่อน นะครับ ทีนี้ คำถามคือ เอ้า

00:02:22.100 --> 00:02:26.632
เติมน้ำ หยิบไม่เป็นไร อะ ทีนี้คำถามว่า LLM อะ

00:02:27.300 --> 00:02:28.833
สรุป มันเป็น multimodal ไหม

00:02:29.900 --> 00:02:35.533
เราใช้ chat gpt เรา เราเคย เราเคยให้ chat gpt มัน generate รูปมั้ย

00:02:36.100 --> 00:02:39.533
เคยถูกมั้ย อะ ถือว่าเป็น unimodal มั้ย

00:02:39.800 --> 00:02:43.433
ไม่เป็นใช่มั้ย สุดท้าย LLM เป็น หรือ chat gpt เป็น

00:02:43.500 --> 00:02:47.233
เป็น multimodal หรือเป็น unimodal นะครับ

00:02:47.300 --> 00:02:52.132
คำตอบก็คือ ไม่รู้แล้วแต่ task บางทีหลังบ้านของ chatGPT มันอาจจะเป็น

00:02:52.200 --> 00:02:57.132
มันอาจจะเป็นก็ได้ หรือบางทีมันอาจจะเป็นแค่แบบ เอ๊ย เป็นโมเดลแล้วไปต่อกับ adapter

00:02:57.200 --> 00:03:02.333
หรือฟังก์ชัน เหมือนที่เมื่อกี้คุณเจมส์เขาเล่าให้ฟัง ก็จะเป็นได้นะครับผม

00:03:02.600 --> 00:03:07.233
งั้นเรามาคุยกันเรื่องของโมเดลกันก่อน เนาะ อะ เราเอาใหม่ เรามี text อยู่ตัวเดียว

00:03:07.800 --> 00:03:10.533
อยู่ เมื่อกี้เหมือนเดิมเลย นะครับ เข้า generative AI

00:03:11.200 --> 00:03:16.433
ครับ แต่รอบนี้เราไม่ได้ใส่แค่ text อย่างเดียว อ่า เป็นเวลาเรา เรา เราคุยกับ chatGPT

00:03:16.500 --> 00:03:19.733
แล้วบอกว่า เฮ้ย ช่วย อธิบายคำนี้ให้หน่อย

00:03:20.100 --> 00:03:23.533
หรือช่วยอธิบายรูป รูปภาพรูปนี้ให้หน่อย แล้วใส่รูปเข้าไป แล้วใส่ text เข้าไป

00:03:23.900 --> 00:03:27.632
แล้วให้มันอธิบายให้ฟัง นะครับ อะ คำตอบแบบนี้

00:03:27.700 --> 00:03:31.632
นะครับ คำถาม คำถามมี input ตัวที่ 1 เป็น text

00:03:31.700 --> 00:03:36.333
input ตัวที่ 2 เป็นรูปภาพ ให้มัน generate เป็น text

00:03:37.000 --> 00:03:38.733
นะครับ แบบนี้เรียกว่า multimodal ยัง

00:03:40.500 --> 00:03:44.132
ตามคอนเซ็ปต์แล้ว ถือว่าเป็นครับ เพราะว่า มันมีการ input ของ

00:03:44.400 --> 00:03:47.733
ข้อมูลมากกว่า 1 type มันอาจจะไม่ได้ generate

00:03:48.200 --> 00:03:54.632
output ที่เป็น 2 type ก็ได้ มันอาจจะ generate output แค่ 1 type แต่เราก็ถือว่ามันเป็น multimodal แล้ว

00:03:54.700 --> 00:03:58.333
เพราะว่ามัน มันสามารถแบบทำ multi data type ที่เป็น input

00:03:58.400 --> 00:04:01.433
ได้นะครับ แต่ถ้าจะให้ดี ถ้าจะตรงคอนเซ็ปต์จริง

00:04:02.200 --> 00:04:07.533
นะครับ มันมี keyword อยู่นี่อยู่ คำว่า generate variety of outcomes ก็คือมันสามารถเข้า

00:04:07.800 --> 00:04:14.333
สร้างสิ่งใหม่ๆ ออกมาได้มากกว่าแค่ text นะครับ ถ้าเป็นไปได้ multimodal ควรจะสร้าง

00:04:14.800 --> 00:04:17.933
output type ได้มากกว่าหนึ่งนะครับผม อย่างเช่นรูปภาพ

00:04:18.600 --> 00:04:25.332
ครับผม แบบนี้ก็เป็น เป็นแบบ multimodal เหมือนกัน แต่ถามว่าสุดท้ายแล้ว input image กับรูปกับ text ไป 2 ตัวนี้ แล้วสร้างเป็น

00:04:25.400 --> 00:04:30.033
เป็น text แบบนี้ถือเป็น multimodal ไหม เป็นนะครับผม อะ ทีนี้

00:04:30.100 --> 00:04:33.332
มาเข้าสู่นิยามของคำว่า multimodal จริงๆ นะครับผม

00:04:33.400 --> 00:04:36.533
อย่าเพิ่งน้ำลายไหลกัน หลังจากเห็นรูปภาพนี้ นะครับ

00:04:36.600 --> 00:04:40.433
multimodal ในอุดมคติ คือ เราจะบอกกันว่า นะครับ

00:04:40.500 --> 00:04:43.933
เรามี source ไม่ว่าจะเป็น text หรือเป็น object

00:04:44.000 --> 00:04:47.533
แต่ใดๆ ก็ตาม นะครับผม เราจะพยายามแปลง source ตัวเนี้ย

00:04:48.100 --> 00:04:51.533
ให้เป็น text นะครับผม อย่างเช่นรูปภาพ เนาะ

00:04:51.800 --> 00:04:54.233
เรามีรูปภาพ เรามี เรามีเสียง เรามีวีดีโอ

00:04:54.600 --> 00:04:57.433
เราอยากจะ change มันนะครับ แล้วทำ projector นะครับผม

00:04:57.500 --> 00:05:01.233
ให้เกิด เกิดออกมาเป็น text นะครับ ไปเข้า LLM อ่า สังเกตมั้ย

00:05:01.600 --> 00:05:04.332
เรามี LLM อยู่ตัวนึง

00:05:04.700 --> 00:05:06.733
LLM ที่เราพยายามจะเข้าใจภาษา

00:05:07.200 --> 00:05:10.533
เข้าใจภาษา ความสามารถของ LLM ที่สามารถเข้าใจเรื่องภาษาได้

00:05:10.600 --> 00:05:13.233
เราแปลง image เป็น text เพื่อให้มันเข้าใจภาษา

00:05:13.500 --> 00:05:15.633
เราแปลง audio เป็น text เพื่อให้มันเข้าใจเหมือนกัน

00:05:16.300 --> 00:05:18.133
ครับ หลังจากมันทำความเข้าใจละ

00:05:18.400 --> 00:05:21.233
ทีนี้ มันทำ encode เสร็จละ มัน ทีนี้มันต้องทำ decode

00:05:21.600 --> 00:05:23.832
อย่างเช่น เราจะ generate รูปภาพอยู่รูปนึง

00:05:24.100 --> 00:05:29.332
นึกถึง นึกถึงคนเรา เราจะ generate รูปภาพ เรา เราเข้าใจคำว่า เออ ช่วย ช่วยสร้างรูปปิกาจูให้ฉันหน่อย

00:05:29.800 --> 00:05:34.533
นะครับ มันอาจจะมีแค่ text เป็นคำเดียวเลย ทีนี้ มันจะแปลง text คำเนี้ยให้เป็นรูปภาพยังไง

00:05:34.800 --> 00:05:37.533
ถูกมั้ย เราก็ต้องเหมือนเวลาเราทำโมเดล AI สัก

00:05:37.600 --> 00:05:40.433
ตัวนึงอ่ะ เราก็ต้องมีการจับคู่กันระหว่างรูปภาพกับ text

00:05:40.700 --> 00:05:43.633
นะครับ เราเทรนด้วยการเอารูปภาพไป

00:05:43.700 --> 00:05:45.933
แล้วก็แปลงออกมาให้เป็น text

00:05:46.000 --> 00:05:48.733
ทีนี้เอาต์พุตเหมือนกันนะครับ เราต้องแปลง text ออก

00:05:48.800 --> 00:05:53.433
ไปเป็นรูปภาพอย่างงี้เป็นต้นนะครับ อันนี้เป็นเรื่องเรื่องของ multimodal ในอุดมคติ

00:05:53.500 --> 00:05:58.433
นะครับ ถามว่าในปัจจุบันเนี้ย มีโมเดลที่สามารถทำได้ขนาดนี้หรือยัง

00:05:58.500 --> 00:06:02.733
นะครับ คำตอบคือเริ่มมีแล้ว แต่ว่ายังไม่ได้เป็น

00:06:02.800 --> 00:06:05.033
ยูนิเวอร์แซลขนาดนั้นนะครับผม

00:06:05.100 --> 00:06:07.633
เพราะงั้นมันก็ยังเลยยังเป็นเรื่องของงานวิจัยกัน

00:06:07.700 --> 00:06:12.332
นะ ถ้าอย่างนั้นทอปปิกในเรื่องของ multimodal อะ มันก็เลยถูกเริ่มพูดกัน

00:06:12.400 --> 00:06:16.033
แต่ว่ายังไม่ได้ถูกเอามาใช้จริงหรือว่าทำให้แบบเราเข้าถึงกันได้

00:06:16.100 --> 00:06:18.133
นะครับผม อย่างตัวที่ใกล้เคียงที่สุด

00:06:18.200 --> 00:06:20.733
นะครับ อย่างที่เราใช้กันอยู่ทุกวันนี้อย่างเช่น ChatGPT

00:06:21.100 --> 00:06:25.933
หรือว่า Gemini หรือว่า Claude พวกนี้ก็เป็น เรียกว่าเป็น multimodal แล้ว

00:06:26.000 --> 00:06:28.933
นะครับ เพราะว่ามันเริ่มเข้าใจพวก source พวก

00:06:29.400 --> 00:06:34.233
image audio วีดีโอ อะไรพวกนี้ รวมถึงว่ามันจะสามารถแบบแปลงออกมา

00:06:34.300 --> 00:06:38.933
เป็นอะไรเป็นรูปภาพ บอกให้มันสร้างรูปภาพได้มั้ย มันบอกให้มันสร้าง audio อะไรพวกนี้

00:06:39.000 --> 00:06:41.633
ได้มั้ย คำตอบคือปัจจุบันมันเริ่มทำได้แล้ว

00:06:41.700 --> 00:06:43.633
นะครับผม อ่า เอ่อ

00:06:45.500 --> 00:06:50.433
ซึ่ง เอา วันนี้ หลักๆ เลย วันนี้ เนื่องจากว่ามันเป็นเซกชันของ

00:06:50.500 --> 00:06:54.733
มันเป็นเซกชันที่ผมมองว่า เออ 30 นาทีเอง เราจะทำยังไงกับ multimodal ตัวนี้ให้ทุกคน

00:06:54.800 --> 00:06:56.332
เข้าใจคอนเซ็ปต์ของมันก็คือ

00:06:56.400 --> 00:06:58.933
เพราะงั้นเราจะเริ่มจากคำว่า image กับ text

00:06:59.400 --> 00:07:02.033
แค่นี้พอ แค่นี้พอ เราจะอินพุต 2 อย่างเนี้ย

00:07:02.100 --> 00:07:04.533
แล้วให้มันตอบคำถามออกมาเป็น

00:07:04.600 --> 00:07:06.933
text ให้ได้ นะครับ

00:07:07.000 --> 00:07:09.633
ความยากความง่ายคืออะไร

00:07:10.300 --> 00:07:12.933
ความยากคือ เรามี LLM ตรงกลางอยู่ 1 ตัว

00:07:13.400 --> 00:07:17.433
ทีนี้ เราจะ ทำยังไงให้มัน input ทั้ง text ทั้ง image

00:07:17.900 --> 00:07:21.533
ได้ อ่า อันนี้คือความยาก อันนี้คือ challenge ของเราในวันนี้

00:07:21.600 --> 00:07:23.933
นะครับผม เมื่อกี้สังเกตจาก class ของพี่เจมส์

00:07:24.700 --> 00:07:28.533
สังเกตจาก พี่เจมส์ พี่เจมส์เค้าใช้ วิธีการ พิมพ์ด้วย ข้อความอย่างเดียว ถูกมั้ย

00:07:29.100 --> 00:07:31.633
พิมพ์ด้วยข้อความอย่างเดียว แล้วมันก็ไป search หา similarity

00:07:31.700 --> 00:07:33.533
ทีนี้ สิ่งที่มันใกล้เคียงกัน

00:07:34.000 --> 00:07:36.832
ทีนี้ เราจะรู้ได้ไงอ่ะ image

00:07:36.900 --> 00:07:41.633
กับ text มันใกล้เคียงกัน 2 อย่างเนี้ย มัน มันอยู่กันคนละโดเมนกันเลย

00:07:42.000 --> 00:07:45.033
ตัวนึงอยู่โดเมนของ text อีกตัวนึงอยู่ในโดเมนของรูปภาพ

00:07:45.100 --> 00:07:47.733
เราทำยังไงให้มันรู้เรื่องตรงนี้ได้นะครับผม

00:07:47.800 --> 00:07:49.633
ในที่ step แรกนะครับ

00:07:49.700 --> 00:07:51.433
เราจะทำยังไงให้อิมเมจเป็น text ก่อน

00:07:52.300 --> 00:07:54.233
step แรกเลย image

00:07:54.600 --> 00:07:57.332
เราจะเข้าใจ image เราคนเราเข้าใจ image ว่ายังไง

00:07:57.400 --> 00:07:59.633
นะครับผม สมมุติมีภาพมา 1 ภาพ

00:08:00.700 --> 00:08:06.633
คนเราเข้าใจ image จาก จากการที่มีคนสอนบอกว่า สิ่งสิ่งนี้คืออะไร สิ่งที่คุณเห็นอยู่คืออะไร

00:08:06.700 --> 00:08:08.533
นะครับ ตัดไปที่คอมพิวเตอร์

00:08:09.100 --> 00:08:13.133
มันมีงาน งานนึงที่เราเรียกกันก็คือ เรียกว่า image captioning

00:08:13.400 --> 00:08:17.433
คือการพยายามอธิบายภาพภาพนี้ ว่าภาพภาพเนี้ยสื่อถึงอะไร

00:08:17.900 --> 00:08:22.033
นะครับผม เราจะพยายามอธิบายมันให้ให้เป็นภาษาภาษาภาษา text เนี่ยแหละ

00:08:22.100 --> 00:08:25.332
หรือภาษา language language ทั่วๆ ไปจาก 1 ภาพตรงนี้

00:08:25.400 --> 00:08:26.033
นะครับ

00:08:26.700 --> 00:08:30.332
แปลงแบล็กบ็อกซ์ เข้าแบล็กบ็อกซ์ แบล็กบ็อกซ์สักตัวนึงก่อน เป็น AI สักตัวนึง

00:08:30.400 --> 00:08:32.732
นะครับ แล้วออกมา นะครับ เป็น

00:08:33.100 --> 00:08:34.332
เท็กซ์สักกล่องนึง

00:08:35.100 --> 00:08:37.033
นะครับ อันนี้ อันนี้เป็น

00:08:37.700 --> 00:08:40.232
มีม ปล่อยมันไป นะครับ

00:08:40.299 --> 00:08:43.433
อันนี้หลักๆ ถามว่าทำไมต้องทำ image captioning เพราะว่า

00:08:43.500 --> 00:08:46.933
จากฟังติโมเดลเมื่อกี้ เมื่อกี้เราเห็นกันเนาะ เราบอกว่าการที่

00:08:47.000 --> 00:08:51.833
จะให้ ให้ multimodal มันเข้าใจ source อื่นที่ไม่ใช่ text ได้เนี่ย

00:08:52.100 --> 00:08:55.733
มันต้องแปลงพวก other source อ่ะ เป็น text ก่อน

00:08:55.800 --> 00:08:59.433
แล้วมัน มันถึงจะแปลงเข้า เข้าสู่โมเดล เพราะงั้นกระบวนการแรกเลย

00:08:59.500 --> 00:09:02.533
แปลง source อื่นให้เป็น text แปลยังไง อย่าง image

00:09:03.000 --> 00:09:05.333
วิธีง่ายที่สุด ทำเป็น image captioning ครับผม

00:09:05.900 --> 00:09:09.733
อ่า อ่า ทีนี้ มันก็มีอีก อีกงานวิจัยนึง

00:09:09.800 --> 00:09:14.533
นะครับผม เราบอกว่า เมื่อกี้เราทำ image อย่างเดียว image อย่างเดียวมัน

00:09:14.600 --> 00:09:16.433
มันก็รู้นี่ image กับ text

00:09:16.900 --> 00:09:21.233
image แปลงเป็น text แต่ว่า ถ้าเราจะตั้งคำถามกับ text text นั้นๆ น่ะ

00:09:22.100 --> 00:09:25.133
เราจะตั้งคำถามกับ text นั้นๆ เช่น รูปรูปนี้คืออะไร

00:09:25.400 --> 00:09:28.933
นะครับ อ่า รูปนี้คืออะไร เราใส่ปิกาจูไป

00:09:29.500 --> 00:09:33.633
แล้วเราตั้งคำถามกับมัน คำถามนี้อาจจะเป็นอะไรก็ได้ เป็นคำถามอื่นก็ได้

00:09:33.700 --> 00:09:34.833
แต่คำตอบของมันต้อง

00:09:35.900 --> 00:09:39.833
ออกมา นะครับผม ออกมาอาจจะเป็น text ก็ได้ อาจจะเป็น image ก็ได้

00:09:39.900 --> 00:09:44.433
ทีนี้ ความยาก ความยาก หรือความ ความที่มันเกิดขึ้นก็คือ

00:09:44.500 --> 00:09:47.033
เราจะแมตชิ่งมันยังไง ระหว่าง text

00:09:47.300 --> 00:09:50.633
กับ image งานวิจัยเนี้ย เราเรียกกันว่า

00:09:50.700 --> 00:09:53.933
Visual Language Model คือเราใส่ทั้ง image

00:09:54.000 --> 00:09:56.833
text เข้าไป เพื่อให้ AI มันเรียนรู้ว่า

00:09:56.900 --> 00:10:01.433
สิ่งสิ่งเนี้ย ทั้ง input แล้วก็ ทั้ง input ที่เป็น image แล้วก็ input ที่เป็น

00:10:01.500 --> 00:10:03.633
text นะครับผม

00:10:03.700 --> 00:10:07.133
สองสิ่งเนี้ย มัน relate กันยังไงเนาะ มันจะแปลง image

00:10:07.500 --> 00:10:12.033
เป็นเวกเตอร์นะครับ แล้วก็แปลง text เป็นเวกเตอร์เหมือนที่เมื่อกี้คุณเจมส์บอกเนาะ

00:10:12.100 --> 00:10:15.933
แล้วมันก็จะไปเข้าฟังก์ชันหรือกระบวนการทางคณิตศาสตร์ของมันสักตัวนึง

00:10:16.400 --> 00:10:21.133
นะครับ แล้วก็ ออกมาบอกว่า โอเค สิ่งสิ่งนี้คืออะไร ก็คืออิงจากคำถาม

00:10:21.200 --> 00:10:23.833
กับรูปภาพ 2 อย่างนี้ที่มันจะ relate กัน

00:10:23.900 --> 00:10:26.933
นะครับ มันก็จะเป็นเรื่องของการเตรียมโมเดลกับการทำ

00:10:27.800 --> 00:10:32.833
การเตรียมดาต้ากับการทำโมเดลเนาะ เรื่องซึ่ง 2 เรื่องเนี้ย ระหว่างการทำ image captioning กับ VLM

00:10:32.900 --> 00:10:36.833
เนาะ 2 ตัวนี้มันก็จะทำให้มัน relate กันได้

00:10:36.900 --> 00:10:41.033
แต่ว่า ความยากอีกอย่างนึงของเราก็คือ

00:10:41.100 --> 00:10:43.233
มันฮาลูซิเนต ถ้าเราทำอย่างนี้

00:10:43.600 --> 00:10:48.633
ถ้าเราทำอย่างงี้แล้วเดต้าเราไม่ดีอ่ะ แน่นอน 1 เลยคือโมเดลมันฮาลูซิเนตแน่นอนนะครับผม คือ

00:10:48.700 --> 00:10:52.433
เรามีดาต้า image แล้วเรามีดาต้า text 2 ตัวที่มัน captioning กัน

00:10:52.800 --> 00:10:56.233
แล้วเราเอามาทำ question and answering เนาะ

00:10:56.900 --> 00:11:00.533
อ่า อันนี้เป็น leader board นะครับว่าปัจจุบันเนี้ยมีโมเดลตัวไหนที่มัน

00:11:00.600 --> 00:11:03.333
มันเก่งมากๆ เนาะ ถ้าเราสังเกตตัว ตัว

00:11:03.900 --> 00:11:04.633
อ่า

00:11:06.500 --> 00:11:06.833
ได้ไหม

00:11:08.200 --> 00:11:09.033
หรือไม่ ไม่ได้

00:11:14.000 --> 00:11:16.333
อ่ะ ขยายไม่ได้ อ่ะ ตัวบนสุดคือ GPT-4o

00:11:16.400 --> 00:11:22.533
สังเกตโมเดลที่เราบอกว่า เอ้ย เรา เราจะใช้ เราจะทำโมเดล VLM เนาะ

00:11:22.600 --> 00:11:27.733
VLM โมเดลที่ตอน ตอนนี้ที่ดีที่สุดก็คือ GPT-4o เอ๊า ไหนบอก GPT-4o เป็น

00:11:27.800 --> 00:11:29.933
เป็น multimodal ใช่ครับ

00:11:30.400 --> 00:11:31.933
multimodal  ก็คือเป็นโมเดล

00:11:33.000 --> 00:11:35.533
เนาะ VLM ก็คือเป็น เป็นงาน

00:11:35.600 --> 00:11:39.333
งาน หรือว่าเป็นโจทย์ปัญหาที่เราจะ จะใช้โมเดลสักตัวนึงเข้าไป solve

00:11:39.700 --> 00:11:44.033
นะครับ ในปัจจุบันเนี้ยพวก multimodal หลายๆ ตัวมันก็เริ่มแบบ solve ปัญหาเรื่อง

00:11:44.100 --> 00:11:48.633
เรื่องวิชัน อ่า พวก visual language modeling ได้แล้ว

00:11:48.700 --> 00:11:53.733
เนาะครับผม อย่าง อ่า ทุกวันนี้ตัว Claude มันก็สามารถใส่ทั้ง image

00:11:53.800 --> 00:11:56.133
แล้วก็ text ในการถามคำถามมัน มันได้ละ

00:11:56.400 --> 00:11:59.533
เนาะ เพราะงั้นไอ้ตัวเนี้ยมันคือเรื่องของโมเดลดิบ

00:12:00.100 --> 00:12:05.633
เนาะ อันนี้มี testing score อยู่ ถ้าเกิดว่าใครอยากจะไปเล่นนะครับ ลอง ลองสามารถเข้าไปเล่นใน vision arena ได้

00:12:06.100 --> 00:12:08.333
อ๋อ อ่า ที่นี่เป็นคำถามที่

00:12:08.400 --> 00:12:13.633
ที่ทุกคนน่าจะ น่าจะสน น่าจะสน ให้ความสนใจกันมาก มากในช่วงนี้คือ

00:12:13.700 --> 00:12:16.133
ถ้าสมมุติเรามี เรามี choice อยู่ตัวนึง

00:12:16.500 --> 00:12:20.733
คือเราจะทำ RAG หรือเราทำ fine tuned model

00:12:20.800 --> 00:12:22.033
ครับทำ RAG ทำไมไม่ทำ fine-tune ครับ

00:12:22.900 --> 00:12:25.133
แพงครับ โอ้โห คำถามนี้น่าสนใจ

00:12:25.500 --> 00:12:27.533
ใช่ RAG

00:12:28.100 --> 00:12:29.633
RAG ถูกไหม

00:12:30.300 --> 00:12:34.333
ก็ ก็ไม่ถูกมั้ย ก็ไม่ค่อยถูกเท่าไหร่เนาะ

00:12:34.400 --> 00:12:39.233
แต่จริงๆ อ่ะ คำ อย่างเราที่เป็น AI engineer 1 คน น่ะครับผม การที่เราจะเลือกว่าเรา แล้ว

00:12:39.800 --> 00:12:46.233
ระหว่างเราจะทำ RAG กับการทำ Fine-tune อ่ะ ถ้าเราสมมุติว่าเราทำ Fine-tune เราต้องมีโมเดลอยู่โมเดลนึงเนาะ ที่เมื่อกี้เรา เราไปนั่ง

00:12:46.300 --> 00:12:51.233
สรรหามา นั่งดูรีซอร์ทมาว่าโมเดลสักตัวนึงเนี่ยจะเอามา

00:12:51.300 --> 00:12:54.733
มาทำ ทำ problem แก้ปัญหาเรื่อง

00:12:54.800 --> 00:12:58.033
VQA อะไรพวกเนี้ย เอ่อ โมเดลพวกนั้นน่ะ

00:12:58.100 --> 00:13:01.833
ว่าจะทำยังไงให้มันเก่ง เก่งพอที่จะมาทำเรื่องพวกนี้

00:13:01.900 --> 00:13:05.733
เราก็ต้องมาทำไฟน์จูน เราก็ต้องไปเตรียม data set อีกเยอะแยะมากมายเลย

00:13:05.800 --> 00:13:10.233
เพราะงั้น ในโซลูชั่นที่ดีที่สุดก็คือ ณ ตอนนี้ก็คือ การทำ RAG

00:13:10.300 --> 00:13:14.633
ในสำหรับเคสที่เป็น startup แบบ ทำแบบเร็วๆ บอกว่าฉันมี

00:13:14.700 --> 00:13:18.733
vector database นะ ฉันมี document ฉันมี image นะครับ ไม่งั้นทุก

00:13:18.800 --> 00:13:22.133
วันนี้ทุกคนก็คงไม่ ทุกคนก็คงคงกระโดดไปทำ

00:13:22.200 --> 00:13:26.033
fine-tuning กัน ถ้าอยากทำ RAG ก็ง่ายมาก ก็แค่มี vector database

00:13:26.300 --> 00:13:28.833
แต่ถ้าทำ fine-tune คุณต้องมี 1 การ์ดจอ

00:13:30.400 --> 00:13:31.033
2 คุณต้องมีเงิน

00:13:31.900 --> 00:13:35.433
ต้องมีเงินเยอะมาก ถ้า ถ้าจะทำ fine-tuning model สักตัวนึง นะครับ

00:13:35.500 --> 00:13:38.333
ครับ เพราะงั้นเรากลับมาที่ RAG กันนะครับ

00:13:38.400 --> 00:13:42.533
ครับ RAG เอ่อ ผมเชื่อว่าคุณเจมส์น่าจะ น่าจะพูดเรื่อง RAG ไป

00:13:42.600 --> 00:13:47.033
พอสมควรละ จริงๆ RAG อ่ะ คอนเซ็ปต์มันก็คือว่าเรา เรามี vector database อยู่

00:13:47.100 --> 00:13:50.433
ตัวนะครับผม เรามี source อย่างเมื่อกี้

00:13:51.100 --> 00:13:55.433
เมื่อกี้ตัว source ของ ของ คุณเจมส์เนาะ อาจจะเป็นเรื่องของ document หรือว่าเป็น

00:13:55.500 --> 00:13:59.733
เป็นตัวพวกข้อมูล text อะไรพวกนี้เนาะ ส่วนผมอาจจะมองเป็น

00:14:00.100 --> 00:14:05.433
เป็น other source สักตัวนึง ก็คือว่า เราอาจจะมีเป็น document เราอาจจะมีเป็นรูปภาพ อาจจะมีเป็นวีดีโอ

00:14:05.800 --> 00:14:08.433
เราทำการ embed embed source เหล่าเนี้ย

00:14:08.800 --> 00:14:13.033
นะครับผม แล้วก็เข้าไปในเวกเตอร์ดาต้าเบส เป็นเวกเตอร์เวกเตอร์นึงที่ถูกเก็บไว้ว่า

00:14:13.100 --> 00:14:15.833
เวกเตอร์ระบุตัวนี้ ระบุว่า มันคือ source ตัวไหน

00:14:15.900 --> 00:14:19.533
มันคือ image ตัวไหน มันคือวีดีโอ channel ไหน นะครับผม

00:14:19.600 --> 00:14:23.733
แล้วเราก็มี user เนาะครับ 2 ฝั่ง user ทำการทำ

00:14:23.800 --> 00:14:27.233
query embedding นะครับผม ไปที่เวกเตอร์ ได้ออกมาเป็น

00:14:27.600 --> 00:14:30.033
เป็นข้อมูลที่เราต้องการจะ search นะครับ

00:14:30.100 --> 00:14:33.233
หลังจากนั้นก็เอาข้อมูลที่ search ไปผ่าน LLM

00:14:33.600 --> 00:14:35.933
นะครับผม เพื่อแปลง แปลงผลออกมา

00:14:36.000 --> 00:14:41.133
จะ 2 step นี้เราเรียกว่า collection กับ question and answer นะครับผม

00:14:41.200 --> 00:14:44.933
ในส่วนของ collection ก็คือการเตรียม data เราจะเตรียม database สักตัวนึงอะ

00:14:45.000 --> 00:14:49.333
อย่างเมื่อกี้ อย่างเมื่อกี้ใน ใน ในแลปเมื่อกี้ เราเห็นละว่าเอ๊ยคุณ

00:14:49.400 --> 00:14:54.733
คุณเจมส์มี database ที่ prepare พร้อมแล้ว ที่นี้ถ้าคุณอยากจะเตรียม vector database เอง เราต้องเตรียมยังไง

00:14:54.800 --> 00:14:57.333
นะครับผม ใน ใน section นี้มีการพูดถึงกัน

00:14:57.400 --> 00:15:01.833
แล้วก็หลังจากเราเตรียม collection database เสร็จละ นะครับ เราได้ vector database มา 1

00:15:01.900 --> 00:15:05.633
ที่นี้เราอยากจะทำ VQA หรือเราจะอยากจะทำ

00:15:05.700 --> 00:15:10.433
image searching image image image ใดๆ ก็ตาม นะครับผม แล้วก็ใช้ question answering

00:15:10.500 --> 00:15:13.433
มาการทำกัน เนาะ อะ เราเริ่มที่ step แรก

00:15:13.800 --> 00:15:16.433
image collection นะครับผม คอนเซ็ปต์ง่ายมาก

00:15:16.500 --> 00:15:19.633
เราก็แค่แปลงรูปภาพ นะครับผม เป็นเวกเตอร์

00:15:20.200 --> 00:15:22.733
แล้วก็ไปเข้าในเวกเตอร์ดีบี นะครับ

00:15:22.800 --> 00:15:24.633
ง่าย ง่ายนิดเดียว คำถามคือ

00:15:25.100 --> 00:15:29.733
ทำยังไง นะครับ สเต็ปแรก อะ สเต็ปแรก เอาเข้าใจง่ายๆ นะครับผม

00:15:30.000 --> 00:15:32.533
เรา มี image ใช่ไหม เมื่อกี้เราบอกแล้ว ว่า การที่เราจะทำ

00:15:32.600 --> 00:15:36.733
ทำ image หรือเราจะทำ model สักตัวนึงอะ เราต้องแปลง

00:15:37.000 --> 00:15:41.933
แปลง other source ให้เป็น text ก่อน แล้ว text อ่ะมันถึงจะไปให้ LLM

00:15:42.000 --> 00:15:46.533
ใช้ในการเรียนรู้ นะครับผม เพราะงั้นเราก็จะคงคอนเซ็ปต์นี้คือเราจะแปลง text

00:15:46.900 --> 00:15:49.933
แปลง other source อย่างเช่น image เนี่ย มาเป็น text ก่อน

00:15:50.600 --> 00:15:53.433
นะครับผม คำถามคือแปลง image เป็น text ยังไง

00:15:53.800 --> 00:15:57.233
ครับ เมื่อกี้พูดไปแล้ว นะครับ เราก็ผ่าน image captioning ไง

00:15:57.500 --> 00:15:59.233
เรามีรูปภาพ เราแปลง image

00:16:00.000 --> 00:16:01.133
นะครับผม เป็น text

00:16:02.000 --> 00:16:05.033
หลังจากเราได้เป็น text แล้ว นะครับ อะจริงๆ ง่ายเลย

00:16:05.100 --> 00:16:08.333
ง่ายเลย เราจะทำ RAG จากจาก text หรือ LLM ทำยังไง

00:16:09.200 --> 00:16:12.733
ไม่ยาก อีก text ก็ไปทำ embedding ไง ไปทำ text embedding

00:16:13.400 --> 00:16:16.733
นะครับผม ได้ออกมาเป็นเวกเตอร์ละ เวกเตอร์เราก็แค่ไป

00:16:17.000 --> 00:16:21.733
สุดท้ายเราก็ไป insert เข้า vector database นะครับผม vector database วันนี้เดี๋ยวเราโชว์กันใน

00:16:21.800 --> 00:16:23.833
ในตัวของ MongoDB เนาะ

00:16:24.200 --> 00:16:28.533
อ่ะ คำถามที่น่าสนใจมากๆ เลย ที่ผมเชื่อว่าทุกคนน่าจะตั้งคำถามกัน

00:16:28.600 --> 00:16:31.633
นะครับ ทำไมเราไม่แปลง image เป็นเป็นเวกเตอร์เลย

00:16:33.100 --> 00:16:34.833
อ่ะ อันนี้เป็นคำถามที่น่าสนใจมาก

00:16:35.500 --> 00:16:40.933
ตอบ ตอบหน่อย มีใครตอบมั้ย

00:16:41.000 --> 00:16:44.033
แจกของมั้ย เอาแจกอะไรดี

00:16:45.600 --> 00:16:49.633
แจกสมุด 1 เล่มครับ แจกสมุด 1 เล่ม อ่า ใคร ใคร ใครตอบได้ ใครตอบได้ ทำไมเราไม่แปลง

00:16:49.700 --> 00:16:51.833
แปลง image เป็น เป็นเวกเตอร์เลย

00:16:56.800 --> 00:16:57.733
เฮ้ย ทำได้

00:16:59.400 --> 00:17:02.033
ทำได้ คุณ คุณดูถูกพลัง

00:17:02.100 --> 00:17:03.633
พลังโมเดลลิ่งเกินไปละ

00:17:06.900 --> 00:17:09.733
ละน้ำลายหยดละ โอเคไม่เป็นไร โอเค อะ ฮือ

00:17:10.400 --> 00:17:10.532
ห๊ะ

00:17:12.000 --> 00:17:14.032
อะไรนะ ใช้ ส

00:17:14.099 --> 00:17:16.032
ไม่ไม่เกี่ยวไม่เกี่ยวไม่เกี่ยวไม่เกี่ยว

00:17:16.599 --> 00:17:20.433
ห๊ะ อะ โอเคเฉลย ขอบคุณขอบคุณ

00:17:20.500 --> 00:17:22.333
เป็น เอาของมั้ย

00:17:22.900 --> 00:17:27.633
อ้าว โอเค อะ เราเฉลย เราเฉลย สาเหตุว่าทำไม

00:17:27.700 --> 00:17:30.433
นะครับผม เพราะว่า การเราจะทำ RAG

00:17:30.700 --> 00:17:33.933
เราอยากจะเสิร์ช เราอยากจะเสิร์ชรูปภาพ 1 รูปภาพ

00:17:34.200 --> 00:17:38.233
นะครับผม ถ้าเราจะทำ เราทำเสิร์ชรูปภาพด้วย คำว่า

00:17:38.300 --> 00:17:41.233
เฮ้ย ฉันขอเสื้อสีแดงหน่อย

00:17:42.700 --> 00:17:45.233
ฉันขอเสื้อสีแดงหน่อย ฉันถาม ถาม

00:17:45.600 --> 00:17:48.133
ถาม RAG ไปด้วย ไปด้วย text

00:17:49.200 --> 00:17:51.033
แล้วมันจะไปเสิร์ชรูปภาพ

00:17:52.500 --> 00:17:56.133
คำถามคือ ในเวกเตอร์ดาตาเบสที่เราเก็บอยู่อ่ะตอนเนี้ย

00:17:56.500 --> 00:17:59.133
เราแปลง image เป็นเวกเตอร์ด้วย

00:17:59.700 --> 00:18:03.533
image embedding ถูกมะ

00:18:04.800 --> 00:18:07.833
มันแปลง มันแปลงหาพฤติกรรมของรูปภาพ

00:18:07.900 --> 00:18:12.233
แต่ว่ามันไม่ได้หาพฤติกรรมของ text เพราะงั้นทางที่ดีเราควรจะ

00:18:12.300 --> 00:18:15.733
ทำรูปภาพก่อนแล้วค่อยแปลงเป็น image captioning เป็น text

00:18:16.200 --> 00:18:18.133
แล้วหลังจากนั้นค่อยแปลงเป็น text เป็นเวกเตอร์

00:18:18.600 --> 00:18:20.933
แล้วถามว่า image embedding อ่ะ ทำไม

00:18:21.400 --> 00:18:24.833
มันเหมาะกับเคสไหนนะครับผม use case ที่เรามักจะใช้กัน

00:18:25.200 --> 00:18:27.633
นะครับผมไม่ได้บอกว่ามันไม่ดีแต่

00:18:27.700 --> 00:18:30.733
มันเหมาะมันไม่ได้เหมาะกับแอปพลิเคชันที่เราใช้ใน

00:18:30.800 --> 00:18:36.133
ใน multimodal RAG เนาะ use case ที่มันน่าสนใจและผมเชื่อว่าทุกคนน่าจะใช้กัน

00:18:36.200 --> 00:18:40.633
ก็คือ image similarity สมมุติคุณบอกว่าคุณมีรูปอยู่ 1 รูป

00:18:40.700 --> 00:18:44.533
คุณอยากจะ คุณอยากจะแมตชิ่งรูปนี้กับรูปที่ใกล้เคียงที่สุด

00:18:44.600 --> 00:18:48.933
เช่น คุณบอกว่า เอ๊ย คุณฉันไป ฉันเข้าไปในแอป

00:18:49.500 --> 00:18:52.133
แอป แอปหนึ่ง มีรูปภาพ product product หนึ่ง บอก

00:18:52.200 --> 00:18:54.433
มา อยากได้สินค้าประมาณเนี้ย

00:18:55.000 --> 00:18:59.233
แล้วก็ส่งรูปเข้าไป แล้วเดี๋ยวมันเสิร์ชแมตช์รูปภาพที่มันใกล้เคียงที่สุด

00:18:59.300 --> 00:19:02.333
อันนี้ได้ อันนี้เหมาะ อันนี้เหมาะมาก

00:19:02.400 --> 00:19:05.433
นะครับผม ใน image similarity หรือการทำ

00:19:05.500 --> 00:19:08.733
identify item เนาะ อันนี้

00:19:09.200 --> 00:19:12.833
การทำ image embedding เหมาะกับเคสนี้

00:19:12.900 --> 00:19:15.533
แต่ถ้าสมมุติเราจะทำ multimodal RAG

00:19:15.600 --> 00:19:18.933
use case ที่เรามักจะใช้กันก็คือเรื่องของ VQA

00:19:19.500 --> 00:19:25.133
คือเรามีรูปภาพที่อยู่ในเวกเตอร์ดาตาเบส เราบอกว่าฉันอยากจะหา identify ด้วย ด้วย text

00:19:25.700 --> 00:19:28.333
ถ้าสมมุติจะบอกว่าหา identify ด้วย text ปั๊บเนี่ย

00:19:29.300 --> 00:19:31.633
ไอ้วิธีข้างล่างอ่ะเวิร์กกว่า

00:19:32.100 --> 00:19:35.833
เห็นๆ เลยครับ โอเค ทีนี้เมื่อกี้เราตั้งคำถามไปแล้ว

00:19:36.200 --> 00:19:39.833
บอกว่า เอ๊ย เราทำคอลเล็กชันกัน เรา เรา เราจะทำ source

00:19:39.900 --> 00:19:43.133
แล้วก็เก็บในเวกเตอร์ดาตาเบสนะ อะ เวกเตอร์ดาตาเบสเราพร้อมละ

00:19:43.200 --> 00:19:46.433
ถ้า vector database เราไม่พร้อม เราไม่ควรทำ RAG

00:19:47.100 --> 00:19:50.133
อ่ะ อันนี้เป็นพอยต์หนึ่งที่อยากจะเตือนทุกคนนะครับผม

00:19:50.200 --> 00:19:53.133
กรุณาขอให้เวกเตอร์ดาตาเบสพร้อมก่อนแล้วค่อยทำ RAG นะครับ

00:19:53.700 --> 00:19:55.733
ไม่งั้นคุณจะทำ RAG โดยที่ไม่มี

00:19:56.300 --> 00:19:59.033
databaseนะครับ ก็จะ query อะไร

00:19:59.700 --> 00:20:03.833
ในความว่างเปล่า นิดนึง นะครับ อ่ะ โอเค เป็น

00:20:03.900 --> 00:20:07.833
meme joke ไป เนาะ question answering เนาะ concept ง่ายๆ

00:20:07.900 --> 00:20:14.933
คนถาม คนถาม คนถามไป คนถามเขาไป มันไป query ในเวกเตอร์ดาตาเบส ได้คำตอบออกมา

00:20:15.000 --> 00:20:18.033
generate คำตอบ ไม่มีอะไร นะครับ

00:20:18.100 --> 00:20:21.933
เรามาดูคอนเซ็ปต์กัน คอนเซ็ปต์เมื่อกี้ อาจจะขยายความเพิ่มเติมจากของพี่เจมส์ เนาะ

00:20:22.000 --> 00:20:26.333
ยึดหลักการเดียวกันกับ LLM คือ เรามี Query User Query ไป

00:20:26.400 --> 00:20:29.633
Query เป็น Text หรือถามข้อความเป็น Text ไป นะครับ

00:20:29.700 --> 00:20:33.533
ผ่าน Text Embedding นะครับ แปลง Text เป็น เป็นเวกเตอร์

00:20:33.800 --> 00:20:37.533
นะครับ เอาเวกเตอร์ไป Search เสร็จแล้วเนี่ย ทำ Similarity Search

00:20:38.000 --> 00:20:40.833
เนี่ย หาความใกล้เคียงใน vector database

00:20:40.900 --> 00:20:44.333
นะครับ ได้คำตอบออกมา ทำ Ranking เสร็จปั๊บ

00:20:44.600 --> 00:20:47.433
นะครับ ผ่าน Prompt Engineer อ่า

00:20:48.200 --> 00:20:52.433
เดี๋ยว เดี๋ยวเรามาคุย เดี๋ยวเรามา มาคุยคอนเซ็ปต์กับ Prompt Engineer ก่อนดีกว่า ว่าทำไมต้องมีสัก

00:20:52.800 --> 00:20:56.333
สังเกตมั้ย ทำไมมันต้องมีเส้นจาก Query มาสู่ Prompt Engineer

00:20:56.900 --> 00:21:01.933
นะครับผม เพราะว่ามันจะเป็นการ Ranking มันจะเป็นการ Matching กันระหว่าง

00:21:02.000 --> 00:21:04.433
คำถาม กับคำตอบ

00:21:04.800 --> 00:21:07.633
แล้วเราเอา Prompt Engineer ตรงเนี้ย ไปให้ LLM

00:21:08.200 --> 00:21:10.433
มันจะได้คำตอบที่มันดูดีที่สุด

00:21:10.900 --> 00:21:14.633
เนาะ ถามว่าทำไมต้องทำแบบนี้ ถ้าสมมุติว่าเรามีแค่คำตอบอย่างเดียว

00:21:14.700 --> 00:21:20.833
เราเข้า LLM คำถามคือเรา เราเอาคำตอบเข้า LLM เลย LLM มัน generate อะไรก็ไม่รู้ มันอาจจะ

00:21:20.900 --> 00:21:25.233
เจนเนอเรทจากพร้อมสักอย่างหนึ่งแล้วมันก็มั่ว แต่ถ้าเกิดว่าเรามีลู่ทางว่า

00:21:25.300 --> 00:21:29.933
user ถามอะไร แล้วคำตอบเป็นอะไร ช่วยสร้างคำตอบออกมาให้มัน

00:21:30.000 --> 00:21:33.933
ใกล้เคียงกับคนตอบให้ได้มากที่สุด นี่แหละจะเป็นความสามารถของ prompt engineer

00:21:34.000 --> 00:21:38.933
เนี่ย เพราะมันจะแมทชิ่งกันระหว่าง query เป็น question กับ answer ที่มันถูก query ออกมา

00:21:39.000 --> 00:21:42.333
นะครับผม แล้วก็ได้เป็นคำตอบตอบกับ user กลับไป

00:21:42.600 --> 00:21:44.133
นะครับผม อ่ะ กลับมาที่ VQA

00:21:45.300 --> 00:21:50.533
นะครับผม เมื่อกี้เราบอกว่าเราทำ เราทำ RAG โอ้ ง่ายๆ มากเลย LLM ทำ

00:21:50.600 --> 00:21:54.333
แล้ว LLM ก็แค่ถาม ถามไป แล้วมันก็แค่ตอบมา

00:21:55.000 --> 00:21:57.933
ทีนี้ถ้าเราจะทำ VQA ที่เป็น RAG จริงๆ

00:21:58.700 --> 00:22:00.733
คำถามคือทำยังไง นะครับผม

00:22:01.600 --> 00:22:03.333
คอนเซ็ปต์แบบเดิม เหมือน LLM เลย

00:22:04.100 --> 00:22:04.733
เพียงแต่

00:22:06.000 --> 00:22:09.733
user query เพิ่มขึ้นมาจากเดิมที่ที่มีแค่ text

00:22:10.100 --> 00:22:16.933
user ใส่ image ไปด้วย อ่า เหมือนที่เราทำกับ ChatGPT บ่อยๆ ไง เรา crop รูปภาพมาแล้วเราใส่

00:22:17.000 --> 00:22:20.533
ใส่คำถามไปว่า เฮ้ย รูปภาพ รูปภาพนี้คืออะไร หรือช่วย

00:22:20.600 --> 00:22:22.433
explain รูปภาพ รูปภาพนี้ให้หน่อย

00:22:22.800 --> 00:22:26.433
นะครับผม ถามว่า เอ้ย ถ้าเป็นแบบนี้แก้ปัญหายังไง

00:22:26.500 --> 00:22:27.133
โอ้ ง่ายมาก

00:22:29.500 --> 00:22:31.633
แปลง image เป็น text นะครับ

00:22:32.100 --> 00:22:34.433
ได้เป็น caption ได้เป็น caption เสร็จปุ๊บ

00:22:35.700 --> 00:22:37.033
เข้า query ตรงๆ เลย

00:22:37.500 --> 00:22:39.033
บอกว่ารูปภาพรูปนี้คืออะไร

00:22:40.100 --> 00:22:43.633
วิธีการนี้เป็นวิธีการทำ VQA ที่สิ้นคิด

00:22:43.900 --> 00:22:45.333
ที่สุดนะครับผม

00:22:45.900 --> 00:22:49.933
แต่ไม่ใช่เบสเคส อันนี้บอกไว้ก่อน ถามว่าทำได้มั้ย ทำได้

00:22:50.000 --> 00:22:53.133
ทำได้เลย คุณไม่ต้องไป optimize model อะไรเยอะ

00:22:53.700 --> 00:22:56.733
คุณสามารถทำ ทำ query ด้วย text ตรงนี้ได้เลย

00:22:57.100 --> 00:23:00.133
เพียงแต่ ถ้าเกิดว่า

00:23:00.200 --> 00:23:04.033
รูปภาพรูปนั้น รูปภาพรูปนั้น ทำ captioning มาไม่ดี

00:23:05.600 --> 00:23:08.233
RAG จะวุ่นวายทันที นะครับผม เพราะงั้น

00:23:08.900 --> 00:23:12.633
พึงระวังไว้ แล้ววิธีที่มันดีกว่าคือยังไงล่ะ

00:23:13.000 --> 00:23:16.433
นะครับ อ่ะ อันนี้เป็น อันนี้เป็น additional

00:23:16.500 --> 00:23:18.933
ถ้าใครอยากจะ อยากจะไปต่อ นะครับ

00:23:19.500 --> 00:23:23.533
อ่า ถ้าใครไม่ไปต่อ เอ่อ สามารถหยุดตรงนี้ได้เลย นะครับ

00:23:23.600 --> 00:23:27.833
โอเค อ่ะ ถ้าไปต่อ นะครับ มี มี solution ไหนบ้าง นะครับ

00:23:29.800 --> 00:23:32.733
1 เมื่อกี้เราบอกว่าเรา เรา เราใส่ทั้ง image

00:23:32.800 --> 00:23:36.133
ทั้ง text ลงไปละ เราจะต้องแมทชิ่งกับคำตอบ

00:23:36.700 --> 00:23:41.733
ครับผม เมื่อกี้เหมือนกัน เราจะทำ text embedding หรือทำ image to text embedding ยังไง

00:23:41.800 --> 00:23:46.533
นะครับผม วิธีการง่ายคือ เอ้า เราก็จะไปใช้โมเดลที่มันเหมาะกับ

00:23:46.900 --> 00:23:51.533
VQA RAG เลย นะครับ เราไป เราไปใช้ solution นั้นเลย นะครับผม

00:23:51.600 --> 00:23:55.033
ที่ VQA ตัวนั้นจะเข้าใจได้ทั้ง image แล้วก็ text

00:23:55.500 --> 00:23:59.833
นะครับผม 2 input พร้อมกัน ถ้าโมเดลตัวนั้นมันเข้าใจได้

00:23:59.900 --> 00:24:05.033
แนะนำว่าให้ไปในเวย์นั้นดีกว่า ผมจะไม่ได้ลงรายละเอียดตรงนั้นมากว่าโมเดลมัน มันทำงานยังไงเนาะ

00:24:05.100 --> 00:24:08.633
เอ่อ สามารถเข้าไปได้ที่ลิ้งค์ตรงข้างล่าง เดี๋ยวสไลด์เดี๋ยวผมมีแจกให้

00:24:08.700 --> 00:24:11.433
หรือใครอยากจะไปเสิร์ช keyword ก็ได้ นะครับผม

00:24:11.800 --> 00:24:15.733
โอเค เนาะ คอนคลูชั่นวันนี้ อยากวันนี้ อยากให้ ให้รู้ อะไร

00:24:15.800 --> 00:24:20.733
นะครับผม อยากให้ วันนี้ไม่ได้ ไม่ได้คาดหวังว่าทุกคนจะเข้าใจคำว่า multimodal  กับคำว่า

00:24:21.000 --> 00:24:25.833
multimodal with RAG เนาะ วันนี้อยากให้ทุกคนมาเข้าเข้าใจแล้วก็มาเปิด

00:24:25.900 --> 00:24:31.133
เปิดโลกว่า วันเนี้ย  multimodal  มันเข้ามาแล้วนะ ที่ทุกวันนี้ที่เราใช้กันอยู่ มัน

00:24:31.200 --> 00:24:35.133
multimodal นะ แต่ว่ายังไม่มีใครพูดถึง อย่างวันเนี้ย ผมก็ไปหา

00:24:35.200 --> 00:24:37.433
ข้อมูลมาว่า เฮ้ย มีคำว่า multimodal

00:24:37.500 --> 00:24:40.233
กับ RAG หรือยัง นะครับ

00:24:40.300 --> 00:24:42.333
คำตอบคือถ้าแทบไม่ค่อยมีคนพูดเลย

00:24:42.800 --> 00:24:47.333
นะครับ แต่คอนเซ็ปต์พอคอนเซ็ปต์มันง่ายๆ ครับผม เหมือน เหมือนกับ RAG เลย คือเราก็แค่

00:24:47.400 --> 00:24:50.333
มี multi-source

00:24:50.800 --> 00:24:55.033
นะครับผม จาก source หลายๆ ที่ image มีรูปภาพ มี text มีวิดีโอ

00:24:55.500 --> 00:24:58.933
นะครับผม เราทำการ multi modal encoding

00:24:59.300 --> 00:25:02.133
นะครับผม เราจะไม่ใช้คำว่า image encoding ละ

00:25:02.400 --> 00:25:07.033
เราจะไม่ใช้ในการทำ captioning ละ text captioning หรือ video extraction

00:25:07.300 --> 00:25:10.433
นะครับผม เราจะทำอะไรก็ได้แบ็คบล็อกตัวนึง

00:25:10.500 --> 00:25:12.933
ในการแปลง source ตัวเนี้ย ให้มาเป็น text

00:25:13.500 --> 00:25:16.333
นะครับ แล้วเราก็แปลง text มาเป็นเวกเตอร์

00:25:16.700 --> 00:25:19.033
นะครับผม เวกเตอร์เราเก็บในเวกเตอร์ดาต้าเบส

00:25:19.400 --> 00:25:22.433
แล้วก็สุดท้ายแล้วก็จะเป็นการถามแบบเดียวกัน

00:25:22.500 --> 00:25:26.033
มี query ครับ question answer นะครับผม แล้วก็ถามไป

00:25:26.100 --> 00:25:30.133
ทำ similarity search นะครับผม ได้ออกมาเป็นคำตอบแล้วก็ถามผ่าน prompt engineer

00:25:30.500 --> 00:25:33.933
LLM แล้วก็ดึงออกมาเป็นคำตอบ นั่นเอง นะครับผม

00:25:34.000 --> 00:25:37.633
อันนี้เป็น conclusion แบบ วิธีแบบ basic ที่สุด

00:25:37.700 --> 00:25:39.533
คือเราถาม

00:25:39.800 --> 00:25:43.833
แค่คำถามที่เป็น text แต่ถ้าเราอยากจะถามที่เป็น text

00:25:44.200 --> 00:25:48.233
และถามที่เป็นวีดีโอ ถามที่เป็น image ถามที่เป็น audio

00:25:48.700 --> 00:25:50.933
นะครับ เราไม่สามารถทำ

00:25:51.000 --> 00:25:55.333
query แบบนี้ได้แล้ว เราอาจจะทำ เราอาจจะทำได้เหมือนเมื่อกี้

00:25:55.400 --> 00:25:59.533
เราอาจจะทำได้เหมือนเมื่อกี้ คือเรา เราทำ multi modal encoding เป็น text

00:25:59.600 --> 00:26:03.433
แล้วเราก็เอา text อ่ะ มาอัดใน query แบบนั้นทำได้ แต่

00:26:03.800 --> 00:26:08.833
ผลลัพธ์มันอาจจะไม่ดี ในการทำ RAG นะครับผม เพราะงั้นก็ เอ่อ ถ้าใครจะทำ

00:26:08.900 --> 00:26:12.733
ก็แนะนำว่า เอ่อ ลองไปศึกษาเพิ่มเติมดูได้ครับผม

00:26:12.800 --> 00:26:14.933
เพราะงั้น เดี๋ยวเราจะเข้าสู่ workshop ของ

00:26:15.700 --> 00:26:18.833
อ่า section ของ workshop ละ ว่า วันนี้มีอะไรกันบ้าง นะครับผม

00:26:18.900 --> 00:26:23.733
หลักๆ วันนี้เราจะเข้าใจคำว่า image captioning นะครับผม แล้วก็การทำ image

00:26:24.000 --> 00:26:29.133
collection ในการเตรียม vector database ทั้งหมดแล้วก็การทำ vector search นะครับผม

00:26:29.200 --> 00:26:36.233
มา เอ่อ จาก จากฝั่งของ image นะครับ ที่เราเก็บใน vector database แล้วอ่ะ เราจะไป query ข้อมูลยังไง

00:26:36.300 --> 00:26:38.133
นะครับ โอเค

00:26:42.700 --> 00:26:45.833
โอเค จึดๆ อะ โอเค นะครับผม

00:26:45.900 --> 00:26:49.533
อ่ะ ถ้าเขา ทุกคนเข้า เข้าไปแล้ว มันจะ มันจะเข้าไปที่ GitHub เนาะ

00:26:50.000 --> 00:26:54.033
เอ่อ ถ้าผมจำไม่ผิดมันจะ มันจะลิงก์กิ้งไปที่ GitHub

00:26:55.900 --> 00:26:57.833
มีใคร มีใคร อ๋อ โอเค อะ

00:26:58.200 --> 00:27:00.833
อ่ะ ถ่ายไว้ก่อน

00:27:02.600 --> 00:27:05.733
ถ่ายไว้ก่อน วันนี้ผมอาจจะไม่รันจริงนะครับ เนื่องจากว่าการรัน

00:27:06.100 --> 00:27:09.233
ผมรันไปแล้วเมื่อเช้า มันผ่านเนาะ แต่ถ้าใครไม่ผ่านก็

00:27:10.400 --> 00:27:13.333
ก็ ทักมาในเรโปได้ เดี๋ยวเค้าไปแก้

00:27:16.200 --> 00:27:20.833
อ่า ใช้เวลา Run ทั้งหมดเนี่ย จริงๆ จริงๆ ใน ในโค้ดที่ผมเตรียมไว้

00:27:21.300 --> 00:27:25.733
ในเรโปที่ผมเตรียมไว้อ่ะ มันใช้เวลา Run ประมาณ 2 ชั่วโมง แบบ No GPU

00:27:26.000 --> 00:27:29.933
นะครับ เพราะงั้นก็ ก็ถ้าใครอยากจะ Run ก็ผม

00:27:30.000 --> 00:27:33.033
เดาว่า Section นี้น่าจะจบประมาณ ประมาณ 5 ทุ่ม เที่ยงคืน

00:27:33.100 --> 00:27:34.533
คงไม่ว่ากันเนาะ

00:27:34.600 --> 00:27:39.633
อ่า อย่าเลย อะ โอเค ก็เข้าไปก็จะเป็น

00:27:40.400 --> 00:27:45.533
อ่า สังเกตนะครับผม เพิ่งอัพเมื่อ 5 ชั่วโมงที่แล้วนะครับผม ตอน 4 โมงเย็นนะครับ แปลว่า

00:27:45.600 --> 00:27:50.233
เพราะว่าผมอัปโหลดในเวลาทำงานนะครับผม อ่า เป็นคนดีของสังคม 1 คน

00:27:50.500 --> 00:27:54.033
ครับ โอเค เข้าไปก็จะเป็นโคแล็บ มีใครไม่เคยใช้โคแล็บมั้ย

00:27:56.000 --> 00:27:59.733
เห้ย โอเค โอเค เป็น section แรกที่ไม่มีใคร

00:28:00.000 --> 00:28:04.533
ที่ทุกคนใช้โคแล็บกันได้ โอเค นะครับผม อ่ะ งั้นผม ผมจะไม่อธิบายอะไรเยอะเนาะ

00:28:04.600 --> 00:28:10.933
ก็ section มีประมาณนี้ครับผม ของๆ workshop ก็ ถ้าอยากลองไปรันเนาะ ก็ อ่า มีเรื่องของ install

00:28:11.300 --> 00:28:14.833
installation มีการ login login hugging face นะครับ

00:28:15.200 --> 00:28:17.833
ก็ เอ่อ เข้าไปล็อกอินกันได้เนาะ

00:28:17.900 --> 00:28:23.733
อ่า อันนี้ login image data set image data set เราจะใช้ เนื่องจากว่าเรามาเป็นทีมของโปเกมอนนะครับผม

00:28:23.800 --> 00:28:27.133
เราก็จะ ใช้โป pokemon blib นะครับ captioning

00:28:29.300 --> 00:28:32.633
นะครับ ถามว่าข้อมูล ข้อมูล data เป็นยังไง ข้อมูล data ประมาณนี้ครับ

00:28:34.200 --> 00:28:38.233
อ่า ข้อมูล data ก็ ก็จะมีรูปภาพอยู่ เราจะเตรียม เตรียมข้อมูลไว้ก่อน คือมีรูปภาพ 1

00:28:38.600 --> 00:28:40.733
อยู่ในรูป อยู่ แล้วก็ เราก็มี caption

00:28:41.200 --> 00:28:43.833
นะครับ caption ว่า เอ้ย text มันเป็นยังไง นะครับ

00:28:43.900 --> 00:28:48.833
สังเกตจาก caption ได้เลยว่าน่าจะใช้ LLM อ่า น่าจะใช้ model สักตัวนึง

00:28:49.100 --> 00:28:51.433
นะครับ ในการแปลง แปลง image เป็น text นะครับผม

00:28:51.500 --> 00:28:53.533
เพราะงั้นไม่ต้องคาดหวังกับผลลัพธ์ว่ามันจะดี ดี

00:28:53.600 --> 00:28:57.433
ดีมากน้อยแค่ไหน อันนี้ก็เป็นคอนเซ็ปต์ให้ ให้ดูนะ ว่าทำยัง

00:28:57.900 --> 00:29:01.033
นะครับ อ่ะ เราเริ่มกัน เริ่มกับการเตรียม data กัน

00:29:01.800 --> 00:29:05.933
นะครับ หลังจากเราได้ data มาเสร็จแล้วเนี่ย เราเอาไปทำ

00:29:06.000 --> 00:29:09.433
นะครับ เอ่อ ในเรื่องของ preparation เรื่องของตัว

00:29:09.800 --> 00:29:15.233
model image captioning เนาะ ก็ เอ่อ ผมใช้ Google vit base นะครับผม

00:29:15.500 --> 00:29:20.533
ก็ เอ่อ vit - Vision Transformer ครับผม ถ้าใครอยากไปดูก็ไปลองดูได้นะครับ

00:29:20.600 --> 00:29:24.933
Vision Transformer base patch 16 ก็ เอ่อ จะเป็นโมเดลที่

00:29:25.000 --> 00:29:28.733
เอ่อ เป็นโมเดล Vision Transformer ตัวแรกๆ ที่สามารถแบบทำ

00:29:28.800 --> 00:29:31.933
ทำพวก image captioning ได้นะครับ

00:29:32.400 --> 00:29:37.633
โอเค ก็ อ่า มีเอาต์พุตออกมา นะครับ เอ่อ เอาไปรันทำโทเคไนซ์ อันนี้ปล่อยไป

00:29:38.000 --> 00:29:42.533
ปล่อยไป อันนี้เป็น step ที่ผมเข้าใจว่าหลายๆ คนเป็น dev น่าจะไม่ ไม่ต้องอยากรู้เรื่องนี้

00:29:42.600 --> 00:29:47.433
นะครับ อันนี้เป็นเรื่องของ AI researcher หรือว่าแบบ data scientist ในการ

00:29:47.500 --> 00:29:51.533
แปลง image เป็น text นะครับผม แล้วก็เทรนโมเดล ทำ

00:29:52.000 --> 00:29:58.933
เทรนโมเดลนะครับผม สำหรับคนที่อยากจะลอง อยากจะลองกลับไปบ้านแล้วบอกว่า เอ้ย ฉันมี custom data ระหว่าง image กับ

00:29:59.000 --> 00:30:01.833
caption อยู่ ฉันอยากจะเทรน image captioning เอง

00:30:01.900 --> 00:30:05.833
นะครับ เทรนยังไง ก็ เอ่อ มี sequence to sequence train argument นะครับ

00:30:06.300 --> 00:30:09.033
ก็เทรนมา อ่าแสดง output เอ่อ ก็

00:30:09.600 --> 00:30:13.133
เอ่อ ผมหยุดเทรนไป เพราะว่าตอนนั้นผมเทรนไปได้ซักประมาณ

00:30:13.200 --> 00:30:17.833
ชั่วโมงกว่าๆ มั้ง เอ่อ นั่นแหละ แล้วก็ เอ่อ ผลลัพธ์มันไม่ได้ดีขึ้น

00:30:17.900 --> 00:30:20.333
เท่าไหร่ นะครับ ก็เป็นเรื่องที่แย่นิดนึง

00:30:20.700 --> 00:30:21.733
ก็ปล่อยไป

00:30:23.300 --> 00:30:26.233
อ่ะ โอเค แล้วก็สุดท้ายก็เซฟโมเดลนะครับผม

00:30:26.300 --> 00:30:28.433
สำหรับคนที่ไม่ต้องการ

00:30:28.500 --> 00:30:32.433
สำหรับคนที่ไม่ต้องการเทรนโมเดลเองนะครับผม เอ่อ ให้กระโดดมาใน

00:30:32.700 --> 00:30:35.233
ในหน้าของ load pipeline เลยนะครับผม

00:30:35.300 --> 00:30:40.733
ก็ ก็ กระโดดมาเลย จากเดิมทีที่เราจะต้องโหลดพรีเทรนทำโมเดลทำ

00:30:40.800 --> 00:30:43.233
ทำ data set เตรียม data set train training model นะครับ

00:30:43.600 --> 00:30:47.533
เรากระโดดมาเลย เราไปหยิบโมเดลของคนอื่นเค้ามาใช้ นะครับ แบบง่ายที่สุด

00:30:48.900 --> 00:30:53.433
เราไปโหลดโมเดลของคนอื่น ซึ่งผมก็ push โมเดลไปแล้ว ใน Pokemon captioner

00:30:53.700 --> 00:30:56.733
ครับ ได้มาเสร็จปั๊บได้เป็น pipeline อ่ะ เรา

00:30:58.300 --> 00:31:03.633
เอ่อ ทำการ นะครับผม ทำ หลัง หลังจากเราได้ pipeline เสร็จปุ๊บ อุ๊ย ผมไม่น่ากดรันเลย

00:31:04.300 --> 00:31:04.733
ยาวละ

00:31:06.700 --> 00:31:08.133
อ่า หลังจากเราได้ pipeline มาเสร็จปุ๊บ

00:31:08.200 --> 00:31:14.433
เราเอา image ที่เราต้องการนะครับผม ไปเข้า แล้วก็มันจะ generate รูปออกมา

00:31:14.500 --> 00:31:16.033
อ่า นะครับ

00:31:16.500 --> 00:31:20.233
อันนี้ก็ เรื่องของ อ่ะ ต่อจากนี้จะเป็นเรื่องของ RAG ละ ก็

00:31:20.500 --> 00:31:27.233
เอ่อ เรามีการเตรียมนะครับ เรื่องของ dataframe ไว้ อ่า หลังจากเรามี dataset รูปภาพมาเสร็จปุ๊บ เรา

00:31:27.500 --> 00:31:30.433
เรามีรูปภาพนะครับ แล้วก็มี

00:31:30.500 --> 00:31:34.333
text ที่เป็น caption ที่เราเตรียมไว้ แต่เราเราจะไม่ใช้กัน

00:31:34.400 --> 00:31:36.233
เราจะใช้ความสามารถของ

00:31:36.800 --> 00:31:40.233
ของ เอ่อ image captioning ที่เราเทรนไว้นะครับผม

00:31:40.300 --> 00:31:45.133
ถ้าเรานึกถึงสภาพจริงๆ เรา ตอนเราเทรนโมเดลกับตอนเรา เราเราจะแปลงจาก image

00:31:45.200 --> 00:31:51.533
image to to text ด้วย image captioning นะครับผม เราก็จะมี เราก็มี data lake ของเราที่เป็นแค่ image อย่างเดียว

00:31:51.600 --> 00:31:54.433
นะครับ แล้วเอา image มาทำ image captioning เนาะ

00:31:54.800 --> 00:31:57.933
แล้วก็จะได้ caption ออกมา นะครับผม ถ้าสังเกต caption ดีๆ

00:31:58.500 --> 00:32:04.033
มันใกล้เคียงกันมากเลยนะครับ เนื่องจากว่ามันน่าจะได้ข้อมูล มันน่าจะได้ข้อมูล

00:32:04.100 --> 00:32:08.333
มาแบบเดียวกัน ผมขอผมสันนิษฐานอย่างนี้นะ มันน่าจะ เอ่อ

00:32:08.400 --> 00:32:10.833
dataset นี้น่าจะถูกเตรียมมาด้วย ด้วย AI

00:32:11.700 --> 00:32:15.833
AI ตัวโมเดลใกล้ๆ กันมันก็เลย generate คำตอบมาใกล้แบบเดียวกันมากเลย เนี่ย

00:32:16.200 --> 00:32:20.433
อย่างตัวเนี้ย รูปภาพรูปเนี้ย รูปภาพแต่ละรูป text ก็คือ

00:32:21.200 --> 00:32:26.633
อ่า ข้อมูลที่เราตั้งไว้เป็น output เนาะ ส่วน caption ก็คือสิ่งที่โมเดลมันจะ generate ออกมาได้

00:32:26.700 --> 00:32:32.233
นะครับ หลังจากนั้นเราก็ออมามาคอนเวริตรูปภาพนะครับผม

00:32:32.300 --> 00:32:37.133
จากเดิมทีที่เป็นฟิว image เนาะ เป็น base64 เพื่อเราจะเก็บไว้ใน MongoDB

00:32:37.500 --> 00:32:41.933
เนาะ อ่า โอเค step ต่อไป step ต่อไปหลังจากเราทำเราทำ image captioning

00:32:42.200 --> 00:32:47.333
เราก็ได้เป็น caption ออกมาแล้วที่เป็น text นะครับ เราเอามาทำ text embedding

00:32:47.800 --> 00:32:53.833
ในการแปลงจาก แปลงจาก text นะครับผมให้ออกมาเป็นเวกเตอร์ อ่า ก็ผ่านโมเดลโมเดลนึงแหละ

00:32:54.300 --> 00:32:58.233
ผ่านโมเดลโมเดลหนึ่งไม่ต้องไปสนใจอะไรตรงนี้เยอะนะครับผม

00:32:58.800 --> 00:33:04.233
นะครับ อ่า ก็จะได้จาก caption นะครับผม จาก caption ตรงนี้ เราก็จะได้ embedding หน้าตาแบบ

00:33:04.500 --> 00:33:09.633
นะครับผม อย่างที่เมื่อกี้ครับ เมื่อกี้ของพี่เจมส์เขาบอกมาว่า เออ embedding มันหน้าตาอย่างไง

00:33:09.700 --> 00:33:13.633
image หน้าตาอย่างงี้ครับ เป็นชุดข้อมูลตัวนึงนะครับผม หลังจาก AI

00:33:14.100 --> 00:33:19.433
AI มัน learning มาเสร็จแล้ว มันพยายามทำความเข้าใจแล้วเรา เราก็จะได้แบบ base model มาตัวนึงเนาะ

00:33:19.500 --> 00:33:23.233
base model ตัวนั้นน่ะ จะบอกมาว่า เอ่อ เวกเตอร์แต่ละตัวของ

00:33:23.300 --> 00:33:25.733
ของตัว embedding อ่ะ มันหน้าตา

00:33:26.100 --> 00:33:28.333
หรือมีความสัมพันธ์ในเชิง vectorize

00:33:28.400 --> 00:33:31.233
ตัวนึงยังไงนะครับ

00:33:32.900 --> 00:33:37.933
โอเค อ่ะ หลังจากนั้น หลังจากนั้น หลังจากเราเตรียม data set เสร็จละ

00:33:38.300 --> 00:33:43.133
นะครับ เราได้ เราได้ data ทั้งหมด 2 dimension ที่น่าสนใจ

00:33:43.200 --> 00:33:45.233
2-3 dimension ที่น่าสนใจคือ

00:33:45.300 --> 00:33:52.333
เราได้ dimension ของรูปภาพ นะครับผม เราได้ dimension ของรูปภาพที่ ที่เรา input เตรียมไว้นะครับ เราได้ dimension ของ caption

00:33:52.700 --> 00:33:57.133
ที่หลังจากเราเอา image ไปผ่าน image captioning แล้ว เราได้ text

00:33:57.200 --> 00:34:01.233
text มาเพื่อที่จะเอาไปเก็บใน RAG ของ LLM นะครับ แล้วก็

00:34:01.800 --> 00:34:06.333
อ่า จาก caption ที่เป็น text เราเอาไปทำทำ text embedding เพื่อออกมาให้ได้เป็น

00:34:06.400 --> 00:34:09.433
เป็นเวกเตอร์นะครับผม อยู่ในคอลัมน์ของ embedding

00:34:10.000 --> 00:34:12.233
นะครับ โอเค

00:34:13.400 --> 00:34:19.433
แล้วก็ทีนี้เราจะมาเตรียมเข้าสู่ MongoDB ละ อ่า เดี๋ยวจะถามว่าไม่ใช่ไม่เป็น section ของ MongoDB

00:34:19.500 --> 00:34:24.233
นะครับ ก็ MongoDB นะครับผม เราจะใช้ตัว MongoDB Atlas นะครับ

00:34:24.300 --> 00:34:30.333
ผม ถ้าสำหรับใครที่ยังไม่เคยมีโปรเจกต์นะครับผม ให้ให้ไปสร้างอ่า ตัว organization

00:34:30.400 --> 00:34:33.632
นะครับผม แล้วก็โปรเจกต์แล้วก็ทำคลัสเตอร์สร้างคลัสเตอร์ออกมา

00:34:33.699 --> 00:34:36.833
ครับ อาจจะเลือก Free Tier ก่อนก็ได้นะครับผม สำหรับการทดลอง

00:34:37.300 --> 00:34:41.632
ในแลปครั้งนี้นะครับผม อ่า อย่าลืมเซ็ตเน็ตเวิร์คนะครับผม

00:34:41.699 --> 00:34:45.132
เป็น 0.0.0.0 เพื่อให้แบบ colab เข้าถึงได้นะครับ

00:34:45.500 --> 00:34:50.033
ก็ เอ่อ หลังจากเซ็ตตรงนี้เสร็จปั๊บ ไปเซ็ต Connection Config นะครับ

00:34:50.699 --> 00:34:55.033
อ่า ก็ไป connection config clustering แล้วก็ไปอัพเดทนะครับผม

00:34:55.300 --> 00:34:59.133
ทำผ่าน connection นะครับเราจะได้ URL มาตัวนึง

00:34:59.200 --> 00:35:03.133
นะครับ อย่าลืม อย่าลืมจำพาสเวิร์ดของคุณไว้

00:35:03.200 --> 00:35:06.233
นะครับ เพราะถ้าพาสเวิร์ดหายคุณต้องรีเซ็ตพาสเวิร์ดอย่างเดียว

00:35:06.700 --> 00:35:09.333
นะครับแล้วมันจะมีปัญหา กับ production ตัวอื่นๆ อย่างมากมาย

00:35:09.400 --> 00:35:11.833
นะครับ อ่า เราได้ URL แล้วเอามาแปะ

00:35:11.900 --> 00:35:15.433
แปะใน แปะใน config URL ตัวนี้ โอ้โห ไม่น่ากดเลย

00:35:16.200 --> 00:35:19.033
นะครับ แล้วก็ โอ้โหยาวละ

00:35:20.200 --> 00:35:23.833
นะครับ แล้วหลังจากนั้นก็ไป get client อ่าอันนี้ get client ไม่มีอะไร

00:35:24.600 --> 00:35:28.733
อ่าเราเตรียม data มา 3 3 คอลัมน์เนาะ อย่างที่เมื่อกี้บอกไปมี image

00:35:29.000 --> 00:35:32.933
ที่เราแปลงละจากจากเดิมทีที่เป็น image pil เนาะ

00:35:33.000 --> 00:35:35.333
image pil มันเป็น object ตัวนึงในใน

00:35:35.400 --> 00:35:39.233
ในการเก็บแคชของ image ใน Python เนาะ แต่ถ้าเราจะเอาตัว

00:35:39.900 --> 00:35:42.533
ที่ pil image อ่ะไปใส่ใน MongoDB อ่ะ

00:35:42.600 --> 00:35:48.433
มันจะใส่ไม่ได้ เราต้องแปลงมันเป็น base มาตรฐานก่อน ก็คือแปลงมันเป็น base64 แหละ วิธีง่ายที่สุดละ

00:35:48.800 --> 00:35:54.633
นะครับ แต่ทางความเป็นจริงอย่าไปทำอย่างงั้นเลย เราเอาไปเก็บใน object database ดีกว่าใช่ไหมครับ

00:35:55.300 --> 00:36:00.333
ใช่ไหมครับ อย่าทำอย่างงั้นเลย มันเป็นเรื่องที่ไม่ดีหรอก เนาะ แต่เนื่องจากว่าวันนี้เราไม่ได้ขึ้นตรงกับ

00:36:01.300 --> 00:36:04.233
cloud เจ้าไหน เพราะงั้นนะครับ เราก็แปลงเป็น base64

00:36:05.100 --> 00:36:07.733
ง่ายๆ เลย นะครับ ได้ image อ่าแปะ

00:36:08.300 --> 00:36:12.833
เป็น image64 นะครับ เรามี caption ที่เราทำการทำ

00:36:12.900 --> 00:36:17.433
ทำ image captioning แล้วก็ embedding นะครับผม ของ text text embedding นะครับ

00:36:17.800 --> 00:36:20.933
อ่า โอเค แล้วหลังจากนั้นเราก็ทำการ

00:36:21.900 --> 00:36:25.133
insert มันเข้าไป insert มันเข้าไป อะ ก็จะได้หน้าตา

00:36:25.200 --> 00:36:29.833
ข้อมูลประมาณนี้ ในเวกเตอร์ clustering นะครับ ถ้าเราไปดู

00:36:31.100 --> 00:36:35.533
ถ้าเขาไปดูใน database ก็จะหน้าตาแบบนี้

00:36:36.400 --> 00:36:37.833
จริงๆ ก็เหมือนกันแหละ ไม่ต่างกัน

00:36:40.100 --> 00:36:43.333
ไม่ต่างกัน อ่า นี่ ตึง โหลดแป๊บนึง

00:36:52.100 --> 00:36:53.233
อ่ะ โหลดนาน ปล่อยไป

00:36:54.700 --> 00:37:01.833
อ่ะ โอเค หลังจากเราเตรียมข้อมูล เรามีข้อมูล เรามีข้อมูลที่ถูกแอปเพนละอยู่ใน ในดาต้าเบสเนาะ

00:37:01.900 --> 00:37:06.433
ทีนี้ เราจะทำยังไง นะครับผม เรา จะบอกว่าตรงเนี้ย เป็นเวกเตอร์ดาต้าเบสยัง

00:37:06.800 --> 00:37:10.433
ตอบคือ เป็นแล้ว นะครับ เพราะว่ามันมีเวกเตอร์อยู่ในดาต้าเบสไง

00:37:11.000 --> 00:37:15.133
อ่า อ่า ทุกคนก็น่าจะ ทุกคนน่า น่าจะ

00:37:16.100 --> 00:37:21.033
ไม่ชอบเขา กับความรู้สึกนี้ว่า มันเป็นยังไงอ่ะ นี่ๆๆๆๆ มันเป็น มันมีตรงนี้ มันมีตรงนี้

00:37:21.100 --> 00:37:23.233
มันมี array มันมี embedding array 1,024

00:37:24.200 --> 00:37:27.633
นะครับ จำตัวเลขไว้ จำตัวเลข 1,024 ไว้ แล้วเดี๋ยวเรา เราจะตอบ

00:37:27.700 --> 00:37:30.833
เราจะมาถาม ถามกัน ว่าไอ้ 1,024 คืออะไร

00:37:31.100 --> 00:37:37.533
ครับผม อ่า นะครับ อะ โอเค หลังจากเราเตรียม database พร้อมแล้ว เราจะไปทำเข้าสู่

00:37:37.800 --> 00:37:43.633
การ search search ละ นะครับ vector search คืออะไร นะครับ vector search ก็คือ เรามี vector อยู่ตัวนึง แล้วเราอยากจะ

00:37:43.700 --> 00:37:48.733
ไป search เนาะ เราไป เราอยากจะไป search ใน ในถัง database เนาะ

00:37:48.800 --> 00:37:52.133
เพราะงั้นการที่เราจะทำ search อ่ะ เราต้องไปนั่งตั้งค่า search ก่อน

00:37:52.200 --> 00:37:57.133
ซึ่งใน mongoDB อ่ะ มี มีสิ่งที่เราเรียกกันว่า Atlas Search นะครับผม ก็คือจะเป็น

00:37:57.200 --> 00:38:03.233
เป็นการทำ vector vector searching อย่างนึง เนาะ ซึ่ง อ่า เราสามารถไปเลือกใช้ตรงนี้แล้ว

00:38:03.500 --> 00:38:07.133
นะครับ ใน Atlas Search แล้วก็ไปที่ Atlas Vector Search

00:38:07.500 --> 00:38:09.833
เลือก JSON Editor เนาะ แล้วมันก็จะมี

00:38:09.900 --> 00:38:13.733
มี ตัว JSON ที่เมื่อกี้คุณเจมส์อธิบายไป

00:38:13.800 --> 00:38:15.833
ว่า ว่า เอ้ย มัน มันสามารถ

00:38:16.500 --> 00:38:22.633
ทำ config อะไรพวกนี้ได้นะ ซึ่ง อ่า คุณจะไป select database ของคุณ ว่าคุณอยากจะทำ

00:38:23.000 --> 00:38:25.733
ทำ เอ่อ search ที่ ที่ database ตัวไหน

00:38:25.800 --> 00:38:29.433
นะครับผม แล้วก็มี indicator ในการ search แบบไหนบ้าง นะครับผม

00:38:31.700 --> 00:38:32.533
คำถาม คำถาม คำถาม คำถาม คำถาม

00:38:32.800 --> 00:38:38.533
จากใน JSON ตัวเนี้ยครับผม เราเห็น type เนาะ type เป็น vector นะครับผม  path เป็น embedding

00:38:39.200 --> 00:38:42.033
นะครับผม num dimensional

00:38:42.100 --> 00:38:46.733
เป็น 1,024 แล้วก็มี similarity นะครับผม เป็น

00:38:46.800 --> 00:38:48.833
dot product คำถาม

00:38:50.000 --> 00:38:51.033
dot product คืออะไรครับ

00:38:54.100 --> 00:38:55.733
โอ้ ขอบคุณ

00:38:58.200 --> 00:38:59.333
เคว้งคว้างมากเลย

00:39:00.900 --> 00:39:02.633
dot product คืออะไร ฮื้อ ตอบหน่อย

00:39:03.900 --> 00:39:04.833
โอ้ เคว้งคว้าง

00:39:09.100 --> 00:39:12.233
อ่ะ อ่ะ โอเค เฉลย โอ้ เศร้าใจ

00:39:12.800 --> 00:39:15.233
dot product คือ คือ เป็น similarity

00:39:15.700 --> 00:39:20.633
similarity method ตัวนึง นะครับผม ในการหาความใกล้เคียงกัน ระหว่าง vector a

00:39:21.000 --> 00:39:25.933
กับเวกเตอร์ b นะครับผม อ่ะ แบบอธิบายแบบง่ายๆ ง่ายๆ นะครับผม

00:39:26.000 --> 00:39:31.333
เพราะงั้น เอ่อ เวลาเราจะใช้ similarity ครับผม เวลาเรา เราเลือก method

00:39:31.400 --> 00:39:35.233
แต่ละ method อย่างที่เมื่อกี้ เจมส์เขาบอกเนาะ มี dot product

00:39:35.300 --> 00:39:39.233
มี dot product มี cosine แล้วก็มี

00:39:39.900 --> 00:39:43.633
Euclidean distance อ่า ใช่ๆ

00:39:43.700 --> 00:39:50.133
นะครับผม มี 3 ตัวนี้ เนาะ ซึ่งเราก็สามารถไปเลือกใช้ได้ ซึ่งแต่ละตัวมันก็จะมีวิธีการในการ

00:39:50.500 --> 00:39:54.933
ในการเสิร์ชที่ไม่เหมือนกัน คือถามว่ามันคำนวณมั้ย มันคำนวณเหมือนกัน แต่ว่า

00:39:55.000 --> 00:40:00.833
ไดเมนชั่น ที่มันจะได้ ออก ได้ออกมา ครับผม มันจะแตกต่างกัน ซึ่งแล้วแต่

00:40:00.900 --> 00:40:05.733
ยูสเคสที่จะเราจะเอาไปใช้งาน เนาะ อ่า เวกเตอร์เสิร์ชชิ่ง ก็ อ่า

00:40:05.800 --> 00:40:08.533
ไม่มีอะไร โค้ดอันนี้ก็ใช้แบบเดียวกัน นะครับ

00:40:08.600 --> 00:40:13.533
เราจะทำลิมิต นะครับผม ลิมิตไว้ 4 แล้วก็ อ่า เซตแคนดิเดตไว้สัก 150

00:40:14.700 --> 00:40:18.233
นะครับผม เราเซตไว้เลยว่า อ่า เราจะไป เราจะไป

00:40:18.600 --> 00:40:20.933
เราจะไปวิ่งไปดูที่ เอ่อ

00:40:21.200 --> 00:40:26.033
เราจะวิ่งไปดูที่ฟิวล์ไหน นะครับ ว่า อ่า ฟิวล์ไหนคือ embedding ที่เราเก็บไว้อยู่ หรือ

00:40:26.100 --> 00:40:31.233
vector ที่เราเก็บไว้อยู่ นะครับผม หลังจากนั้นเราจะ เราจะเอาอะไรออกมา นะครับผม

00:40:31.300 --> 00:40:33.933
สกอริ่งนะครับผม หลังจากเรา เราเช็ก

00:40:34.300 --> 00:40:40.033
มีการ searching ไปแล้วเราทำ scoring แล้วก็ sorting มันออกมาว่าเราจะเอาตัวไหน

00:40:40.100 --> 00:40:43.833
บ้างนะครับผม อ่า คอลัมน์ที่เราจะออกมา อ่า

00:40:43.900 --> 00:40:45.533
ถ้าสมมุติว่า

00:40:46.500 --> 00:40:50.733
วาลูเป็น 0 นะครับผม คีย์ของไอดีเป็น 0 ก็คือเราจะไม่เอาตัวนั้นออกมา แต่ถ้าสมมุติ

00:40:51.100 --> 00:40:55.433
value เป็น 1 ก็คือเราจะเอาคอลัมน์นั้นออกมาเนาะ image64 โอ้ เราก็จะเอา

00:40:55.500 --> 00:41:01.233
image ออกมาว่า สิ่งที่เราเสิร์ชไปอะ image 64 หรือตัวรูปภาพรูปนั้นคืออะไร แล้วก็ caption

00:41:01.700 --> 00:41:07.433
ว่าเป็น caption อะไร นะครับผม เช่น เราตั้งคำถามมา query I want to see your your pikachu

00:41:08.100 --> 00:41:11.133
โอเค แล้วก็ทำ picture search มา นะครับ

00:41:11.200 --> 00:41:14.933
ก็จะได้ผลลัพธ์ออกมา 34 ตัว อย่างงี้ นะครับผม

00:41:15.000 --> 00:41:18.433
อ่า มี มี caption ที่ โอเค มี caption ที่โอเค

00:41:18.500 --> 00:41:22.233
a very cute looking for Pokemon picture with big eyes

00:41:22.300 --> 00:41:25.933
ครับผม อ่า ตัวที่ 2 เหมือนกัน อ่า โปเกมอน อ่า อือ อือ

00:41:26.000 --> 00:41:29.133
yellow-black pokemon pikachu with pink eyes นะครับ

00:41:29.200 --> 00:41:31.433
ทีนี้เรามาดู response ผลลัพธ์

00:41:32.500 --> 00:41:35.033
หลังจากเราดู response แล้วเราค่อนข้างจะผิดหวังนิดนึง

00:41:36.000 --> 00:41:37.733
ตัวไหนเป็นพิคาชู พิคาชูบ้างครับ

00:41:38.800 --> 00:41:44.433
มีแค่ตัวขวาสุดเนาะ แล้วถามว่าทำไม ทำไม 3 ตัวที่เหลือมันไม่เป็นพิคาชูอ่ะ

00:41:44.900 --> 00:41:46.933
แต่แต่ caption มันดูเป็นพิคาชูมากเลยนะ

00:41:47.800 --> 00:41:53.633
เนี่ย เนี่ย เนี่ย เนี่ย เนี่ย caption บอกว่า อ้อ a very cute looking Pokemon Pikachu with big eyes

00:41:53.700 --> 00:41:54.933
big eyes with

00:41:56.700 --> 00:42:02.133
ทั้ง 2 ตัวเหมือนกันเลย นะครับผม หมายความว่าไง หมายความว่า data ที่เราทำ image generation มันออกมาไม่ได้ ไม่ดี

00:42:02.200 --> 00:42:06.233
เวลาเรา searching ออกมา เรา searching image ออกมา มัน มันก็เลยได้ไม่ดีเหมือนกัน

00:42:06.300 --> 00:42:09.233
เพราะงั้นการที่เราจะทำ image captioning ให้

00:42:09.500 --> 00:42:14.333
ให้ เอ่อ การที่เราจะทำ ทำตัว multimodal RAG นะครับผม ให้มันดีอะ

00:42:14.400 --> 00:42:20.133
อ่า การแปลงจาก image ออกมาเป็น text อ่ะ มันควรจะดีด้วยเหมือนกัน ก็คือหมายความว่า ณ ตอนเนี้ย

00:42:20.200 --> 00:42:25.433
เราทำ image captioning ได้ไม่ดีพอ เพราะงั้นเราจะแก้ปัญหานี้ยังไง

00:42:25.500 --> 00:42:30.433
เราต้องย้อนกลับไป back กลับไป back กลับไปแล้วแก้ไรได้บ้างนะครับ เราแก้

00:42:30.500 --> 00:42:35.133
เราแก้ dataset ได้มั้ย เราแก้ dataset ไม่ได้ เราแก้ เราแก้ตัว image

00:42:35.200 --> 00:42:40.633
captioning ได้มั้ย นะครับผม เนี่ยเราแก้ back prop กลับไปว่า เออ เราจะทำตัวไหนให้มันได้ดีที่สุดอะ

00:42:41.000 --> 00:42:44.333
เราก็จะได้ผลลัพธ์ออกมาที่ดี แต่อย่างน้อย อย่างน้อยที่สุดวันนี้

00:42:44.400 --> 00:42:48.133
นะครับผม มันสามารถเอารูปภาพออกมาได้แล้ว

00:42:48.200 --> 00:42:52.733
นะครับ มันสามารถเสิร์ชออกมาได้แล้วจากแค่คำว่า text จากคำว่า I want to see your Pikachu

00:42:52.800 --> 00:42:57.233
แล้วมันก็เสิร์ชออกมาได้แล้วแต่สิ่งที่มันใกล้เคียงที่สุดนะครับ ผลลัพธ์สุดท้าย

00:42:57.300 --> 00:43:01.133
เราสามารถเอา image กับ เราสามารถเอา text

00:43:01.400 --> 00:43:05.033
สองตัวเนี้ย ไปผ่าน LLM เพื่อ generate คำตอบออกมาได้

00:43:05.400 --> 00:43:10.433
ต่อเนื่องไปเรื่อยๆ นะครับผม ส่วนในพาร์ทของ generate ผมจะไม่แสดงให้ดูเนาะ เพราะผมเชื่อว่า

00:43:10.500 --> 00:43:11.633
ทุกคนน่าจะเขียนพร้อม

00:43:12.600 --> 00:43:20.533
ได้กันอยู่แล้วเนาะ เพราะงั้นผลลัพธ์สุดท้ายตรงนี้ก็ขอฝากไปแล้วถ้าเกิดว่าใครมีคำถามอะไรหรือใครสนใจอะไรนะครับผม

00:43:20.600 --> 00:43:23.533
ก็อ่าเข้ามาคุยกันได้นะ

00:43:23.600 --> 00:43:27.433
ครับผมก็สำหรับวันนี้พิคาชูก็ขอบคุณทุกคนนะครับ

00:43:27.500 --> 00:43:28.233
ピカ ピカ

00:43:28.300 --> 00:43:32.533
ピカ

00:43:32.600 --> 00:43:36.933
กาวสมใจยัง? / ขอบคุณมากครับ ผมตอนแรกไม่คิดว่าจะมาเป็น

00:43:37.000 --> 00:43:40.033
ピカチュウ จริงๆ นะฮะ กำลังเซฟอยู่ ทำไมไม่แต่งเต็ม

00:43:40.100 --> 00:43:40.833
ทั้งตัวเลย

00:43:42.600 --> 00:43:45.433
อ๋อมีแล้วมีแล้วโอเค นะครับผม ก็เดี๋ยว

00:43:45.700 --> 00:43:48.633
ก่อนที่เดี๋ยวเราจะมาถ่ายรูปรวมกันนะครับผม

00:43:48.700 --> 00:43:52.433
พอดีของที่ระลึกนะฮะ ยังมีอีกเพียบเลยนะครับผม

00:43:52.500 --> 00:43:56.633
ก็เดี๋ยวเราจะมาเล่นเกมคาฮูทกันสั้นๆ ประมาณ 15 ข้อแบบไวๆ พี่ฟี่

00:43:57.000 --> 00:43:57.533
ครับผม

00:43:58.800 --> 00:44:02.633
สำหรับคนที่ได้อันดับ 1 2 3 4 5 นะครับผม

00:44:05.800 --> 00:44:07.833
ก็สามารถเลือกของที่ระลึกได้คนละ

00:44:08.400 --> 00:44:11.033
คนละ 3 ชิ้นละกันนะฮะ คนละ 3 ชิ้นไปเลยนะครับผม

00:44:12.100 --> 00:44:14.333
เออ สปีคเกอร์เล่นไม่ได้นะ สปีคเกอร์เล่นไม่ได้
