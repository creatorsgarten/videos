WEBVTT - Auto-generated by autosubserv

00:00:00.944 --> 00:00:07.372
คนที่จะมาเล่าเรื่อง Lightning Talk

00:00:07.500 --> 00:00:12.740
อยากให้มาลองนั่งตรงนี้เตรียมตัวไว้ก่อนเลยก็ได้ครับ

00:00:12.780 --> 00:00:24.612
เดี๋ยวต่อจากผมไปเลย ขอบคุณมากครับ

00:00:24.652 --> 00:00:27.372
สวัสดีครับ ผมเวหานะครับ

00:00:27.372 --> 00:00:30.732
มาช่วยจัดงาน Code Meetup ครั้งนี้

00:00:30.732 --> 00:00:33.273
แล้วก็อยากจะมาเล่าให้ฟังว่า

00:00:33.964 --> 00:00:40.927
เราจะตามข้อมูลเรื่อง AI ให้ทันได้ยังไง

00:00:40.972 --> 00:00:41.881
เพราะช่วงนี้ผมเป็น software engineer

00:00:41.888 --> 00:00:43.692
แล้วก็มีไปสอนที่ต่างๆ แล้วทุกคนก็ถามว่า

00:00:43.692 --> 00:00:45.292
เราจะตามข่าวได้ยังไง มีโมเดลใหม่มาทุกสัปดาห์

00:00:45.319 --> 00:00:46.378
วันนี้ก็ Gemini 1.5 Flash เพิ่งออกมา

00:00:47.372 --> 00:00:54.716
ผมคิดว่าวิธีการที่ทำให้เราตามข่าวพวกนี้ได้ สำหรับผมก็คือ

00:00:55.116 --> 00:00:57.759
เราต้องเข้าใจเทรนด์สำคัญอย่างหนึ่งก่อน

00:00:57.767 --> 00:01:00.516
นั่นก็คือเรื่อง scaling law แล้วเราต้องมี tool

00:01:00.556 --> 00:01:04.289
ในการเช็คว่างานของเราควรจะตามเรื่องไหนบ้าง

00:01:04.476 --> 00:01:05.996
ซึ่งเดี๋ยวผมอยากจะมาเล่าให้ฟังวันนี้ครับ

00:01:08.876 --> 00:01:13.872
ก่อนอื่นเลยเดี๋ยวเราจะพูดเรื่อง scaling law

00:01:13.932 --> 00:01:19.772
แต่ก่อนถึง scaling law มีเรื่องคล้ายๆ กันมาเล่าให้ฟัง

00:01:19.852 --> 00:01:24.172
ในรูปเนี่ยเป็นผมถ่ายรูปมาเมื่อหลายปีแล้ว

00:01:24.172 --> 00:01:32.012
อันนี้เป็น Washington Monument นะ

00:01:32.012 --> 00:01:32.492
เป็นเสาใหญ่ๆ อยู่ข้างกับ White House ทำเนียบขาว

00:01:32.492 --> 00:01:36.812
ข้างบนสุดเนี่ยเป็นก้อนคล้ายๆ พีระมิดก้อนหนึ่ง

00:01:36.812 --> 00:01:37.212
ที่ทำมาจากโลหะชนิดหนึ่ง ที่ตอนนั้นราคาแพงกว่าทองอีก

00:01:38.124 --> 00:01:44.484
แล้วก็ผ่านจนถึงปี 2024 เนี่ย ราคาลดลงไป 564 เท่า

00:01:45.484 --> 00:01:53.377
564 เท่านี่ขนาดไหน สมมติเราซื้อของชิ้นนี้มา

00:01:53.964 --> 00:01:55.084
ในราคา 10,000 บาท เมื่อตอนที่มันสร้าง

00:01:55.964 --> 00:01:58.444
ตอนนี้ราคาเหลือ 2 บาท เมื่อปริมาณเท่ากัน

00:01:58.512 --> 00:01:59.564
มีใครอยากทายไหมครับว่า โลหะชิ้นนี้คืออะไร

00:02:02.124 --> 00:02:03.724
ตะกั่ว? ผิดครับ

00:02:05.644 --> 00:02:12.364
อะไรนะครับ? หมึกพรินเตอร์? เกือบถูกแล้วครับ

00:02:12.524 --> 00:02:16.764
อันนั้นแพงขึ้นครับ ไม่ใช่ถูกลง

00:02:16.844 --> 00:02:17.964
มีใครอยากทายอย่างอื่นไหมครับ

00:02:17.964 --> 00:02:20.364
Vibranium? ใกล้เคียงมาก

00:02:20.364 --> 00:02:21.004
สมควรไปอยู่ใน Marvel แต่เราอยู่ในโลกจริงครับ ไม่ใช่ครับ

00:02:24.092 --> 00:02:28.218
สแตนเลส? เกือบถูกครับ แต่สแตนเลสไม่ใช่โลหะ

00:02:32.366 --> 00:02:34.388
สรุปว่าไม่ใช่สแตนเลส

00:02:34.892 --> 00:02:37.879
อลูมิเนียม? ถูกครับ มันคืออลูมิเนียม

00:02:37.932 --> 00:02:38.412
ที่เห็นก้อนๆ อยู่ตอนนี้มันคือก้อนอลูมิเนียม

00:02:38.412 --> 00:02:38.732
เรียกว่า aluminum apex นะ

00:02:38.604 --> 00:02:43.324
สาเหตุที่ตอนแรกมันโคตรแพง แพงกว่าทองอีกเนี่ย

00:02:43.404 --> 00:02:47.564
เพราะช่วงปี 1850 ที่มีการสร้าง Washington Monument

00:02:47.751 --> 00:02:50.124
ก้อนอลูมิเนียมเนี่ยมันถลุงยากมาก

00:02:50.124 --> 00:02:56.684
กว่าที่มันจะออกมาจากโลกแล้วกลายเป็นอลูมิเนียมได้

00:02:56.764 --> 00:02:57.820
ต้องใช้ค่าแปลงของก้อนดินให้กลายเป็นอลูมิเนียมสูงมาก

00:03:00.044 --> 00:03:04.284
ซึ่งสิ่งนี้มันก็เกิดคล้ายๆ กัน กับสิ่งที่เกิดขึ้น

00:03:04.284 --> 00:03:08.463
กับเรื่อง intelligence เรื่องความฉลาด

00:03:09.452 --> 00:03:10.892
ที่ผมจะเล่าให้ฟังต่อไป

00:03:11.532 --> 00:03:12.732
ไอเดียที่ผมอยากจะเล่าเรื่อง scaling law เนี่ย

00:03:12.812 --> 00:03:16.012
มาจากหนังสือเล่มนี้ครับ

00:03:16.732 --> 00:03:19.291
The Scaling Era and an Oral History จาก Dwarkesh Patel

00:03:19.452 --> 00:03:24.052
ไม่รู้มีใครเคยฟังพอดแคสต์ Dwarkesh หรือเปล่า

00:03:25.052 --> 00:03:26.988
หนึ่งคนนะครับ ก็ไปฟังกันได้ครับ

00:03:27.084 --> 00:03:31.052
ส่วนใหญ่ก็จะเป็น data scientist ที่อยู่ในฟิลด์มาฟังกัน

00:03:31.472 --> 00:03:39.004
ก็หนังสือของ Stripe Press นะครับ ผมชอบมาก

00:03:39.084 --> 00:03:41.324
สำหรับคนที่ตอบคำถามถูก เอาไปเลยครับ

00:03:45.296 --> 00:03:49.056
สำหรับคนที่อยากได้ข้อมูลพอๆ กัน

00:03:49.056 --> 00:03:49.368
อยากให้ไปซื้อแบบ Audible

00:03:49.376 --> 00:04:01.536
เพราะว่าเสียงมันจะตรงกับคนที่พูดมากกว่าในหนังสือ

00:04:01.856 --> 00:04:02.576
แต่ว่าหนังสือสวยครับ แนะนำ

00:04:02.669 --> 00:04:05.556
โอเค ต่อมา สิ่งที่จะมาเล่าวันนี้คือเรื่อง scaling law

00:04:05.628 --> 00:04:06.096
ซึ่งทุกคนก็น่าจะรู้อยู่แล้วมั้งอันนี้

00:04:06.096 --> 00:04:06.176
แต่มาแบบย้ำให้ฟังอีกรอบหนึ่ง

00:04:06.336 --> 00:04:09.484
scaling law ความฉลาดที่ราคาถูกลง

00:04:09.564 --> 00:04:12.044
และ hallucination ที่ต่ำลง

00:04:12.044 --> 00:04:15.884
และเราจะเลือกตามเทคโนโลยีใหม่ๆ ยังไง

00:04:15.884 --> 00:04:17.059
ให้เหมาะสมกับเรานะครับ

00:04:17.387 --> 00:04:18.603
โอเค scaling law

00:04:19.803 --> 00:04:25.548
ซึ่งผมคิดว่าทุกคนก็น่าจะรู้จักกันอยู่แล้วใช่ไหมครับ

00:04:25.644 --> 00:04:26.594
pre-training scaling, post-training scaling

00:04:26.604 --> 00:04:27.288
test-time scaling, long thinking

00:04:27.324 --> 00:04:30.844
ที่แบบกดเลือกได้ว่าให้มันใช้เวลาคิดนานขนาดไหน

00:04:31.628 --> 00:04:35.948
ก็ไปต่อกันเลย ก็คือเรื่อง

00:04:36.459 --> 00:04:37.879
intelligence too cheap to meter

00:04:38.348 --> 00:04:41.948
เทรนด์ที่ 2 คือความฉลาดราคาถูกลงเรื่อยๆ

00:04:42.188 --> 00:04:45.411
ตัวอย่างคือเมื่อปีที่แล้ว GPT-4o mini ออกมา

00:04:45.411 --> 00:04:46.668
ถูกกว่า GPT-4 20 เท่า

00:04:47.548 --> 00:04:49.804
และควาฉลาดก็ไม่ได้ต่างกันมาก

00:04:49.868 --> 00:04:53.348
Sam ก็เลยนำมาก่อนเลย โคตรถูก

00:04:53.388 --> 00:04:54.188
ถูกจนไม่ต้องนับกันแล้ว

00:04:55.084 --> 00:04:59.304
ถูกขนาดไหน ถูกขนาดที่ว่าสัปดาห์ที่แล้ว

00:05:00.364 --> 00:05:02.951
ตอนที่ o1-mini ออกมา

00:05:03.004 --> 00:05:07.187
Sam เอาไปเทียบกับตอนที่ o1-preview ออกมา

00:05:07.964 --> 00:05:11.524
ที่ทำคะแนน ARC-AGI 1 ได้เกิน 85%

00:05:11.724 --> 00:05:12.924
อยู่ในช่วงใกล้ๆ กัน

00:05:13.164 --> 00:05:16.834
ปรากฏว่าราคามันถูกลง 300 เท่า

00:05:17.044 --> 00:05:19.244
Sam ก็เลยบอกว่า 300 เท่าใน 1 ปี ถูกจัดเลย

00:05:21.324 --> 00:05:25.564
อันยิ่งกว่านั้นครับ เมื่อวานนี้

00:05:25.644 --> 00:05:27.764
Gemini 1.5 Flash ออกมา เกิดอะไรขึ้น

00:05:28.604 --> 00:05:36.212
ปรากฏว่า Gemini 1.5 Flash ได้ประมาณ 85% เหมือนกัน

00:05:36.524 --> 00:05:38.924
แม่งถูกลง 26,000 เท่า

00:05:38.924 --> 00:05:42.244
จาก o1-preview เมื่อปีที่แล้วนะครับ

00:05:42.319 --> 00:05:43.884
อันนี้เป็นเทรนด์ที่ 2 ที่ฉลาดขึ้น ถูกลง

00:05:43.884 --> 00:05:44.684
และ more powerful เก่งขึ้น

00:05:46.252 --> 00:05:48.787
ใครอยากรู้ว่ามันเก่งขึ้นขนาดไหน

00:05:50.412 --> 00:05:56.412
ตัวนี้เป็น eval ตัวหนึ่งที่คนชอบใช้กัน METR

00:05:56.652 --> 00:05:58.252
เป็น eval ที่เทียบว่า

00:05:58.252 --> 00:05:59.672
คนน่าจะใช้เวลานานขนาดไหนในการแก้ปัญหานี้

00:05:59.747 --> 00:06:01.025
และถ้า AI แก้ปัญหาได้พอๆ กัน

00:06:01.132 --> 00:06:05.612
ก็น่าจะมีความสามารถมากขึ้นพอประมาณเท่าๆ กัน

00:06:07.148 --> 00:06:11.420
โอเค และ hallucinate น้อยลงด้วย คือมั่วน้อยลง

00:06:11.468 --> 00:06:16.108
อันนี้ทุกอย่างมีลิงก์นะครับ กดลิงก์ได้

00:06:16.135 --> 00:06:19.308
ถ้าใครมีลิงก์ไปที่เว็บก็ไปกดลิงก์ตรงนี้ได้

00:06:19.908 --> 00:06:24.988
ซึ่งอันนี้ก็คือแค่ก๊อปมาจากหน้าเว็บ Artificial Analysis

00:06:25.068 --> 00:06:26.876
จะเห็นได้ว่าตัวที่เพิ่งออกมาใหม่ๆ อย่างเช่น

00:06:26.916 --> 00:06:27.156
Gemini 1.5 Flash, Gemini 1.5 Pro

00:06:27.183 --> 00:06:32.268
Claude 3.5 Sonnet ก็เริ่มมั่วน้อยลงเรื่อยๆ แล้ว

00:06:32.588 --> 00:06:33.788
ตามเทรนด์คือตัวมั่วก็คือน้อยลงเรื่อยๆ

00:06:35.244 --> 00:06:38.924
เนื่องจากพอเรามีภาพใหญ่แบบนี้

00:06:40.364 --> 00:06:45.046
ภาพใหญ่ที่โมเดลทั้งฉลาดขึ้น ถูกลง และมั่วน้อยลง

00:06:45.110 --> 00:06:45.866
มันทำให้มีโมเดลใหม่ๆ ตลอดเวลา

00:06:45.884 --> 00:06:47.724
คำถามคือเราควรจะเลือกตามอะไรดี

00:06:47.804 --> 00:06:54.124
คำแนะนำที่ปกติผมให้ก็คือ

00:06:54.124 --> 00:06:55.964
อ้อ และนอกจากจะถูกลงเนี่ย

00:06:57.084 --> 00:06:57.884
server capacity สูงขึ้นตลอดทุกปีด้วย

00:06:57.884 --> 00:06:59.724
ข่าวว่า AI bubble หรือเปล่า

00:06:59.964 --> 00:07:02.113
คือ AI ลงทุนกับการปั๊ม server เยอะขนาดไหน

00:07:03.068 --> 00:07:05.868
จะเห็นได้ว่าสั้นๆ แค่ปีเดียว

00:07:05.868 --> 00:07:08.748
ได้ server size แบบ 1 กิกะวัตต์มาแล้ว

00:07:10.952 --> 00:07:14.048
scaling law สำหรับคนที่ยังไม่เชื่อ

00:07:14.828 --> 00:07:22.551
ให้ไปดูวิดีโอนี้ สำหรับ Dario เป็น CEO Anthropic

00:07:23.996 --> 00:07:25.388
ถ้าใครตาม Dario จะรู้ว่า Dario เป็นคนพูดจริงทำจริง

00:07:25.388 --> 00:07:28.138
น่าเชื่อถือ แบบตอน 2 ปีที่แล้วบอกว่า

00:07:28.508 --> 00:07:30.188
ไม่รู้ scaling law มันจริงหรือเปล่า

00:07:32.508 --> 00:07:33.788
แต่วันนี้บอกว่ายังไงมันก็เก่งขึ้น ฉลาดขึ้น

00:07:33.788 --> 00:07:37.644
และเราก็จะรวยขึ้น ลองไปเปิดดูได้ครับผม

00:07:41.088 --> 00:07:43.061
เรารู้อยู่แล้วว่า AI มันฉลาดขึ้นเรื่อยๆ

00:07:43.264 --> 00:07:45.888
หนึ่งใน eval ที่บอกได้คือ eval ชื่อว่า

00:07:46.368 --> 00:07:51.518
Artificial Analysis Intelligence Index v3 ครับ

00:07:52.768 --> 00:07:53.608
แต่ละเวอร์ชันมันเทียบกันไม่ได้

00:07:53.808 --> 00:07:59.448
ต้องดูเวอร์ชันเดียวกันกับโมเดลขนาดเท่ากัน

00:07:59.808 --> 00:08:01.248
จะเห็นได้ว่าเมื่อเวลาผ่านไป โมเดลฉลาดขึ้นเรื่อยๆ

00:08:02.688 --> 00:08:12.061
อีกอย่างคือ eval นี้รวบรวม 10 eval เข้าด้วยกัน

00:08:13.676 --> 00:08:21.836
อันนี้เป็นตัวอย่างอีกหนึ่ง eval คือ ARC-AGI 1

00:08:22.156 --> 00:08:28.076
ถ้าเราเลือก eval ที่เหมาะสมกับงานของเราได้

00:08:28.076 --> 00:08:30.796
เราก็ไม่จำเป็นต้องไปตามว่าสัปดาห์นี้

00:08:30.796 --> 00:08:33.340
แค่ดู eval ของเราพอว่าแก้ปัญหาได้ฉลาดขึ้นจริงไหม

00:08:34.443 --> 00:08:39.964
แต่แค่ดูชื่อไม่พอนะ ARC-AGI 1 ตอนแรกคนสร้างบอกว่า

00:08:39.964 --> 00:08:42.104
ถ้ามีโมเดลไหน solve ARC-AGI 1 ได้ นี่แหละคือ AGI

00:08:42.604 --> 00:08:44.341
ตอนนี้มีตัว solve ได้แล้ว เขาก็เลยออก

00:08:44.364 --> 00:08:50.680
ARC-AGI 2 และ ARC-AGI 3 ออกมา จีเนียสมาก

00:08:50.764 --> 00:08:56.744
ถ้าดูแค่ชื่อไม่พอต้องทำยังไง

00:08:58.284 --> 00:09:02.460
อย่างเคสนี้ ARC-AGI มี playground ให้ลองเล่น

00:09:02.604 --> 00:09:06.844
ซึ่ง eval เกือบทุกตัวจะมี playground ให้ลองดู

00:09:07.404 --> 00:09:15.164
หรือบอกว่าพอโมเดล solve แล้วมี thinking test ยังไงบ้าง

00:09:17.260 --> 00:09:25.820
อย่างเคสนี้จะมีตัวอย่างให้ 2 ตัวอย่าง

00:09:25.820 --> 00:09:28.620
มีคำถาม 1 คำถาม แล้วให้หาคำตอบให้ได้

00:09:29.120 --> 00:09:35.360
พอเราดูแบบนี้จะรู้สึกว่ามัน abstract idea มากๆ

00:09:37.420 --> 00:09:38.460
บอกได้คร่าวๆ ว่าโมเดลน่าจะมีความสามารถ

00:09:38.460 --> 00:09:38.733
ในการทำ spatial thinking อะไรก็ว่าไป

00:09:39.420 --> 00:09:40.300
ต้องดูอีกทีว่าคำถามพวกนี้เหมาะกับงานเราในแง่ไหน

00:09:42.828 --> 00:09:49.308
ประเด็นคือพอเห็นคะแนน eval พุ่งขึ้นเรื่อยๆ

00:09:49.308 --> 00:09:50.908
อย่าไป confuse the map with territory นะครับ

00:09:51.048 --> 00:09:56.535
บางครั้งคะแนนพุ่ง แต่โมเดลอาจจะโง่เท่าเดิม

00:09:57.708 --> 00:09:59.708
ตัวอย่างหนึ่งคือหลายคนรู้จัก LM Arena

00:10:01.761 --> 00:10:06.108
ช่วงแรกคนชอบมาก มันคือการมีคำถาม 1 ข้อ

00:10:06.108 --> 00:10:08.416
แล้ว blind test คำตอบจาก 2 โมเดล

00:10:09.735 --> 00:10:19.148
ถ้าโมเดลไหนคนเลือกมากกว่า โมเดลนั้นก็ชนะไป

00:10:19.148 --> 00:10:21.048
พอคนจำนวนมากมาเลือกคำตอบที่ดีที่สุด

00:10:21.228 --> 00:10:21.788
มันควรจะหาโมเดลที่ฉลาดที่สุดออกมาได้

00:10:21.788 --> 00:10:22.908
อันนี้คือ assumption ของ LM Arena

00:10:25.004 --> 00:10:34.404
แต่ก็อาจจะมีคนที่เห็นต่างอย่าง Edwin Cheng

00:10:35.084 --> 00:10:43.749
CEO ของ SearchAI บริษัทที่ทำ data labeling

00:10:43.953 --> 00:10:46.300
เตรียมข้อมูลให้บริษัท AI เอาไปเทรนต่อ

00:10:46.406 --> 00:10:49.969
เขาบอกว่าใครที่ไป optimize LM Arena

00:10:50.220 --> 00:10:53.820
คนนั้นคือ optimize สำหรับทำ clickbait

00:10:54.140 --> 00:11:00.226
เพราะเราให้ใครก็ไม่รู้มาลองกดเลือกคำตอบ

00:11:00.226 --> 00:11:04.444
เขาอาจจะเลือกแค่เพราะยาวกว่า สวยกว่า มี emoji

00:11:05.724 --> 00:11:09.964
ข้อคิดคือดูแค่ชื่อและวิธีการไม่พอ

00:11:10.284 --> 00:11:14.204
ต้องดูว่ามัน optimize สำหรับสิ่งที่เราต้องการจริงๆ ไหม

00:11:15.360 --> 00:11:20.000
ตัวอย่าง หนึ่งในตัวอย่างของ eval

00:11:21.152 --> 00:11:22.288
วันที่โมเดลออกเราก็จะเห็นเลย

00:11:23.600 --> 00:11:24.720
ไปดูจาก model announcement นะครับ

00:11:26.960 --> 00:11:31.840
จะมี list มาเพียบเลย ให้เราดูว่าอันไหนถูกใจเรา

00:11:32.080 --> 00:11:36.320
ถ้าคะแนนมันดีเราค่อยไปต่อ

00:11:36.320 --> 00:11:37.760
ถ้าคะแนนไม่ประทับใจก็แยกย้าย

00:11:37.760 --> 00:11:38.800
อย่างเช่น มีใครดูมาบ้างครับ Gemini 3 Flash

00:11:38.827 --> 00:11:39.120
มีอะไรน่าสนใจบ้าง

00:11:40.748 --> 00:11:45.468
ถ้าเป็นเมื่อตอนที่ Gemini 3 Pro ออก

00:11:45.708 --> 00:11:47.908
ตัวที่คนปลื้มกันก็คือ Screenshot2Code Pro

00:11:48.748 --> 00:11:55.068
ออกมา 72.7% ในขณะที่ตัวอื่นอยู่ที่ 30%

00:11:56.188 --> 00:11:57.468
มันเป็น eval ในความสามารถที่เช็คได้ว่า

00:11:59.052 --> 00:12:01.932
โมเดลสามารถควบคุมหน้า UI ได้เก่งแค่ไหน

00:12:01.932 --> 00:12:05.532
เข้าใจหน้า UI ขนาดไหน แล้วควบคุมได้ดีหรือเปล่า

00:12:05.772 --> 00:12:07.425
มันโดดมาเลยเมื่อเทียบกับชาวบ้านเขา

00:12:07.532 --> 00:12:15.872
แต่ GPT-5.2 สัปดาห์ที่แล้วออกมาทำไป 86.3%

00:12:15.932 --> 00:12:16.332
คนก็เลยกลับไปใช้ GPT ต่อดีกว่า

00:12:17.676 --> 00:12:19.740
จะเห็นได้ว่าในนี้ Opus ไม่ค่อยมี

00:12:21.356 --> 00:12:23.956
เพราะ Opus อาจจะไม่สู้ multimodal เท่าไหร่

00:12:25.916 --> 00:12:32.766
คำถามคือเราจะเอา eval ตัวไหนมาเป็นที่พึ่งทางใจ

00:12:33.569 --> 00:12:36.456
มาช่วยให้เราเลือกโมเดลที่เหมาะสมกับเราดี

00:12:38.103 --> 00:12:40.236
มีตัวอย่างง่ายๆ ประมาณ 12 eval ไปเลือกเอาได้

00:12:40.236 --> 00:12:41.143
อย่างเช่น Creative Writing

00:12:41.516 --> 00:12:43.716
เราต้องไปดูอีกทีว่ามันเทสยังไง

00:12:43.943 --> 00:12:49.484
ตัวนี้เทสว่าโมเดลมีความ creative ขนาดไหน

00:12:49.484 --> 00:12:52.364
Context Arena บอกว่าถ้า context มันยาวมากๆ

00:12:52.364 --> 00:12:56.300
โมเดลจะลืมหรือเปล่า เหมาะสำหรับคนที่จะแก้ codebase

00:12:57.404 --> 00:13:00.584
ที่ใหญ่มากๆ แสนบรรทัด ล้านบรรทัด

00:13:01.991 --> 00:13:03.964
ถ้าโมเดลยังจำได้ระหว่างทาง

00:13:06.940 --> 00:13:09.820
มาดูอะไรเท่ๆ บ้าง อย่างเช่น AI-VIS Thai Exam

00:13:10.700 --> 00:13:13.260
อันนี้เป็นพี่ไทยทำนะ

00:13:13.260 --> 00:13:19.460
เอาโมเดลไปรันเทียบกับข้อสอบ O-NET ดูว่ามันเก่งแค่ไหน

00:13:20.300 --> 00:13:23.500
ถ้าใครอยากทำงานที่มีภาษาไทยด้วย

00:13:25.633 --> 00:13:27.340
ก็อาจจะลองไปดู eval ตัวนี้ดู

00:13:27.340 --> 00:13:27.980
ว่ามีโมเดลไหนแก้ปัญหาภาษาไทยได้เก่งๆ แล้วไปลองเทสได้

00:13:28.087 --> 00:13:31.980
มีอะไรอีก Play Pokemon สำหรับคนที่ตามอยู่

00:13:32.300 --> 00:13:38.508
Gemini 1.5 Pro สามารถเล่น Pokemon Red ได้จบแล้ว

00:13:38.508 --> 00:13:39.948
แต่ใช้ token ไปเยอะมาก

00:13:39.948 --> 00:13:42.088
เมื่อเทียบกับตัวใหม่คือ Gemini 3 Pro

00:13:42.748 --> 00:13:44.788
Gemini 3 Pro แป๊บเดียว ใช้ token นิดเดียว จบแล้ว

00:13:46.188 --> 00:13:51.548
คำแนะนำของผมคือไปเลือกโมเดลที่ใช่

00:13:52.268 --> 00:13:58.161
ถ้าอยากได้งานที่โค้ดเยอะๆ และทำหลายขั้นตอน

00:13:58.161 --> 00:13:59.575
ก็อาจจะดู Terminal Bench

00:13:59.948 --> 00:14:02.135
แทนที่จะวัดแค่โมเดลอย่างเดียว

00:14:02.188 --> 00:14:04.028
คือวัดทั้งโมเดลและ harness ด้วย

00:14:04.588 --> 00:14:08.228
อย่างในรูป ตัวที่เป็นอันดับหนึ่งตอนนี้คือ

00:14:08.268 --> 00:14:08.748
Droid กับ Opus 4.5

00:14:09.388 --> 00:14:14.410
Droid เป็น harness ตัวหนึ่งที่บริษัททำโดยเฉพาะ

00:14:14.988 --> 00:14:16.828
เราสามารถเลือกโมเดลไหนก็ได้

00:14:16.848 --> 00:14:19.628
แล้วอาจจะไป mix and match กับ Context Arena ดู

00:14:19.681 --> 00:14:25.508
ถ้าอยากได้โค้ดเยอะๆ เอา context ยาวๆ

00:14:25.708 --> 00:14:27.068
เลือกโมเดลที่เลือก harness เก่งๆ ไปใช้ด้วยกัน

00:14:27.068 --> 00:14:34.868
คำแนะนำสุดท้ายคือถ้า eval ที่ว่ามา

00:14:35.308 --> 00:14:38.828
ไม่มีอันไหนเหมาะสมกับปัญหาเราเลย

00:14:38.828 --> 00:14:40.268
แนะนำให้ลองทำ eval เป็นของตัวเองครับ

00:14:40.268 --> 00:14:40.988
เริ่มจากเอา log ที่เรามีก็ได้

00:14:41.008 --> 00:14:42.508
แล้วมาเลือกปัญหาเล็กๆ ที่เราเคยทำ

00:14:42.688 --> 00:14:44.548
เลือกจำนวนปัญหาน้อยๆ เลือก subset ของปัญหามา

00:14:46.764 --> 00:14:50.124
แล้วอย่าลืมเก็บ log ไว้ด้วยว่า

00:14:50.204 --> 00:14:54.524
LLM ที่เคยแก้ปัญหาเรา หน้าตามันเป็นยังไง ขอบคุณครับ
