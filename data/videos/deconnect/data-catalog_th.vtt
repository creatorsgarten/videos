WEBVTT

00:00:00.300 --> 00:00:03.000
ก็ครับ เอ่อ ผมแมนนะครับ

00:00:03.000 --> 00:00:04.300
ชื่อ Yothin Muangsommuk ครับ

00:00:04.300 --> 00:00:05.600
มาจาก LINE Thailand ครับ

00:00:05.600 --> 00:00:10.400
เป็น Data Engineer ต๊อกต๋อยอยู่ในบริษัทนั้นครับผม

00:00:11.700 --> 00:00:17.900
ต้องบอกว่าตอนที่-- ตอนที่เป็นหัวข้อนี้เนี่ย
ตอนก่อนจะเริ่มมาเป็นหัวข้อนี้

00:00:19.400 --> 00:00:21.700
ตอนนั้นเนี่ยตอนคุยกับ คุณแก้วคุณกานต์เนาะ

00:00:22.200 --> 00:00:28.900
แล้วก็รู้สึกว่า เฮ้ย มันมีคอมโพเนนต์ตัวหนึ่งเว้ยที่ในเวลาเราทำ Data Platform เนี่ย

00:00:28.900 --> 00:00:31.800
คนไม่ค่อยพูดถึง อย่างน้อยก็ในคอนเท็กซ์ใน

00:00:32.299 --> 00:00:37.100
ในประเทศเราเนาะ คนไม่ค่อยพูดถึงแล้วรู้สึกว่า เฮ้ย มันก็สำคัญนะ

00:00:37.100 --> 00:00:39.100
เออ แต่คนกลับไปโฟกัสอีกจุดหนึ่ง

00:00:39.100 --> 00:00:43.000
จุดอื่นไรเงี้ย เดี๋ยวค่อยว่ากันในทอล์คครับ ก็เลยวันนี้คิดว่า

00:00:43.900 --> 00:00:46.600
เราจะมาทำให้ดูว่าไอ้ตัว Data Catalog เนี่ย

00:00:46.600 --> 00:00:48.700
จริงๆ แล้วเนี่ยมัน มันสำคัญยังไง

00:00:48.700 --> 00:00:52.800
แล้วก็ข้างในมันทำงานยังไงบ้างครับคร่าวๆ ครับ

00:00:52.800 --> 00:00:57.500
คร่าวๆ วันนี้ก็จะมีอยู่ 4 section หลักๆ

00:00:57.500 --> 00:01:01.900
นะครับ ก็คือเดี๋ยวคุยกันเรื่องว่าเฮ้ยตัว Catalog เนี่ยมัน มันเกิดขึ้นมาได้ไง

00:01:02.600 --> 00:01:05.200
อ่า แล้วก็ตามมาด้วยว่าตัว

00:01:05.200 --> 00:01:08.100
ตัวประเภทของ Catalog เนี่ย เฮ้ยมันมีอะไรบ้างนะ

00:01:08.100 --> 00:01:11.800
เพราะว่าคำว่า Catalog มันก็ดูเป็นคำที่มันเจเนริกเนาะ

00:01:11.800 --> 00:01:17.400
เออ ใครอาจจะพูดอาจจะเข้าใจไม่ตรงกันครับ
แล้วก็ในส่วนที่สามเนี่ย เราจะพูดว่าเฮ้ยมัน

00:01:18.000 --> 00:01:20.700
มันทำงานยังไง
เบื้องหลังมันเป็นยังไงอะไรอย่างเงี้ย

00:01:20.700 --> 00:01:23.800
จุดดีไซน์ดีซิชั่นของมันที่มันเกิดขึ้นมามันเพราะอะไรครับ

00:01:23.800 --> 00:01:28.100
แล้วก็ส่วนสุดท้ายก็คือเราจะพูดถึงว่าในอนาคตต่อไปเนี่ย

00:01:28.100 --> 00:01:33.700
เออ มันจะไปทางไหน ตัวทูลลิงตัวนี้
ตัวคอมโพเนนต์ตัวนี้ครับโอเค

00:01:33.700 --> 00:01:40.200
ไม่ให้เป็นการเสียเวลาครับ ตัวแรกที่เราจะพูดถึงกันก็คือตัว Catalog เนี่ยมันเกิดมาได้ไง

00:01:41.500 --> 00:01:45.200
ในนี้ทุกคนน่าจะรู้จักสิ่งที่เรียกว่าห้องสมุดเนาะ

00:01:45.800 --> 00:01:50.000
อ่านี่เป็นสิ่งที่ทุกคนคุ้นเคยกันใน
ใน physical world ครับ

00:01:50.000 --> 00:01:54.300
ซึ่งห้องสมุดก็มีอะไร มี Data
Data คืออะไร หนังสือถูกป่ะ

00:01:54.300 --> 00:01:58.500
อยู่ตามชั้นอยู่ตามอะไร
ทีเนี้ยเราก็จะเกิดคำถามว่า โอเค

00:01:59.100 --> 00:02:02.500
ถ้าเราอยากจะไปหาหนังสือสักเล่มนึง
สมมุติไปหา อ่า

00:02:02.500 --> 00:02:05.900
อะไรนะ Designing Data-Intensive Application ที่พี่กานต์พูดตะกี้

00:02:05.900 --> 00:02:11.700
เราจะไปหาที่ชั้นไหนยังไงครับ ถ้าใครอายุเยอะหน่อย

00:02:11.700 --> 00:02:14.400
อาจจะคุ้นเคยกับสิ่งนี้

00:02:15.100 --> 00:02:20.300
อันนี้ อันนี้ขอเช็กคร่าวๆ
มีใครไม่เคยเห็นสิ่งนี้ไหมครับ โอเค

00:02:20.300 --> 00:02:23.000
แปลว่าเราอาจจะอยู่กันคนละยุคกันจริงจริง (หัวเราะ)

00:02:23.000 --> 00:02:27.500
ครับ สิ่งนี้มันเป็นเหมือน Index Card Catalog ในห้องสมุดเนาะ

00:02:27.500 --> 00:02:32.100
คือก่อนที่มันจะเริ่มมีระบบคอมพิวเตอร์เข้ามาในชีวิตประจำวันของเราเยอะๆ เนี่ย

00:02:32.100 --> 00:02:34.100
การหาหนังสืออยู่ในห้องสมุดเนี่ย

00:02:34.100 --> 00:02:38.300
การที่เราจะเดินหาตามชั้น— สมมุติห้องสมุดมันใหญ่มากแล้วมันก็ใช้เวลาเยอะนะครับ

00:02:38.300 --> 00:02:42.731
มันก็เลยจะถูกย่อตัว Index Card ตัวนี้อยู่ที่มุมมุมหนึ่งในห้องสมุด

00:02:42.731 --> 00:02:45.800
อาจจะเป็นตู้ที่มันมีชั้น Stack อะไรอย่างเงี้ย

00:02:45.800 --> 00:02:52.000
แล้วก็จะมีตัวอักษรบอกว่าโอเคอะไรอยู่ตรงไหนนะครับซึ่งในตัว Index Card เนี่ยมันจะมี

00:02:52.000 --> 00:02:57.700
มันจะมีดีเทลคร่าวๆ ก็คือแบบว่า เฮ้ย
มันเป็นหนังสืออะไร ใครเขียนนะ

00:02:57.700 --> 00:03:03.100
เสร็จแล้วมันก็จะมีบอกว่าไอ้ตัวหนังสือตัวนี้หรือ Material ที่เราต้องการหาเนี่ย

00:03:03.100 --> 00:03:07.500
มันอยู่ในเซคชั่นไหน ชั้นไหนของห้องสมุด

00:03:07.500 --> 00:03:09.800
อ่า ตัวนี้ซึ่งถามว่า

00:03:09.800 --> 00:03:13.200
พอเรามาดูอย่างงี้เนี่ยมันช่วยอะไร ถ้าเรามองแบบฟิสิคอลเนาะ

00:03:13.200 --> 00:03:17.500
มันช่วยให้เราประหยัดเวลาแทนที่เราจะต้องไปเดินหาแบบตามชั้น เฮ้ยชั้นนี้อยู่ที่ไหน

00:03:17.500 --> 00:03:20.200
หมวดไอทีอยู่ตรงไหน
หมวด Data Engineering อยู่ตรงไหนเนี่ย

00:03:20.200 --> 00:03:22.900
เรามาดูตรงนี้ก่อน เราก็รู้ชั้น เราจะรู้

00:03:22.900 --> 00:03:27.900
เราจะรู้มุม เราจะรู้ชั้น
แล้วเราก็จะไปหยิบได้ถูกเล่ม

00:03:27.900 --> 00:03:31.200
อ่านี่คือ physical world ที่เราคุ้นเคยกันเนาะ

00:03:32.200 --> 00:03:39.100
ทีนี้กลับมาที่ตัวงาน Data ของเราเนี่ย ในยุคแรกๆ
เนี่ยตัวระบบ Data มันยังไม่ซับซ้อนครับ

00:03:39.100 --> 00:03:40.766
จริงๆ มันก็ซับซ้อนแหละ แต่ว่า

00:03:40.766 --> 00:03:44.100
สิ่งที่มันอยู่มันอยู่ในสิ่งที่เรียกว่า Data Warehouse เนาะ

00:03:44.100 --> 00:03:47.100
อ่าซึ่งแต่ก่อนมันก็จะเป็นซอฟต์แวร์ก้อนเดียว

00:03:47.100 --> 00:03:51.800
อ่าอาจจะสมมติว่ามันเป็นตัว RDBMS สักตัวหนึ่งที่มันใหญ่มากๆ นะครับ

00:03:51.800 --> 00:03:55.500
ซึ่งเราก็จะคุ้นเคยกับหน้าตัวหน้าการ Query เนาะ

00:03:55.500 --> 00:04:02.500
แล้วเราก็จะคุ้นเคยกับอินเตอร์เฟสว่าเอ้ยเราใช้ SQL ในการ Query ตัว Data ที่เรามีอยู่เนี่ยขึ้นมาได้ในตัว

00:04:02.500 --> 00:04:05.400
Data ที่เราจัดการอยู่นะครับ

00:04:05.400 --> 00:04:09.300
ซึ่งตัวคอมโพเนนต์ตัวนี้หรือ Data Warehouse ตัวนี้เนี่ย

00:04:10.100 --> 00:04:14.300
ความสะดวกสบายของมันน่ะก็คือเรารู้แค่ SQL

00:04:14.300 --> 00:04:18.500
เรารู้ว่า Data เราอยู่ที่ไหน
เราสามารถ Select จากตัวจุดที่เรารู้ได้เลย

00:04:18.500 --> 00:04:21.300
เราไม่จำเป็นต้องจำว่าเอ้ยอะไรมันอยู่ตรงไหนเนาะ

00:04:21.300 --> 00:04:25.900
เบื้องหลังจริงๆ ของ Warehouse เนี่ย
ถ้าเราไปดู Architecture ของตัว RDBMS เนี่ย

00:04:26.700 --> 00:04:31.900
มันจะประกอบด้วยคอมโพเนนต์ยุบยับเนาะแต่จะมีคอมโพเนนต์ตัวนึงชื่อว่า Catalog Manager นะครับ

00:04:31.900 --> 00:04:37.500
หรืออีกชื่อหนึ่งถ้าจะไปดูตัว Architecture ของตัว Database System เราเรียกว่า Data Dictionary นะครับ

00:04:37.500 --> 00:04:40.200
ตัวนี้จะเป็นตัว Map ว่าตัวเนื้อไฟล์จริงๆ อ่ะ

00:04:40.900 --> 00:04:43.300
อ่าตัวนั้นน่ะมันมี Structure ของ Data เป็นยังไง

00:04:43.300 --> 00:04:48.200
ตัว Database ชื่ออะไร แล้วก็แต่ละคอลัมน์อ่ะมันเป็น Type ไหนอะไรอย่างเงี้ย

00:04:48.200 --> 00:04:50.000
จะถูก Define ไว้ในสิ่งที่เรียกว่า Data Dictionary

00:04:50.000 --> 00:04:52.900
ซึ่งอยู่ในสิ่งที่เรียกว่า Catalog Manager เนาะ

00:04:52.900 --> 00:04:56.000
อ่าอันนี้คือยุคที่เป็นตัว อ่า

00:04:56.000 --> 00:04:58.800
ผมเรียกว่า Monolithic Data Warehouse ก็คือยังเป็นก้อนใหญ่ๆ

00:04:58.800 --> 00:04:59.300
ก้อนนึงอยู่

00:04:59.900 --> 00:05:05.600
ทีนี้เนี่ยอย่างที่ทุกคนรู้กันอาจจะสักประมาณ— ตอนนี้ปี 2025 ใช่ไหม

00:05:05.600 --> 00:05:09.100
ย้อนกลับไปประมาณปี 2010 เราเริ่มมีปัญหาการ Scaling

00:05:09.600 --> 00:05:11.941
อ่าเราเริ่มมีปัญหาการ Scaling ว่าโอเค

00:05:11.941 --> 00:05:14.600
ไอ้ก้อนใหญ่ๆ ก้อนนี้มันเริ่มเอาไม่อยู่แล้ว

00:05:14.600 --> 00:05:19.000
เพราะ Data ในยุคที่มันเป็นเว็บเนี่ย มันไหลมาเยอะมาก

00:05:19.000 --> 00:05:22.900
ไม่ว่าจะเป็นสมมติทำระบบบริษัทเอ็นเตอร์ไพรส์ใหญ่ๆ อย่างเงี้ย ทำระบบเซลล์

00:05:22.900 --> 00:05:24.510
ทำหน้าเว็บขายของ ทำนู่นทำนี่

00:05:24.510 --> 00:05:27.100
เราจะเริ่มมี Data ไหลเข้ามาในระบบเยอะๆ นะครับ

00:05:27.100 --> 00:05:31.400
ซึ่งตัว Monolithic Data Warehouse ก้อนโตๆ เนี่ย ไม่ว่าจะขยาย CPU

00:05:31.400 --> 00:05:33.300
ขยาย RAM ขยายฮาร์ดดิสก์ยังไงเนี่ย

00:05:33.300 --> 00:05:35.800
การที่มันระบบเป็นก้อนก้อนเดียวเนี่ย มันก็เริ่มเอาไม่อยู่แล้ว

00:05:36.300 --> 00:05:41.900
เพราะฉะนั้นมันเลยเกิดสิ่งที่ทุกคนอาจจะเริ่มคุ้นเคยกันดีในยุคนี้นะครับ ก็คือ Cloud

00:05:42.500 --> 00:05:45.600
อ่า เริ่มมีการสเกลเป็น Distributed เป็น Cloud อย่างเงี้ย

00:05:45.600 --> 00:05:51.500
แล้วเกิดสิ่งที่เรียกว่า Cloud Data Platform ขึ้นนะครับ ซึ่งพอเรามองย้อนไปเนี่ย

00:05:52.500 --> 00:05:55.600
เอ่อ ตะกี้เราคุ้นเคยกับ Structure
ของตัว Data Warehouse เนาะ

00:05:55.600 --> 00:05:57.900
คนที่ทำงานกับ Data ก็เลยเริ่มคิด Structure

00:05:57.900 --> 00:06:02.600
ว่าเอ้ย เราจะทำยังไงดีนะที่เราจะทำการประมวลผล Data อยู่บน Cloud

00:06:02.600 --> 00:06:08.200
โดยใช้คอมโพเนนต์ที่มันทำให้เราใกล้เคียงกับสิ่งที่เราเคยทำได้มากที่สุดครับ

00:06:08.200 --> 00:06:13.200
มันก็เลยเกิดเป็น Building Block ตัวนี้ครับ ขึ้นมาเป็นตัว Cloud Data Platform

00:06:14.100 --> 00:06:18.700
อ่า ซึ่งสมมุติถ้าเราคิดถึงการที่เราจะทำงานกับ Data อย่างเงี้ย

00:06:18.700 --> 00:06:19.700
ในใจเราจะเริ่มคิดแล้ว

00:06:19.700 --> 00:06:21.400
เฮ้ย มันต้อง มันต้องมีคอมโพเนนต์อะไรบ้างนะ

00:06:21.900 --> 00:06:23.400
เอ่อ หลักๆ เนี่ย

00:06:23.900 --> 00:06:28.300
โดยส่วนใหญ่จากที่ประสบการณ์คุยกับหลายคนมา หรืออ่านในคอมมูนิตี้มาเนี่ย

00:06:28.300 --> 00:06:32.100
คนจะเริ่มโฟกัสกับ 2 อย่าง
2 อย่างแรกสุดเลยนะครับ

00:06:32.100 --> 00:06:36.600
ซึ่งจริงๆ มันก็สำคัญนะ เออ
ก็คือเราโฟกัสกับตัวคอมพิวท์

00:06:37.300 --> 00:06:40.700
อ่า ซึ่งคือ CPU กับ RAM เนาะ รีซอร์สต่างๆ
ที่เราต้องใช้ในการประมวลผล

00:06:40.700 --> 00:06:42.500
อีกส่วนหนึ่งที่เราจะคิดก็คือตัว Storage

00:06:43.200 --> 00:06:46.600
อ่า เราจะคิดถึง 2 คอมโพเนนต์นี้ก่อนเสมอเลย ซึ่ง

00:06:46.600 --> 00:06:50.600
ซึ่งมันก็ไม่ผิดเนาะ
แต่ว่าอีกจุดหนึ่งที่สำคัญก็คือ

00:06:50.600 --> 00:06:52.600
แล้วเราจะใช้ Data ตัวนั้นยังไง

00:06:52.600 --> 00:06:55.200
อ่า มันจะเกิดคำถามว่าเรามี CPU--

00:06:55.200 --> 00:06:58.000
เรามีคอมพิวเตอร์เครื่องหนึ่งอ่ะ เอาไว้ประมวลผลแล้วอ่ะ

00:06:58.000 --> 00:07:02.600
แต่พอประมวลผลเสร็จแล้วอ่ะ เราจะเอาตัวประมวลผลตัวเนี้ยให้คนอื่นใช้ยังไงนะครับ

00:07:02.600 --> 00:07:04.100
ซึ่งอันนี้เป็นจุดที่

00:07:04.100 --> 00:07:06.900
ที่ค่อนข้างจะสำคัญในจุดนี้ อ่า

00:07:06.900 --> 00:07:11.700
แต่ก่อนอื่น ก่อนในยุคที่เป็น Cloud เนี่ย ก่อนที่จะไปถึงยุคที่มันมีแค็ตตาล็อกเนี่ย

00:07:12.800 --> 00:07:17.600
อยากจะให้เห็นโลกก่อนว่าโลกที่มันไม่มีแค็ตตาล็อกเนี่ย หน้าตามันเป็นยังไง

00:07:17.600 --> 00:07:20.100
อ่า ทุกคนอาจจะรู้จักเทอมๆ นี้

00:07:20.100 --> 00:07:24.200
อ่า ในยุคนี้น่าจะเป็น Common Word แล้วก็คือสิ่งที่เรียกว่า Data Lake เนาะ

00:07:24.200 --> 00:07:27.900
อ่า อย่างที่ อย่างที่เกริ่นไปตะกี้ก็คือในยุค Cloud เนี่ย

00:07:28.800 --> 00:07:31.900
เรามี Data เยอะมากเนาะ มันจะถูกฟีดดิ้งเข้ามาผ่านการ Inject เข้ามา

00:07:31.900 --> 00:07:34.800
ผ่านการซิงค์ Integrate เข้ามาเยอะมากอยู่ในสิ่งที่เรียกว่า Data Lake

00:07:35.400 --> 00:07:40.500
เสร็จแล้วเนี่ย Data มันกองอยู่ตรงเนี้ยเยอะมาก แล้วเราจะต้องใช้มัน

00:07:40.500 --> 00:07:44.517
อ่ะ ทีนี้เนี่ย การที่เราไม่มีวิธีการการจัดการมัน

00:07:44.517 --> 00:07:48.200
สมมุติเราเอามากองกันแล้ว เออ ทุกระบบ เดฟ

00:07:48.200 --> 00:07:50.700
รีพอร์ต อนาลิสต์อะไรอย่างเงี้ย เอามากองไว้ตรงนี้

00:07:51.500 --> 00:07:55.500
ถ้าไม่มีการจัดการให้มันดีๆ สิ่งที่เกิดขึ้นก็คือ

00:07:55.500 --> 00:07:58.200
แทนที่เราจะได้วาดฝันว่า โอ้ เรามี Data เยอะมาก

00:07:58.200 --> 00:08:03.600
แล้วเราจะมี Data Warehouse ที่เราสามารถคิวรี่ แบบที่เราเคยทำได้ในสมัยที่เรามี

00:08:03.600 --> 00:08:07.600
Data Warehouse เป็นก้อนๆ เนี่ย มันจะเกิดการกรอง Data
ออกมาเยอะ

00:08:07.600 --> 00:08:09.300
เป็น เขาเรียกว่าอะไร Garbage in

00:08:09.900 --> 00:08:14.300
ครับ ซึ่งเราก็จะเกิดคำถามว่า เอ๊ะ แล้วเราจะใช้ Data ตัวนี้ยังไงเนาะ เออ

00:08:15.300 --> 00:08:18.900
ซึ่งสถานะเนี้ย ในการที่เรามี Data Lake

00:08:18.900 --> 00:08:22.700
แล้วเราใช้งานมันไม่ได้อ่ะ สิ่งเนี้ยในทางเทคนิคเราเรียกว่า Data Swamp

00:08:23.400 --> 00:08:27.400
ครับ Data Swamp เนี่ย มันเป็นสเตจของตัว Data Lake ที่

00:08:27.400 --> 00:08:30.800
เราเอาข้อมูลไปใช้ไม่ค่อยได้อ่ะ หรือใช้ยากอะไรอย่างเงี้ย

00:08:30.800 --> 00:08:34.200
เราไม่รู้ว่าเราจะหาข้อมูลตัวนั้นยังไงอ่ะ ยกตัวอย่างเช่น

00:08:34.200 --> 00:08:39.000
เฮ้ย ถ้าสมมติเราอยากได้ Log สมมติมี Traffic งานเข้า เราทำเว็บอีคอมเมิร์ซเนาะ สมมติ

00:08:39.000 --> 00:08:46.010
แล้วเราอยากรู้ว่า เฮ้ย มีคนเข้าเว็บไซต์เราเท่าไหร่ วันนี้เดือนนี้มียอดขายเท่าไหร่ เดือนนี้

00:08:46.010 --> 00:08:49.000
จริงๆ เดฟก็เอา Data มากรองให้ Data Lake แล้วนะ แต่ว่า

00:08:49.000 --> 00:08:53.100
เราไม่มีวิธีการจัดการมัน เราก็จะไม่รู้จะใช้งาน Data ตัวนั้นยังไงอ่ะ เออ

00:08:53.100 --> 00:08:58.700
Data อยู่ตรงนั้นแหละ แต่เรายังไม่ได้ทำเอามาพาสเอามาทำนู่นนั่นนี่ในการจัดการให้มันเป็นระบบนะครับ

00:08:58.700 --> 00:09:03.900
ซึ่งอันเนี้ยเป็น sign ที่สำคัญมาก ในการที่สมมติถ้าเราอยู่ในยุค Cloud เนี่ย

00:09:03.900 --> 00:09:08.800
จะให้มองไว้ เพราะว่ามันจะช่วยป้องกันปัญหาที่ก่อนที่มันจะเริ่มโต

00:09:08.800 --> 00:09:14.000
เราสามารถหยุดมันได้ อ่านะครับ ซึ่ง

00:09:14.000 --> 00:09:16.925
Data Swamp เนี่ย เป็นสเตจที่ทุกคนก็ไม่อยากเจอเนาะ อ่า

00:09:16.925 --> 00:09:20.402
เพราะฉะนั้นมันก็เลยเกิดคอมโพเนนต์ขึ้นมาในยุคคลาวเหมือนกันอีกตัว

00:09:20.402 --> 00:09:22.500
ซึ่งก็คือสิ่งที่เราจะคุยกันวันนี้ก็คือ

00:09:22.500 --> 00:09:23.900
Data Lake เอ้ย Data Catalog

00:09:24.600 --> 00:09:28.800
ครับผม อ่า ในการจัดการว่าเราจะใช้ข้อมูลแต่ข้อมูลยังไง

00:09:28.800 --> 00:09:36.900
ทีนี้เนี่ย ผมพูดเร็วไปไหมนะ ไม่เร็วนะ โอเคครับ ทีนี้เนี่ย

00:09:36.900 --> 00:09:38.900
ก่อนที่จะไปคุยกันเรื่อง Data Catalog ต่อเนี่ย

00:09:38.900 --> 00:09:42.600
อยากให้รู้จักกับประเภทของ Data Catalog ก่อนนะครับ

00:09:42.600 --> 00:09:48.100
โอเค คือถ้าเราเอาคำว่า Data
Catalog ไปเสิร์ชใน Google

00:09:48.100 --> 00:09:52.900
ตอนนี้ในปี 2024 ตอนนี้ปี 2025
เนาะ เราจะเจอว่า โอ้โห มันมี

00:09:52.900 --> 00:10:00.600
มันมี Tooling หลายชื่อ หลายตัวอยู่ในสารสนเทศในการทำตัว Cloud Data Platform
เยอะมาก

00:10:00.600 --> 00:10:04.900
เยอะไปหมด เยอะจนเรารู้สึกว่า เฮ้ย เราจะใช้ตัวไหนดีวะ เออ

00:10:04.900 --> 00:10:09.400
ซึ่งตัว Data Catalog เนี่ย ถ้าเรามามองประเภทมันจริงๆ

00:10:09.400 --> 00:10:13.600
มันสามารถแบ่งกลุ่มได้เป็น 2 ประเภทใหญ่ๆ นะครับ

00:10:14.200 --> 00:10:16.800
ก่อนอื่น ไอ้คำ Catalog อันที่ผมเล่าไปแล้วเนาะ

00:10:16.800 --> 00:10:20.800
ก็คือมันเป็นคำที่โหลมากครับ เราพูดกับบุคคลที่ 1

00:10:20.800 --> 00:10:22.500
บุคคลที่ 2 บุคคลที่ 3 ทุกคนอาจจะเข้าใจว่า

00:10:22.500 --> 00:10:23.900
Catalog ไม่เหมือนกันเลยก็ได้

00:10:23.900 --> 00:10:30.200
อ่า เพราะฉะนั้นนั่นคือสาเหตุว่าทำไมเราต้องมาคุยกันว่ามันมีประเภทอะไรบ้างนะครับ

00:10:30.200 --> 00:10:33.000
ประเภทแรกเราเรียกว่า Technical Catalog

00:10:33.000 --> 00:10:38.800
นะครับ Technical Catalog เนี่ย หน้าที่หลักของมันก็คือทำการ Track ตัว Table Metadata

00:10:39.400 --> 00:10:44.500
นะครับว่า Table เรามีหน้าตาเป็นยังไง เอ่อ มีสกีม่าเป็นยังไง มี

00:10:44.500 --> 00:10:48.100
Database อะไรบ้าง แล้วมันจัด Hierarchy กันยังไง อยู่ตรงโลเคชั่นไหนนะครับ

00:10:48.100 --> 00:10:52.600
ซึ่งหัวใจสำคัญมันก็คือเป็นตัว Source of Truth ของตัวเนื้อ Data ของเรา

00:10:52.600 --> 00:10:57.700
ว่ามันอยู่ที่ไหนนะ อ่านะครับ ตัวนี้เป็นตัวแรก

00:10:57.700 --> 00:11:01.600
ซึ่ง ถ้าจากดูรูปใหญ่ตะกี้เนาะ

00:11:01.600 --> 00:11:05.900
มันสามารถแบ่งมาอยู่ในนี้ได้อีกหลายตัวมาก อีกกลุ่มนึงซึ่ง

00:11:05.900 --> 00:11:09.400
ผมว่าถ้าเราเสิร์ชด้วยคำว่า Data Catalog
เราจะเจอสิ่งนี้มากกว่า

00:11:09.400 --> 00:11:12.500
สิ่งนั้นเราเรียกว่า Federated Catalog นะครับ

00:11:12.500 --> 00:11:16.600
Federated Catalog เนี่ย หรือในอีกชื่อนึงอาจจะเป็นชื่อ Business Catalog

00:11:16.600 --> 00:11:18.800
แต่ผมไม่ค่อยอยากเรียกว่า Business Catalog เนาะ

00:11:18.800 --> 00:11:23.600
Federated คืออะไร? Federated คือการที่เอามารวมรวมกันจากหลายๆ แหล่งนะครับ

00:11:23.600 --> 00:11:26.100
ตัว Federated Catalog เนี่ยจะทำการ Track

00:11:26.100 --> 00:11:29.600
ในเลเวลที่ Business มอง อ่า

00:11:29.600 --> 00:11:32.656
ตัว Technical Catalog อะ เราจะมองในมุมของของเครื่องมือเนาะ

00:11:32.656 --> 00:11:35.421
มองมุม Engineer ว่าเออเครื่องมือมันเชื่อมถึงกันยังไง

00:11:35.421 --> 00:11:38.400
แต่มุม Federated Catalog เนี่ย เราจะมองในมุมของ Business

00:11:38.400 --> 00:11:43.000
ว่าโอเคตัวฝั่ง Business เนี่ยเราจะมอง Data อะไร เราจะมองหาอะไร 

00:11:43.000 --> 00:11:48.200
ซึ่งมันจะประกอบด้วยตัวความสามารถ Capability เนี่ย ในมุมอีกมุมหนึ่ง 

00:11:48.200 --> 00:11:52.100
เช่น ตัว Data Governance ในการจัดการ Access Control หรือว่าตัว

00:11:52.100 --> 00:11:55.400
Document และการสืบค้นเพื่อให้มันง่ายขึ้นนะครับ

00:11:55.400 --> 00:11:59.900
อ่า ซึ่งต้องบอกว่าวันนี้เนี่ย

00:11:59.900 --> 00:12:04.700
ด้วยความที่เรื่อง Data Catalog มันใหญ่มากเนาะ วันนี้เราจะโฟกัสที่ Technical Catalog

00:12:04.700 --> 00:12:12.500
นะครับ ด้วยเวลาที่เรามีจำกัดอีก 18 นาที อ่ะ ทีนี้เนี่ยถ้ามาดูว่าตัว Catalog

00:12:12.500 --> 00:12:17.600
เนี่ยมันทำงานยังไง อ่ะ อ่า ตะกี้เราเห็นก้อนคอมโพเนนต์เล็กๆ

00:12:17.600 --> 00:12:20.600
ตะกี้เนาะ ในภาพของตัว Data Platform

00:12:21.500 --> 00:12:23.500
ต้องย้อนกลับไปเลยว่า

00:12:23.500 --> 00:12:28.400
จุดเริ่มต้นมันน่ะ ในยุคที่มันเริ่มออกมาเป็นตัว Distributed เนี่ย อ่า

00:12:28.400 --> 00:12:31.200
มันเกิดสิ่งที่เรียกว่า
Hive Metastore ขึ้นนะครับ

00:12:31.200 --> 00:12:40.700
Hive Metastore เกิดขึ้นตอนไหน ต้องบอกว่าในยุคนี้มีใคร เอ่อ ไม่รู้จัก Hadoop ไหมครับ

00:12:40.700 --> 00:12:44.900
ติ๊กต็อก ติ๊กต็อก แปลว่ารู้จักกันทุกคน อ่านะครับ

00:12:44.900 --> 00:12:47.300
Hadoop เนี่ยมันเกิดมาตอนประมาณช่วงปี

00:12:47.300 --> 00:12:52.100
2010 กว่าๆ เนาะ เออมันเกิดปัญหาว่าตอนนั้นคำคำที่บูมมากก็คือคำว่า Big Data

00:12:53.400 --> 00:12:56.000
ตอนนั้นเนี่ยมันเกิดปัญหาว่าโอเคคอมพิวเตอร์เครื่องนึง—

00:12:56.000 --> 00:13:00.100
ไอ้ที่เราเกริ่นกันก่อนหน้านี้ว่า Data Warehouse
ก้อนก้อนหนึ่งมันเริ่มมันเริ่มไม่ไหวละ

00:13:00.100 --> 00:13:01.700
แล้วคอมพิวเตอร์มันแพงมาก

00:13:01.700 --> 00:13:05.300
ตัว CPU อะไรมันแพงมากในการที่จะสเกลขึ้นมาเป็นระบบระบบหนึ่ง

00:13:05.300 --> 00:13:08.000
ก็เลยเกิดเฟรมเวิร์คขึ้นมาครอบคลุมก็คือตัว Hadoop เนาะ

00:13:08.000 --> 00:13:14.100
ซึ่งมันทำให้เราใช้คอมพิวเตอร์เครื่องถูกๆ เนี่ยในการกระจายโหลดของการประมวลผลเนี่ยไปอยู่หลายๆ ตัวได้นะครับ

00:13:14.100 --> 00:13:16.600
ตัว Hadoop เนี่ยมันจะมี Stack คร่าวๆ ก็คือ

00:13:16.600 --> 00:13:21.600
มันจะมีตัว HDFS อยู่ข้างล่างเนาะ อันนี้ไม่แน่ใจเห็นเมาส์ผมไหม ก็คือมี HDFS

00:13:21.600 --> 00:13:27.700
เป็นตัว เป็นตัวสตอเรจเนาะ ถ้าเราเทียบกับภาพคลาวด์ตะกี้ แล้วก็มีตัว Yarn เป็นตัวจัดการรีซอร์ส แล้วก็จะมีตัว

00:13:27.700 --> 00:13:33.300
MapReduce ที่เป็นเฟรมเวิร์คเนี่ย ไว้คอยเขียนโปรแกรมในการเอาไปประมวลผลบน Hadoop นะครับ

00:13:33.300 --> 00:13:36.900
ทีเนี้ยในยุคแรกๆ ของ Hadoop เนี่ย มันเกิดปัญหาว่า

00:13:36.900 --> 00:13:40.600
ตัว MapReduce API ของมันเนี่ยมันเขียนยาก

00:13:40.600 --> 00:13:45.100
เพราะว่าคนที่จะเขียนโปรแกรมกับ Hadoop ได้ถามว่าต้องเขียนยังไง ก็เขียนภาษา Java

00:13:45.100 --> 00:13:51.500
แล้วถามว่าคน Dev ที่เป็นอะไรนะ อะนาไลสต์ สมมติเราจะเขียน Java อย่างเงี้ย ในการเอาไปข้อมูลไปวิเคราะห์

00:13:51.500 --> 00:13:57.100
เขียนเป็นโปรแกรม Java แล้วก็รู้สึกว่าโอ้โห ตอนแรกแม่งอยู่ใน Data Warehouse
เขียน SQL กันสวยงาม

00:13:57.100 --> 00:14:00.400
มันต้องไปเขียน Java มานั่งทำโปรแกรม MapReduce อะไรอย่างเงี้ย

00:14:00.400 --> 00:14:03.100
มันเริ่มมีความเป็น software engineering จัดๆ ละ

00:14:03.100 --> 00:14:04.935
มันก็เริ่มไม่สะดวกนะครับ

00:14:05.800 --> 00:14:10.300
ในช่วงถัดมาเนี่ยฝั่ง Facebook ก็เลยบอกว่าโอเคมันเริ่มลำบากไปละ

00:14:10.300 --> 00:14:13.600
เราก็เลยสร้าง Hive ขึ้นมาครอบตัว MapReduce Framework ตัวนี้อีกทีนึง

00:14:13.600 --> 00:14:16.900
ซึ่งตัว Hive เนี่ยจะเป็นทำตัวเป็น

00:14:16.900 --> 00:14:20.400
Data Warehouse ที่อยู่บน Distributed Framework ซึ่งก็คือ Hadoop เนาะ

00:14:20.400 --> 00:14:27.300
ในการทำให้เราสามารถคิวรี่โดยใช้ท่าแบบทำเป็น SQL ที่เราเคยทำได้อยู่บน Hadoop

00:14:27.300 --> 00:14:30.800
ถามว่าข้อดีคืออะไร ข้อดีคือเราได้พลังการประมวลผล

00:14:30.800 --> 00:14:34.000
ในระดับ Data ที่ใหญ่มากในระดับ Hadoop

00:14:34.000 --> 00:14:37.500
แต่เราก็ยังมีอินเทอร์เฟซที่เราใช้งานง่ายที่เป็น SQL อินเทอร์เฟซ

00:14:37.500 --> 00:14:44.100
ในการทำงานกับ Data นะครับ ซึ่งถ้าเราไปดูอาร์คิเทคเจอร์ของ Hive เนี่ย

00:14:44.100 --> 00:14:51.000
ถ้าคุณดูภาพตัว Data Warehouse ตะกี้เนาะ จะเห็นว่ามันแยกส่วนของของตัวที่เป็นรีซอร์ส

00:14:51.000 --> 00:14:57.900
อ่า ดิสก์กับตัวคอมพิวออกจากกันนะครับ แต่ว่าอันนี้อาจจะไม่ต้องลงดีเทลมาก

00:14:57.900 --> 00:15:02.900
แต่ว่าสิ่งที่อยากจะให้เห็นก็คือเราจะรู้ได้ไงว่า

00:15:02.900 --> 00:15:05.012
ตัว Data ตัวนั้นมันอยู่ที่ไหนนะครับ

00:15:05.012 --> 00:15:09.900
มันก็เลยมีคอมโพเนนต์คอมโพเนนต์หนึ่งซึ่งมันมีลูกศรชี้เข้าชี้ออกเยอะมาก สิ่งนั้นคือ

00:15:09.900 --> 00:15:18.400
Metastore ตัวนี้ วงกลมสีน้ำเงิน ตัวนี้เป็นคอมโพเนนต์ที่เกิดขึ้นมาในยุคนั้นนะครับ ซึ่ง

00:15:18.400 --> 00:15:23.600
ตัว Metastore เนี่ยทำหน้าที่หลักๆ เนี่ยก็คือจัดการตัว Abstraction

00:15:23.600 --> 00:15:30.810
อย่างที่ผมบอกก็คือแทนที่เราจะมานั่งนั่งเปิดไฟล์อ่านทำเขียนโปรแกรมกับตัว Hadoop อินเทอร์เฟซ HDFS อย่างเงี้ย

00:15:30.810 --> 00:15:36.000
สิ่งที่เราทำก็คือตัวเนี้ยมันจะจัดการสร้าง Abstraction ครอบความเป็น Table

00:15:36.000 --> 00:15:41.900
ใน MySQL อะไรอย่างเงี้ยขึ้นมาให้ เพื่อให้เราสามารถคิวรี่ได้ แล้วก็จัดการในการทำตัว

00:15:41.900 --> 00:15:45.700
Data Discovery ในการหาว่าเฮ้ยตัว Data เนี้ยมีอะไรบ้าง จัดเป็น

00:15:45.700 --> 00:15:49.300
Catalog เป็น Collection ไว้เพื่อให้เราสามารถสืบค้นได้นะครับ

00:15:49.300 --> 00:15:54.800
ตัวเนี้ย คือความสามารถของมันนะครับ ซึ่ง

00:15:54.800 --> 00:15:58.700
ถ้าไปมองใน Stack ย้อนกลับมาเนาะ ใน Stack ใหญ่ๆ เนี่ย

00:15:58.700 --> 00:16:01.306
ตัวเนี้ย core จริงๆ มันมีแค่นั้นเลย

00:16:01.306 --> 00:16:06.643
ก็คือทำหน้าที่ในการเก็บว่าอะไรมันอยู่ตรงไหน แล้วจะเข้าถึงได้ยังไงนะครับ

00:16:06.643 --> 00:16:09.200
เสร็จแล้วเนี่ยพอมันโฟกัสมากๆ เนี่ย

00:16:09.200 --> 00:16:13.700
มันก็มีคนมาเชื่อมกับมันอยู่ใน
ใน Stack รอบตัวมัน ยกตัวอย่างเช่น

00:16:13.700 --> 00:16:16.900
ตัว compute engine อย่างเช่น Spark หรือ Hive อะไรอย่างเงี้ย

00:16:16.900 --> 00:16:20.300
ซึ่งถ้าใครใช้ Spark ยุคนี้เนาะ
ก็จะมีบางคนแบบว่า

00:16:20.300 --> 00:16:23.400
เฮ้ย ทำไมจะต้องเซ็ตตัว Hive Metastore อีกนะ เราไม่ได้ใช้ Hive นะ

00:16:23.400 --> 00:16:26.500
เพราะว่า Spark เนี่ยมันไม่รู้ว่าอะไรมันอยู่ตรงไหน

00:16:26.500 --> 00:16:29.900
อะ มันต้องมีคนคอยบอกว่าอะไรมันอยู่ตรงไหน
ซึ่งก็คือตัว Hive Metastore

00:16:29.900 --> 00:16:32.600
หรือว่าตัว Presto เนี่ย
ถ้าสมมติไปเก็บของไว้เนี่ย

00:16:32.600 --> 00:16:38.600
บางทีมันก็ไม่รู้ ก็ต้องพึ่งตัว Hive Metastore ในการแบบว่าบอกว่า เฮ้ย อะไรมันอยู่ตรงไหนนะครับ อะ

00:16:39.300 --> 00:16:42.100
แต่ว่ามันก็ไม่ได้คิดแค่นั้นอย่างเดียว

00:16:42.100 --> 00:16:45.300
อย่างเช่น ความสามารถในการจัดการ access control อย่างเงี้ย

00:16:45.800 --> 00:16:48.800
เอ่อ ตัว Hive มันก็มีระดับนึง แต่ว่าคนที่จัดการจริงๆ

00:16:48.800 --> 00:16:52.900
ก็ extend อ่านความรู้ที่ได้จากตรง Hive Metastore เนี่ยไปอยู่ในฝั่ง

00:16:52.900 --> 00:16:55.000
Apache Ranger อะไรอย่างเงี้ย หรืออย่างเช่น

00:16:55.000 --> 00:17:01.900
เอาข้อมูลใน Metastore เนี่ยไปทำ Data Lineage เนี่ย ก็ไปอยู่ในฝั่งตัว Apache Atlas นะครับ อะ

00:17:01.900 --> 00:17:03.965
อันนี้คือภาพรวมคร่าวๆ เนาะ

00:17:03.965 --> 00:17:07.700
ซึ่งพอเรามาดูตัวก้อนของ Hive Metastore จริงๆ อะ

00:17:07.700 --> 00:17:09.800
จริงๆ คอมโพเนนต์มัน มันง่ายมากเนาะ ถ้าใคร

00:17:10.598 --> 00:17:15.300
ถ้าใครเคยเขียนเว็บมาบ้างเนาะ จะรู้จัก สิ่งที่เรียกว่า Three Tier Architecture เนาะ

00:17:15.300 --> 00:17:17.800
อ่า มันก็จะมีแบบเป็นดาต้าเบส เป็นแบ็คเอนด์

00:17:17.800 --> 00:17:20.300
เป็นฟรอนต์เอนด์อะไรอย่างเงี้ยที่
ที่เราคุ้นเคยกันเนาะ

00:17:20.300 --> 00:17:24.900
ตัว Hive Metastore Program จริงๆ เนี่ยมันประกอบไปด้วยแค่ 3 ชั้นอย่างงี้เลยครับ

00:17:24.900 --> 00:17:28.000
ชั้นแรกเนี่ยก็คือตัว Metastore Service

00:17:28.000 --> 00:17:34.000
ตัวเนี้ย สีเหลืองๆ ตัวเนี้ย ซึ่งถูกเขียนในตัว Thrift Framework เนาะ

00:17:34.000 --> 00:17:38.400
อ่า ซึ่งเป็น Interface อีกรูปแบบหนึ่ง ซึ่งสมัยนี้อาจจะหาคนเขียนได้ยากแล้วนะครับ

00:17:38.400 --> 00:17:42.800
เป็น Interface ไว้ให้คุยกับตัว component อื่นๆ นะครับ แล้วก็จะมีตัวฝั่ง database

00:17:42.800 --> 00:17:48.300
ซึ่งตัวเนี้ยจะเก็บตัว metadata อย่างที่บอกเราเก็บอะไร เราเก็บตัว table

00:17:48.900 --> 00:17:54.900
เราเก็บตัว field ว่าเอ๊ย มันมีอะไรเป็นแบบไหน เสร็จแล้วตัวสุดท้ายที่เรามาคุยกันเนี่ยก็คือตัว

00:17:54.900 --> 00:17:57.800
client ซึ่งเอาไว้ในการ interact กับตัว metastore service

00:17:57.800 --> 00:18:00.800
ซึ่งก็คุยผ่านตัว Thrift protocol อีกทีนึงนะครับ อะ

00:18:01.400 --> 00:18:03.000
ดูเข้าใจง่ายๆ

00:18:03.800 --> 00:18:09.300
นะครับ ทีนี้ถ้าเราเจาะลึกเข้าไปในตัวดาต้าเบสว่าตัว Hive Metastore เนี่ย

00:18:09.300 --> 00:18:10.900
สุดท้ายแล้วมันเก็บอะไรบ้างใน table

00:18:10.900 --> 00:18:16.900
มันมีบอกที่ทำเอาดาต้าเบสของ Hive เนี่ย มาแกะตัว Schema ให้ดูเป็นแผนผังอีกทีนึง

00:18:16.900 --> 00:18:18.400
เราจะเห็น table แบบยุบยับเต็มไปหมดเลย

00:18:18.400 --> 00:18:24.300
แต่ถ้าเราอ่านชื่อมันดีๆ เนี่ยจะเริ่มเห็นว่ามันคือองค์ประกอบที่ทำให้เรามีสิ่งที่เรียกว่าตัว

00:18:24.300 --> 00:18:27.566
table กับดาต้าเบสที่เราคุ้นเคยกันได้ ยกตัวอย่างเช่น

00:18:27.566 --> 00:18:30.000
พอเราแยกตัว metadata object ออกมาเนี่ย

00:18:31.100 --> 00:18:34.200
3 กลุ่มหลักๆ ที่เราต้องใช้ในการ Query มีอะไรบ้าง

00:18:34.200 --> 00:18:39.300
เราอยากรู้เนาะว่าตัวดาต้าเบสมีดาต้าเบสอะไรบ้าง เราอยากรู้ว่า table เนี่ย

00:18:40.000 --> 00:18:42.500
ใน table หนึ่งเนี่ยมันมีคอลัมน์อะไรบ้าง

00:18:43.100 --> 00:18:47.500
ตัวดาต้าเบสไหนเป็นเจ้าของ Storage มันเป็นอะไร ก็คือตัว type ของ field เนาะ

00:18:47.500 --> 00:18:51.800
เสร็จแล้วตัว location ของไฟล์ของ table เหล่านั้นเนี่ยมันอยู่ที่ไหนนะครับ

00:18:51.800 --> 00:18:53.900
แล้วก็ส่วนสุดท้ายคือ partition

00:18:53.900 --> 00:18:58.700
อันนี้ต้องสืบย้อนกลับไปนิดนึงว่าความเป็นยุค Hadoop เนี่ย

00:18:59.600 --> 00:19:02.500
เอ่อ ตัวไฟล์อ่ะมันยังอยู่ในระดับ Hierarchy อยู่

00:19:02.500 --> 00:19:06.670
หมายความว่าเราเก็บตัวไฟล์เป็น เป็น Hierarchy ตัวดาต้าอะไรอย่างเงี้ย

00:19:06.670 --> 00:19:08.600
แล้วการที่เราจะ access ได้เนี่ย

00:19:08.600 --> 00:19:12.200
มันก็จะผ่านชั้นตัว folder folder folder ซ้อนเข้าไปนะครับ

00:19:12.200 --> 00:19:17.400
ก็เลยต้องมีสิ่งที่เรียกว่า partition ขึ้นมาด้วย เดี๋ยวตอนตัวอย่างอาจจะได้เห็นครับ

00:19:18.200 --> 00:19:20.900
ทีนี้ตะกี้มันเป็น abstraction เนาะ เรามาดูตัวอย่างของจริงกันดีกว่า

00:19:21.500 --> 00:19:25.200
พอตอนสมมติเรา create table ตัวเนี้ย

00:19:25.200 --> 00:19:29.000
พอเราสั่ง create table อันนี้ทุกคนน่าจะคุ้นเคยตัว SQL ตัวนี้เนาะ

00:19:29.000 --> 00:19:31.200
เออ นะครับ ถ้าทำงาน data น่าจะคุ้นเคยกันอยู่แล้ว

00:19:31.700 --> 00:19:34.600
พอเราสั่ง create table ผ่านตัว Client มันเนี่ย

00:19:34.600 --> 00:19:38.400
Client เนี่ยจะไปสั่งให้ Metastore Service เนี่ยเก็บข้อมูลลงในตัว

00:19:38.400 --> 00:19:42.400
ดาต้าเบสแต่ละ table นะครับ ซึ่งตะกี้ก็อย่างที่เราบอกไปมันมีทั้งดาต้าเบส

00:19:42.400 --> 00:19:46.400
มีทั้งตัว table แล้วก็จะมีตัว partition เนาะ อะไรอย่างเงี้ย

00:19:46.400 --> 00:19:49.700
เก็บเป็น type ว่าโอเคมี field อะไรบ้างนะครับ

00:19:49.700 --> 00:19:57.200
ซึ่งตรงตัวไม่มีอะไร ตะกี้ผมพูดไปนิดนึงแล้วเรื่องการที่มันเก็บว่า โอเคมันเป็น

00:19:57.800 --> 00:20:00.900
เป็นชั้นตัว folder ยังไงเนาะ

00:20:00.900 --> 00:20:05.900
อ่าซึ่งเป็นชั้นๆ อันนี้ก็เลยต้องเก็บข้อมูลลงในตัว Metastore

00:20:07.800 --> 00:20:12.000
อาจจะงงนิดนึงตรงนี้ ทีนี้ตอน Read เนี่ย ถามว่าตอน Read Read ยังไง

00:20:12.000 --> 00:20:14.600
เนื่องจากความที่มันเก็บข้อมูลลงเป็น

00:20:14.600 --> 00:20:18.100
เป็น table directory แต่ละ table เนาะ ในตัวชั้น Storage ของมัน

00:20:19.000 --> 00:20:22.900
ทุกครั้งที่มันถาม Query ขึ้นมา
สิ่งที่เกิดขึ้นก็คือตัว Query Engine น่ะ

00:20:22.900 --> 00:20:24.900
ไม่ว่าจะเป็นตัว Hive เป็น Spark อะไรอย่างเงี้ย

00:20:24.900 --> 00:20:29.500
จะวิ่งไปถาม Metastore ก่อนเสมอว่า เฮ้ย

00:20:30.200 --> 00:20:34.400
เราอยากจะ Query ตัวเนี้ย สมมติในนี้มันเป็น Employee Tracker Coffee Log ตัวเนี้ย

00:20:34.400 --> 00:20:37.600
อยากถามว่าไอ้ table ตัวเนี้ย มันมี field อะไรบ้าง

00:20:37.600 --> 00:20:42.500
Field นั้นมี type เป็นอะไร Location ของไฟล์มันอยู่ที่ไหนนะ

00:20:42.500 --> 00:20:45.800
เสร็จแล้วถ้าสมมติเรา Query สมมติเราชอบ Query เป็น

00:20:45.800 --> 00:20:51.900
เป็น timestamp เนาะ ซึ่งหลายๆ ครั้งในงาน data เราแบ่งงานเป็น partition ตัวนี้ก็จะบอกอีกว่า folder มันอยู่ตรงไหน

00:20:51.900 --> 00:20:54.900
เสร็จแล้วพอเราได้ข้อมูลจากตรงนี้มามากอะ ได้ครบแล้วเนี่ย

00:20:55.500 --> 00:21:01.300
ตัว Query Engine เนี่ยก็จะวิ่งไปอ่านตัวไฟล์แต่ละ path ซึ่งอาจจะอยู่ในตัว Object Storage หรือว่าตัว

00:21:01.300 --> 00:21:07.300
อ่า HDFS ได้นะครับ อันนี้เป็นหลักการทำงานของมัน ซึ่ง อ่า

00:21:07.300 --> 00:21:09.200
พอถึงจุดนี้ก็รู้สึกว่ามันฟังดูดีเนาะ

00:21:09.200 --> 00:21:12.500
มันฟังดูดีว่าเออมันก็ตรงไปตรงมา
นี่แบบไปถาม ไปถามอะไรนะ

00:21:12.500 --> 00:21:16.800
ไปถามบรรณารักษ์ว่าอะไรอยู่ตรงไหน
แล้วก็ ไปหยิบของ ได้ของกลับมานะครับ

00:21:17.300 --> 00:21:19.800
แต่มันมี limitation ในยุคนี้อยู่นะครับ

00:21:20.300 --> 00:21:25.300
Limitation ยุคนี้ก็คือ อย่างแรกตัว Interface ของ Metastore เองเนี่ย

00:21:25.300 --> 00:21:28.500
มันเขียนด้วย Thrift ถามว่าในยุคนี้มีใครเขียนโปรแกรมด้วย Thrift ไหมครับ

00:21:29.300 --> 00:21:31.400
ไม่มีเนาะ ทุกคนรู้จักแต่ HTTP

00:21:31.900 --> 00:21:37.200
ทุกคนรู้จักแต่ REST Protocol ทุกคนรู้จักอะไรอาจจะ อาจจะแรงขึ้นก็คือ gRPC

00:21:37.200 --> 00:21:41.400
อะไรอย่างเงี้ย เพราะฉะนั้น Thrift Interface ในยุคนี้เนี่ยมันค่อนข้างจะแบบ

00:21:41.400 --> 00:21:44.100
เริ่มจะหาคนดูแลยากและจะหาคน Extend ได้แล้ว

00:21:44.100 --> 00:21:49.300
อีกจุดหนึ่งที่อาจจะเป็น limitation ของตัว Hive Metastore คือ ทุกครั้งที่มัน query อ่ะ

00:21:49.800 --> 00:21:52.400
มันต้องไปถามตัว RDBMS

00:21:52.400 --> 00:21:55.500
ทุกอย่าง ทุกอย่างยกเว้นตัว Data

00:21:55.500 --> 00:21:58.400
ทุกอย่างหมายถึงอะไร ตัว Column Definition

00:21:58.400 --> 00:22:00.900
Table อยู่ที่ไหน Location อยู่ตรงไหนอะไรอย่างเงี้ย

00:22:00.900 --> 00:22:03.500
มันต้องไปถามตรง RDBMS

00:22:03.500 --> 00:22:06.000
ตัว Database ที่มันเป็นตัวเก็บ Metadata โหลดหนักมาก

00:22:06.000 --> 00:22:09.200
ซึ่งถ้าสมมติเราต้อง query เยอะๆ หรือกับเราอยากสแกนด้วยว่า

00:22:09.200 --> 00:22:12.700
เฮ้ย ทั้งหมดเนี่ยมันมีเก็บข้อมูลอยู่เท่าไหร่เนี่ย

00:22:12.700 --> 00:22:18.600
ตัว Database ตัวเนี้ยไม่ว่าจะสเกลเท่าไหร่มันก็จะเริ่มเหนื่อยมากจนเริ่มจะเป็นคอขวดในระบบนะครับ

00:22:18.600 --> 00:22:24.200
แล้วก็จริงๆ แล้วตัว Thrift API เนี่ยมันสามารถต่อตรงได้ซึ่งอาจจะไม่ค่อยปลอดภัยเท่าไหร่เนาะอันนี้

00:22:26.000 --> 00:22:30.800
ทีนี้เนี่ยพอเห็นว่าไอ้ Metadata เนี่ยมันเหนื่อยมากๆ เนาะ เออ

00:22:31.500 --> 00:22:34.500
Netflix ก็เลยบอกว่า โอเค เราจะไม่อยู่กับมันละ

00:22:34.500 --> 00:22:37.200
เราอยู่กับมันมานานพอละ เราจะแก้ปัญหามัน

00:22:37.200 --> 00:22:41.800
มันก็เลยเกิดสิ่งที่เรียกว่า open table format

00:22:41.800 --> 00:22:45.700
ซึ่งหนึ่งในตัวที่เกิดขึ้นมาใน Netflix ก็คือ Iceberg ครับ

00:22:45.700 --> 00:22:49.500
ในนี้มีใครไม่รู้จัก Iceberg ไหมครับ

00:22:50.300 --> 00:22:52.200
โอเค แปลว่าส่วนใหญ่รู้จักนะครับ

00:22:52.200 --> 00:22:54.100
ไม่แปลกใจเพราะนี่มันงาน Data Engineer เนาะ

00:22:54.100 --> 00:22:56.900
เราไม่รู้จัก Iceberg ก็อาจจะแปลกๆ หน่อยครับ

00:22:56.900 --> 00:23:01.700
ในยุค Iceberg เนี่ยถ้าเราไปเสิร์ชตัว Architecture มันจริงๆ เนี่ย

00:23:01.700 --> 00:23:04.600
มันจะเริ่มต่างจาก Hive แล้ว
พอเรามองดูเนี่ย

00:23:04.600 --> 00:23:06.800
ไอ้สิ่งที่มันชูโรงมาเป็นแถวแรกสุดเลยอะ

00:23:07.400 --> 00:23:09.800
คือสิ่งที่เรียกว่า Iceberg Catalog นะครับ

00:23:09.800 --> 00:23:13.500
ตามด้วยตัว Metadata Layer และตัว Data Layer

00:23:14.000 --> 00:23:15.100
นะครับ อ่า

00:23:16.000 --> 00:23:17.400
เดี๋ยวเรามาเจาะดูทีละตัวกัน

00:23:18.500 --> 00:23:19.700
ตัว Iceberg Catalog เนี่ย

00:23:20.600 --> 00:23:24.700
ถ้าเรามองดูเนาะ เฮ้ย มันก็เหมือน Hive Metastore เนาะ

00:23:24.700 --> 00:23:26.400
แต่ถ้าเราดูในอินดีเทลจริงๆ เนี่ย

00:23:27.100 --> 00:23:29.800
ตัวเนี้ยมันจะลดโหลดบางอย่าง

00:23:30.600 --> 00:23:34.800
สิ่งที่มันเก็บเนี่ยมันจะเก็บแค่ Metadata pointer

00:23:34.800 --> 00:23:39.500
หมายความว่าอะไร หมายความว่าแทนที่จะเก็บตัว Table Definition ทั้งหมด อย่างเช่น

00:23:39.500 --> 00:23:42.700
Table เราเนี่ยมี DDL เอ่อ
มีฟิลด์หน้าตาแบบไหน

00:23:42.700 --> 00:23:45.100
มีคอลัมน์อะไรบ้างอย่างเงี้ยเก็บใน Iceberg Catalog

00:23:45.100 --> 00:23:49.800
ไม่ — Iceberg Catalog บอกว่าเราเก็บแค่ Location ของมันนะครับ

00:23:49.800 --> 00:23:56.600
เสร็จแล้วพอเรารู้ Location ของตัว Metadata เนี่ยในเลเวลที่สองเนี่ย ตัว Metadata เก็บอะไร

00:23:56.600 --> 00:24:00.800
ตัว Metadata เก็บรายละเอียดของ Table ตรงนั้นทั้งหมด

00:24:00.800 --> 00:24:03.100
รายละเอียดนั้นมีอะไรบ้าง รายละเอียดนั้นคือ

00:24:03.100 --> 00:24:06.700
เรามีไฟล์เก็บ path อยู่ที่ไหน

00:24:06.700 --> 00:24:09.400
เรามี Schema หน้าตาเป็นยังไงบ้างอะไรอย่างเงี้ย

00:24:09.400 --> 00:24:14.500
ไอ้รายละเอียดที่เราเคยเก็บอยู่ในตัว Hive Metastore เนี่ย มันถูก offload

00:24:14.500 --> 00:24:19.000
ออกมาอยู่ในตัว Metadata Layer ซึ่ง อ่า

00:24:19.700 --> 00:24:23.900
พอมัน offload ตรงนี้เนี่ย…

00:24:23.900 --> 00:24:28.700
ความสามารถของการทำ Schema Evolution อย่างเงี้ย มันเกิดขึ้นได้ง่ายขึ้น

00:24:28.700 --> 00:24:33.000
แล้วคอขวดมันไม่ได้อยู่ที่ตัว Hive Metastore หรือตัว Database ของมันอีกแล้วนะครับ

00:24:33.000 --> 00:24:35.900
ส่วนสุดท้ายเนี่ยก็คือตัว Data File

00:24:35.900 --> 00:24:38.800
ซึ่งจะมีสิ่งที่เรียกว่า Manifest File เป็นตัวประกบไว้เนาะ

00:24:38.800 --> 00:24:41.800
ตัวเนี้ยก็จะเป็นตัวคอยบอกย่อยอีกทีนึงว่า

00:24:41.800 --> 00:24:45.800
ตัว Data File เราเนี่ย Type มันเป็นอะไร อ่า นะครับ

00:24:45.800 --> 00:24:49.900
ซึ่งพอมาดูตัว Iceberg เนี่ย Iceberg

00:24:49.900 --> 00:24:52.200
จริงๆ แล้วตัว Catalog มีหลายตัว

00:24:52.200 --> 00:24:54.400
แต่ตัวหนึ่งที่ Iceberg ชูขึ้นมาก็คือสิ่งที่เรียกว่า

00:24:54.400 --> 00:24:56.300
Iceberg REST Catalog นะครับ

00:24:56.300 --> 00:24:58.800
Iceberg REST Catalog
เนี่ยมันเป็นเหมือน standard ที่

00:24:58.800 --> 00:25:02.800
Iceberg สร้างขึ้นมาว่าการจะทำ Catalog เนี่ยในการคุยกับตัว Iceberg Table เนี่ย

00:25:03.400 --> 00:25:06.900
มันต้องคุยกันด้วย อ่า ฟอร์แมตอะไรบ้างนะครับ

00:25:06.900 --> 00:25:10.000
ซึ่งคอมโพเนนต์ ถ้าเราคุ้นเคยกับภาพตัว Hive Metastore ตะกี้เนาะ

00:25:10.600 --> 00:25:13.200
หน้าตามันก็จะมาแนวเดียวกันเลยก็คือ

00:25:13.200 --> 00:25:16.600
ตัว Iceberg Catalog ซึ่งตะกี้เราพูดถึงว่า

00:25:16.600 --> 00:25:21.300
Thrift มันมีปัญหาเนาะใน Hive Metastore Iceberg บอกว่า Iceberg เราไม่ใช้ Thrift

00:25:21.300 --> 00:25:24.100
เราจะใช้อะไรที่คนเขาเอาไว้ implement ง่ายๆ

00:25:24.100 --> 00:25:27.800
เพราะฉะนั้นก็เลยเกิดสิ่งที่เรียกว่า REST Catalog Specification ขึ้นมานะครับ

00:25:27.800 --> 00:25:33.600
แล้วก็คุยกันผ่านตัว HTTP Service ที่ทุกคนอาจจะเข้าใจกันอยู่แล้ว

00:25:34.100 --> 00:25:34.500
อะ

00:25:34.800 --> 00:25:38.300
แล้วก็ยังมีมรดกตกทอดออกมาอยู่ก็คือ

00:25:38.300 --> 00:25:43.800
เราจะต้องเก็บข้อมูลบางอย่างอยู่ในตัว Database ของตัว Iceberg REST Catalog

00:25:43.800 --> 00:25:49.700
ซึ่งเดี๋ยวเราไปลงดีเทลต่อไปนะครับ แล้วก็มีตัว Client ที่คุยกันผ่านตัว REST Interface

00:25:49.700 --> 00:25:52.000
ไปที่ Iceberg REST Catalog เนาะ อ่า

00:25:53.500 --> 00:25:55.300
ตะกี้เราพูดถึงอันนี้ไปนิดนึงแล้วก็คือ

00:25:55.300 --> 00:26:01.700
แทนที่เราจะเป็นสเปคของ Thrift ซึ่งค่อนข้างจะแบบล็อก vendor มากแล้วเราไม่รู้ว่าเฮ้ยข้างในมันมีอะไรมีอะไรบ้างนะ

00:26:01.700 --> 00:26:05.000
ตัว Iceberg บอกว่า Iceberg เราทำ REST Catalog specification ให้

00:26:05.000 --> 00:26:07.200
แล้วก็ถ้าใครอยากทำตัว Connector

00:26:07.200 --> 00:26:10.200
เอ้ยทำตัว Catalog เนี่ยก็ implement ตามนี้เลยนะครับ

00:26:10.200 --> 00:26:15.200
ซึ่งถ้าใครเป็นโปรแกรมเมอร์แล้วอ่าน Specification เป็นก็จะรู้ว่าโอเคมันมีแค่ input output

00:26:15.200 --> 00:26:18.200
ที่เราแค่ต้องเสิร์ฟออกมาตาม specification

00:26:18.200 --> 00:26:20.168
ส่วนเราจะเป็น implement ด้วยภาษาอะไร

00:26:20.168 --> 00:26:22.300
เป็น Python เป็น Rust เป็นอะไรก็แล้วแต่

00:26:23.100 --> 00:26:27.800
ก็แค่ทำตามนี้ก็พอนะครับ อีกจุดหนึ่งที่น่าสนใจของตัว

00:26:27.800 --> 00:26:30.500
Iceberg Catalog ก็คือตัว Metadata
Object อย่างที่บอก

00:26:31.000 --> 00:26:33.576
ถ้าเราย้อนกลับไปดูภาพ ภาพแรกตรงนี้เนาะ

00:26:33.576 --> 00:26:35.000
Iceberg Catalog เนี่ย

00:26:36.000 --> 00:26:38.900
ตรงนี้มันบอกว่าเราเก็บแค่ Metadata Pointer

00:26:38.900 --> 00:26:39.936
หมายความว่ายังไง

00:26:39.936 --> 00:26:44.600
พอเราไปดูตัวสกีมาจริงๆ ที่ตัวดาต้าเบสของตัว Iceberg Catalog มันเก็บไว้อะ

00:26:45.200 --> 00:26:47.200
สิ่งที่มันสนใจมันสนใจแค่ 2 อย่างเองก็คือ

00:26:47.900 --> 00:26:49.000
มันมี namespace อะไรบ้าง

00:26:49.000 --> 00:26:52.800
Namespace เนี่ยในภาษาที่เราเข้าใจกันก็คือดาต้าเบสเนาะ อ่า

00:26:52.800 --> 00:26:55.900
อีกตัวหนึ่งที่เราสนใจเนี่ยก็คือตัว Iceberg Table

00:26:55.900 --> 00:26:59.000
ก็คือตัว Table จริงๆ ซึ่งตัว Table เนี้ย

00:26:59.900 --> 00:27:04.000
เราสนใจแค่ว่ามันอยู่กับ namespace ไหน อ่า ชื่ออะไร

00:27:04.600 --> 00:27:09.000
แล้วสิ่งที่สนใจจริงๆ คือ Metadata file มันน่ะอยู่ที่ไหนนะครับ

00:27:09.000 --> 00:27:15.900
ซึ่งอาจจะเป็น path ใน HDFS, path ใน S3, path ใน Google Storage อะไรอย่างเงี้ยก็ว่าไปนะครับ

00:27:17.600 --> 00:27:20.200
ทีนี้มาดูเทียบกันว่าจังหวะการเขียนเป็นยังไง

00:27:20.900 --> 00:27:24.900
จังหวะการเขียนสมมุติเราสร้าง create table คล้ายๆ กับตอนที่เราทำ Hive Metastore ตะกี้เนาะ

00:27:26.000 --> 00:27:29.700
พอมันเขียนเนี่ยสิ่งที่มันเซฟลงในตัวดาต้าเบส

00:27:29.700 --> 00:27:32.800
มันเซฟแค่ว่า โอเค เราเกิด DB Table หนึ่งนะ

00:27:32.800 --> 00:27:40.400
DB Table หนึ่งมีการมี Metadata file อ่ะอยู่ที่นี่ อยู่ที่อาจจะเป็น

00:27:40.400 --> 00:27:43.200
S3 แล้วก็เป็น path something อะไรอย่างเงี้ย

00:27:43.200 --> 00:27:50.300
แล้วก็เป็นไฟล์ .json ที่เราอาจจะไป inspect ได้นะครับ เสร็จแล้วมันก็จะสร้างตัวโฟลเดอร์ขึ้นมาในตัว object storage จริงๆ

00:27:50.300 --> 00:27:53.700
แล้วก็เกิดตัว Metadata file ขึ้นมาเป็นเวอร์ชันแรกนะครับ

00:27:53.700 --> 00:27:59.000
ซึ่งตัว Iceberg Catalog มันพอยต์ไปอยู่นะครับ อ่านี่คือการ create table เนาะ

00:27:59.000 --> 00:28:00.700
ทีนี้จังหวะที่มัน read บ้างล่ะ

00:28:01.600 --> 00:28:03.800
จังหวะที่มัน read สมมติเรามีดาต้าแล้วเนี่ย

00:28:03.800 --> 00:28:06.500
สิ่งที่เกิดขึ้นตามจังหวะก็คือ โอเค

00:28:06.500 --> 00:28:09.800
ตัว Client เนี่ยวิ่งไปถามตัว Iceberg Catalog มันว่า Table นี้

00:28:10.700 --> 00:28:12.500
อ่า Metadata file มันอยู่ที่ไหนนะ

00:28:12.500 --> 00:28:14.900
มันก็จะจิ้มไปว่าโอเคอยู่ที่ Metadata นะ

00:28:14.900 --> 00:28:16.700
เสร็จแล้วพอวิ่งไปที่ Metadata ปุ๊บ

00:28:16.700 --> 00:28:21.200
Metadata ก็จะบอกว่าตัว manifest file ของตัว Data file เราอยู่ที่ไหน

00:28:21.200 --> 00:28:23.500
มันก็จะวิ่งไปตามขั้น ถามว่า

00:28:23.500 --> 00:28:27.600
ภาพนี้มันดูเหมือนไม่มีอะไร แต่จริงๆ แล้วสิ่งที่เกิดขึ้นน่ะ

00:28:27.600 --> 00:28:30.900
ไอ้ตัวโหลดใน system ของ Iceberg Catalog ตรงนี้มันน้อยมาก

00:28:30.900 --> 00:28:33.900
สิ่งที่มันถามก็แค่ถามว่าอะไรมันอยู่ตรงไหน แบบจุดจุดเดียว

00:28:34.700 --> 00:28:38.100
รายละเอียดของ Table เช่น เรารู้ว่าคอลัมน์มันอยู่ที่ไหน

00:28:38.100 --> 00:28:40.400
Location ของตัว Data file อยู่ตรงไหนอย่างเงี้ย

00:28:40.400 --> 00:28:45.700
รวมถึงเวอร์ชันของดาต้ามันถูกออฟโหลดไปอยู่ข้างๆ ใน Metadata layer หมดเลยนะครับ

00:28:45.700 --> 00:28:50.900
นี่คือวิวัฒนาการที่เกิดจากยุค Hive Metastore ขึ้นมาเป็น Iceberg Catalog อ่า

00:28:52.100 --> 00:28:58.100
ครับซึ่งตัว advantage เมื่อกี้ผมน่าจะเล่าไปหมดแล้ว ผมขอข้ามแล้วกันนะครับ ตึ๊งตึ๊ง

00:28:59.400 --> 00:29:03.600
พูดถึงอนาคตบ้างซึ่งตะกี้ทุกคนจะเริ่มเข้าใจแล้วว่าจริงๆ

00:29:03.600 --> 00:29:07.100
แล้ว ตัว Catalog เนี่ยมันก็เริ่มพอจะทำงานยังไงเนาะ อ่า

00:29:08.700 --> 00:29:13.700
ทีนี้เนี่ยพอ Catalog มันทำงานพื้นฐานได้ละ คนก็เริ่มแบบว่า โอ๊ย

00:29:13.700 --> 00:29:15.500
มันก็ไม่ได้ซับซ้อนขนาดนั้นนี่หว่า

00:29:16.000 --> 00:29:22.000
เราเริ่มจะมียูสเคสว่าเอามันไปใช้กับอะไรบ้างดีนะครับ ถ้าเราตามเทรนด์

00:29:22.000 --> 00:29:24.700
ในตัว Data Engineering community มาสักพักเนาะ

00:29:24.700 --> 00:29:27.300
เราจะเริ่มเห็นว่าตัว Open Table Format เนี่ย

00:29:27.300 --> 00:29:32.000
มันค่อนข้างจะ dominate ช่วงนี้หนักมากนะครับ เราทุกคนต้องปรับตัวอยู่กับมันนะครับ

00:29:32.700 --> 00:29:39.000
เทรนด์แรกเกี่ยวกับ Data Catalog ที่อยากจะให้รู้ก็คือมันจะเริ่มเกิดสิ่งที่เรียกว่า

00:29:39.000 --> 00:29:40.200
Format Agnostic Catalog

00:29:40.200 --> 00:29:42.000
Format Agnostic คืออะไร

00:29:42.000 --> 00:29:47.300
อ่า ในช่วงที่เราดูตรงเนี้ย มันจะมีบางตัวที่บอกมันว่า

00:29:47.300 --> 00:29:49.144
เค เราชอบทำงานกับไฟล์ format นี้

00:29:49.144 --> 00:29:52.200
เราชอบทำงานกับไฟล์ format นี้ที่อยู่ใน Data Lakehouse

00:29:52.200 --> 00:29:58.500
แต่ทุกคนก็รู้ว่า หลาย need ในปัจจุบันมันก็มี requirement แต่ละทีมไม่เหมือนกันเนาะ

00:29:58.500 --> 00:30:00.600
ทีมนี้อยากได้ อ่า performance ดีๆ

00:30:00.600 --> 00:30:04.800
ในการ query ข้อมูล ทีมนี้อยากได้แค่แบบเป็นทำ monthly stat อะไรอย่างเงี้ย

00:30:04.800 --> 00:30:11.200
ซึ่งพอ requirement need มันไม่เหมือนกันเนี่ย มันก็เลยเกิด อ่า ตัว

00:30:11.200 --> 00:30:13.300
Open Format ขึ้นมาหลายๆ ไฟล์นะครับ

00:30:13.300 --> 00:30:16.700
ซึ่งไอ้ Format Agnostic ตัวนี้มันเข้ามาแก้ปัญหาในจุดนี้

00:30:16.700 --> 00:30:21.800
ก็คือแทนที่เราจะมี 1 Catalog ต่อ 1 ไฟล์ Open Format type เนี่ย

00:30:22.300 --> 00:30:25.400
เรามี Catalog ตัวนี้ที่มัน interop กับตัว

00:30:26.000 --> 00:30:31.300
ตัวไฟล์ type หลายหลายแบบได้เลยนะครับ ซึ่งเพื่อให้มั่นใจได้ว่าเรามี

00:30:31.800 --> 00:30:33.600
เรามีอะไรนะ ไฟล์ format ที่เหมาะสมกับแต่ละ

00:30:33.600 --> 00:30:37.500
use case แล้วก็ตัว specification ค่อนข้างจะเปิดกว้างเพื่อจะให้เรา

00:30:37.500 --> 00:30:40.300
extend มากยิ่งขึ้นนะครับ ซึ่งตัวอย่างของตัว

00:30:41.100 --> 00:30:44.300
อ่า Format Agnostic Catalog ตัวนี้ก็คือตัว Unity Catalog เนาะ

00:30:44.300 --> 00:30:48.500
ซึ่งตอนนี้ support หลากหลายมากกับตัวอย่างเช่น Apache Trino

00:30:48.500 --> 00:30:54.700
หรือว่าตัว XTable
เองก็น่าจะกำลังคิดอยู่ตรงนี้อยู่ว่าเป็นตัว Catalog ที่ support ในการ inter

00:30:54.700 --> 00:30:59.400
interprocess ตัว Open Table Format
นะครับอีกกลุ่มหนึ่งนะครับ

00:31:00.400 --> 00:31:04.300
เอ่อ ประมาณช่วงเดือนที่แล้วผม
ผมไปเจอบทความความหนึ่งชื่อว่า

00:31:05.000 --> 00:31:09.800
Rise of Single Node Processing นะครับ มัน
มันพูดถึงเทรนด์ในช่วงนี้ว่า เฮ้ยทำงาน Data Engineer

00:31:09.800 --> 00:31:12.500
เรา เราไม่ค่อยอยากจะ เขาเรียกอะไรนะ

00:31:12.500 --> 00:31:14.800
setup ตัว cluster ในการประมวลผลขึ้นมาเยอะแล้ว

00:31:14.800 --> 00:31:18.400
เพราะเทคโนโลยี compute engine เนี่ยมัน

00:31:18.400 --> 00:31:20.400
มันดีขึ้นมากแล้ว ยกตัวอย่างเช่น ไอ้

00:31:20.900 --> 00:31:24.100
MacBook ตัวนี้ เอาจริงๆ มันก็แรงเนาะ ถูกไหม

00:31:24.100 --> 00:31:26.600
มัน มันไม่เหมือนคอมสมัยก่อนที่แบบแรม 4 GB

00:31:26.600 --> 00:31:30.600
ซีพียูแบบกระจึ๋งนึง อะไรอย่างเงี้ย
แล้วเราประมวลผลดาต้า ไม่ได้

00:31:30.600 --> 00:31:32.800
คอมสมัยนี้มันแรงพอที่เราจะทำอะไรในเครื่องได้แล้ว

00:31:32.800 --> 00:31:37.800
มันก็เลยเกิด tooling ที่ทำให้เราประมวลผลในเครื่องได้ที่เป็น Single Processor อย่างเช่นตัว

00:31:37.800 --> 00:31:41.700
DuckDB หรือตัว Apache Arrow หรือตัว Polars อย่างเงี้ย

00:31:41.700 --> 00:31:46.400
อ่า ซึ่งพอเกิด movement ตัวนี้ขึ้นมา สิ่งที่เกิดขึ้นคือ

00:31:46.400 --> 00:31:52.500
ความเป็นแค็ตตาล็อกอะ แทนที่เราจะต้อง maintain เป็น component แยกอะ มันจะเริ่ม shift ไปหาฝั่งที่เป็น Processor มากขึ้น

00:31:52.500 --> 00:31:59.400
ก็คือให้มันอยู่ในเครื่องนี้เลย โดยการ pre-load ตัว อ่า แค็ตตาล็อกหรือ knowledge ในการ accessing ดาต้าเข้าไปนะครับ

00:31:59.400 --> 00:32:04.600
ซึ่งมันก็ช่วยลดความซับซ้อนในการ maintain component หลายๆ component ที่อยู่ใน Cloud Data Platform มากขึ้น

00:32:04.600 --> 00:32:10.300
แต่อย่างที่บอก พอเราออฟโหลดสิ่งเนี้ยเข้าไปอยู่ในฝั่ง User มากขึ้นเนี่ย การจัดการตัว

00:32:10.300 --> 00:32:12.200
access control หรือว่าแบบ security

00:32:12.200 --> 00:32:14.500
อะไรอย่างเงี้ย มันก็เริ่มมีความ challenge อยู่นะครับ

00:32:14.500 --> 00:32:17.900
ตัวนี้เป็นเทรนด์อีกเทรนด์หนึ่งที่กำลังมาของแค็ตตาล็อก

00:32:17.900 --> 00:32:22.800
เทรนด์สุดท้ายที่อยากจะพูดถึงครับ ก็คือตัว
Orchestrator Integrated นะครับ

00:32:23.400 --> 00:32:26.700
คือถ้าเรามองในมุม Data Platform เนาะ

00:32:26.700 --> 00:32:31.200
ทุกคนเนี่ยอยากทำงาน— ตะกี้พี่กานต์พูดถึงว่า ถ้าอยากให้มันทำงานซ้ำๆ มันก็ต้องมี Cron เนาะ

00:32:31.900 --> 00:32:35.900
แต่ถ้างานในดาต้าจริงๆ เราก็จะมี Orchestrator เนาะ Airflow หรือนู่นนั่นนี่

00:32:35.900 --> 00:32:39.900
หรือที่เราใช้กันนะครับ ซึ่งตัว Orchestrator

00:32:39.900 --> 00:32:42.700
เนี่ยก็เริ่มมี movement เหมือนกัน
แทนที่เราจะทำงานเป็น

00:32:42.700 --> 00:32:45.600
เป็น taskๆ แบบว่า ทำ A ไป B ไป C อะไรอย่างเงี้ย

00:32:45.600 --> 00:32:50.400
เราจะเริ่มทำงานกับดาต้าในมุมของสิ่งที่เรียกว่า Asset มากยิ่งขึ้นนะครับ

00:32:50.400 --> 00:32:55.000
ซึ่งทั้งๆ ที่ตัว Orchestrator มันรู้อยู่แล้วว่ามันจะคุยกับใครอะไรยังไงอ่ะ

00:32:55.000 --> 00:32:58.900
มันก็ยกระดับตัวเองขึ้นมาว่า เฮ้ย
เรากุมความรู้ของแค็ตตาล็อกตัวนี้ไว้ด้วยนะ

00:32:58.900 --> 00:33:01.000
อยากรู้อะไรว่าอะไรมันเชื่อมกับอะไรตรงไหนเนี่ย

00:33:01.000 --> 00:33:04.400
มาดูที่เรานะครับ ถามว่าทำอย่างงี้แล้วมันดียังไง

00:33:05.500 --> 00:33:09.900
ดาต้าแค็ตตาล็อกส่วนใหญ่เนี่ย มันจะแยก component ออกไปเป็นต่างหากตัวหนึ่งเนาะ

00:33:09.900 --> 00:33:14.685
แล้วต้องการที่จะทำให้มันมี value ขึ้นมา
เราต้องทำการส่งดาต้าให้มัน

00:33:14.685 --> 00:33:15.700
อาจจะจะเป็นการ

00:33:15.700 --> 00:33:17.558
push model หรือ pull model ก็ได้

00:33:17.558 --> 00:33:21.100
แต่การที่เรา move ตัวแค็ตตาล็อกตัวนี้มาอยู่ในตัว Orchestrator

00:33:21.100 --> 00:33:22.500
ซึ่งทุกคนต้องทำงานกับมันอยู่แล้วอ่ะ

00:33:23.000 --> 00:33:27.200
มันทำให้ความรู้อยู่ตรงเนี้ย
แล้วการเกิดขึ้นของดาต้า

00:33:27.200 --> 00:33:29.012
ดาต้าควอลิตี้เป็นยังไงอย่างเงี้ย

00:33:29.012 --> 00:33:31.900
มันถูกจัดการอยู่ในตัว Orchestrator ทีเดียวเลยนะครับ

00:33:31.900 --> 00:33:38.600
ซึ่งมันก็ลดความซับซ้อนไว้อีกเนาะนะครับ
ซึ่งถามว่าตัวเนี้ย ถามว่าเกิดขึ้นมากแค่ไหน เอ่อ

00:33:38.600 --> 00:33:41.000
ผมไม่รู้ ผมไม่รู้ Orchestrator ตัวอื่นเนาะ

00:33:41.000 --> 00:33:45.500
แต่ตัวอย่าง Dagster หรืออย่างเช่นตัว Airflow ที่ทุกคนใช้กันเนี่ย

00:33:45.500 --> 00:33:47.300
Dagster ก็จะมีสิ่งที่เรียกว่า Asset เนาะ

00:33:47.300 --> 00:33:48.800
ตัว Airflow ก็จะมีสิ่งที่เรียกว่า Asset

00:33:48.800 --> 00:33:51.300
ตัวเนี้ยเป็นตัว drive ตัว movement นี้ขึ้นมาว่า

00:33:51.300 --> 00:33:54.900
โอเค เราย้ายแค็ตตาล็อกมาอยู่ที่ฝั่งของ Orchestrator

00:33:54.900 --> 00:33:58.600
นะครับ อ่ะ ทีนี้

00:33:58.600 --> 00:34:00.800
จริงๆ ขอเกินเวลา ขออภัยนะครับ

00:34:01.800 --> 00:34:05.500
จริงๆ อ่ะ ที่ผมยกตัวอย่างเมื่อตะกี้ มัน มันยังไม่หมดของแค็ตตาล็อกเลยครับ

00:34:05.500 --> 00:34:10.300
มันเป็นแค่ตัว core ความสามารถของแค็ตตาล็อกเลยว่าอะไรมันอะไรอยู่ตรงไหนนะครับ จริงๆ

00:34:10.300 --> 00:34:14.000
มันมีเรื่องอีกเยอะมากที่ไม่ได้พูดถึงซึ่ง

00:34:14.000 --> 00:34:22.000
เอ่อ ก็หวังว่าอันนี้อาจจะเป็นจุดเริ่มต้นที่ไปมองมุมแค็ตตาล็อกตัวนี้มากยิ่งขึ้น

00:34:22.000 --> 00:34:24.300
ว่ามันควรจะทำอะไรได้ ทำอะไรไม่ได้นะครับ

00:34:24.300 --> 00:34:31.100
แล้วก็สิ่งที่อยากจะฝากไว้อันสุดท้ายของทอล์คนี้คือ คือตัว Data Catalog เนี่ย

00:34:31.900 --> 00:34:35.000
ถ้าสมมุติเราอยู่ในบริษัทเนาะ ลอง ลองคิดภาพตัวบริษัท

00:34:35.000 --> 00:34:40.400
บริษัทเนี่ย เวลาเราเข้าไปเนี่ย ให้มองดูว่าตัว Adoption ของดาต้าเราเป็นเลเวลไหน

00:34:40.400 --> 00:34:47.199
อะ บริษัทเราเป็น Brownfield หรือเปล่า ที่มีการทำ Governance หนักมาก มีทุกอย่างพร้อม มี Processing เรียบร้อยแล้ว

00:34:47.199 --> 00:34:53.757
หรือว่าเราเข้าไปเป็น Data Engineer คนแรกที่อยู่ในบริษัท แล้วเราไม่รู้ว่าจะทำอะไรยังไงขึ้นมา อะไรอย่างเงี้ยนะครับ

00:34:53.757 --> 00:34:56.100
ความรู้ที่เรามีในการทำแค็ตตาล็อกตัวเนี้ย

00:34:57.600 --> 00:35:01.900
ในวันนี้ที่ผมเล่าไปเนี่ย มัน serve สอง
สองคน สองคน สองกลุ่มเนี้ยต่างกัน

00:35:02.400 --> 00:35:06.300
อ่า อย่างเช่นสมมุติเราอยู่ในโลกที่มัน Brownfield มากเนาะ

00:35:06.300 --> 00:35:08.700
เออ เรามี Governance หนักมาก เรามีนู่นนั่นนี่หนักมาก

00:35:08.700 --> 00:35:14.600
ถามว่าถ้าสมมุติ Governance เราเริ่มช้า หรือตัว Data Catalog ของ ของตัวหลักเรามันเริ่มโหลดมากๆ

00:35:14.600 --> 00:35:18.900
อย่างเงี้ย เราจะทำยังไงให้มันเร็วขึ้นในสภาวะที่องค์กรมันใหญ่มากๆ อย่างเงี้ย

00:35:18.900 --> 00:35:23.100
การที่เรารู้ว่าแค็ตตาล็อกมันทำงานยังไง หรือว่าเราจะเลือกใช้ สร้างมันยังไงอย่างเงี้ย

00:35:23.700 --> 00:35:25.200
ตัวเนี้ยจะทำให้มัน accelerate ยิ่งขึ้น

00:35:26.500 --> 00:35:28.900
หรืออย่างเช่นถ้าอยู่ใน Greenfield อย่างเงี้ย

00:35:28.900 --> 00:35:32.400
โอเค เราไม่รู้อะไรเลย เราเป็น Data Engineer คนแรกในบริษัท เราจะทำยังไง

00:35:32.400 --> 00:35:37.300
การที่เรารู้จักแค็ตตาล็อกเนี่ย มันทำให้รู้ว่า โอเค จุดเริ่มต้นที่ Data Citizen เลเวลแรก

00:35:37.300 --> 00:35:42.800
เลเวลแรกคือใครคือ Engineer ที่เราทำงานด้วยเนี่ย เขาจะใช้ดาต้ายังไงเนี่ย มันจะมีประโยชน์ยังไงบ้างนะครับ

00:35:42.800 --> 00:35:45.400
นอกจากที่เราจะรู้ว่าเราจะเลือก Compute Engine ยังไง

00:35:45.400 --> 00:35:51.800
เราจะเลือก Storage ตัวไหนนะครับ ตัวนี้ก็น่าจะหวังว่าจะช่วยให้ อ่า กลุ่มคนที่อยู่ในสองโลกนี้เนาะ

00:35:51.800 --> 00:35:53.800
เข้าใจกับ Data Catalog มากยิ่งขึ้น

00:35:54.500 --> 00:35:56.800
ครับผม ประมาณนี้ครับ ขอบคุณครับ

00:35:56.800 --> 00:35:59.100
ขอเสียงปรบมือให้พี่แมนหน่อยค่ะ

00:35:59.800 --> 00:36:02.900
(เสียงปรบมือ) ขอบคุณพี่แมนมากๆ นะคะ
