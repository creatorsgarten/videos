WEBVTT

00:00:00.300 --> 00:00:04.300
ก็ครับ เอ่อ ผมแมนนะครับ
ชื่อโยธิน วงศ์สมุหครับ

00:00:04.300 --> 00:00:10.400
มาจาก LINE Thailand ครับ
เป็น Data Engineer ต๊อกต๋อยอยู่ในบริษัทนั้นครับผม

00:00:11.700 --> 00:00:17.900
ต้องบอกว่าตอนที่-- ตอนที่เป็นหัวข้อนี้เนี่ย
ตอนก่อนจะเริ่มมาเป็นหัวข้อนี้

00:00:19.400 --> 00:00:21.700
ตอนนั้นเนี่ยตอนคุยกับ คุณแก้วคุณกานต์เนาะ

00:00:22.200 --> 00:00:28.900
แล้วก็รู้สึกว่า เฮ้ย
มันมีคอมโพเนนต์ตัวหนึ่งเว้ยที่ในเวลาเราทำ Data Platform เนี่ย

00:00:28.900 --> 00:00:31.800
คนไม่ค่อยพูดถึง อย่างน้อยก็ในคอนเท็กซ์ใน

00:00:32.299 --> 00:00:37.100
ในประเทศเราเนาะ
คนไม่ค่อยพูดถึงแล้วรู้สึกว่า เฮ้ย มันก็สำคัญนะ

00:00:37.100 --> 00:00:39.100
เออ แต่คนกลับไปโฟกัสอีกจุดหนึ่ง

00:00:39.100 --> 00:00:43.000
จุดอื่นไรเงี้ย
เดี๋ยวค่อยว่ากันในทอล์คครับ ก็เลยวันนี้คิดว่า

00:00:43.900 --> 00:00:46.600
เราจะมาทำให้ดูว่าไอ้ตัว Data Catalog เนี่ย

00:00:46.600 --> 00:00:48.700
จริงๆ แล้วเนี่ยมัน มันสำคัญยังไง

00:00:48.700 --> 00:00:57.500
แล้วก็ข้างในมันทำงานยังไงบ้างครับคร่าวๆ ครับ คร่าวๆ
วันนี้ก็จะมีอยู่ 4 section หลักๆ

00:00:57.500 --> 00:01:01.900
นะครับ
ก็คือเดี๋ยวคุยกันเรื่องว่าเฮ้ยตัว Catalog เนี่ยมัน มันเกิดขึ้นมาได้ไง

00:01:02.600 --> 00:01:08.100
อ่า แล้วก็ตามมาด้วยว่าตัว
ตัวประเภทของ Catalog เนี่ย เฮ้ยมันมี มันมีอะไรบ้างนะ

00:01:08.100 --> 00:01:11.800
เพราะว่าคำว่า Catalog มันก็ดูเป็นคำที่มันเจเนริกเนาะ

00:01:11.800 --> 00:01:17.400
เออ ใครอาจจะพูดอาจจะเข้าใจไม่ตรงกันครับ
แล้วก็ในส่วนที่สามเนี่ย เราจะพูดว่าเฮ้ยมัน

00:01:18.000 --> 00:01:20.700
มันทำงานยังไง
เบื้องหลังมันเป็นยังไงอะไรอย่างเงี้ย

00:01:20.700 --> 00:01:23.800
จุดดีไซน์ดีซิชั่นของมันที่มันเกิดขึ้นมามันเพราะอะไรครับ

00:01:23.800 --> 00:01:28.100
แล้วก็ส่วนสุดท้ายก็คือเราจะพูดถึงว่าในอนาคตต่อไปเนี่ย

00:01:28.100 --> 00:01:33.700
เออ มัน มัน มันจะไปทางไหน ตัว ตัวทูลลิงตัวนี้
ตัวคอมโพเนนต์ตัวนี้ครับโอเค

00:01:33.700 --> 00:01:40.200
ไม่ให้เป็นการเสียเวลาครับ
ตัวแรกที่เราจะพูดถึงกันก็คือตัว Catalog เนี่ยมันเกิดมาได้ไง

00:01:41.500 --> 00:01:45.200
ในนี้ทุกคนน่าจะรู้จักสิ่งที่เรียกว่าห้องสมุดเนาะ

00:01:45.800 --> 00:01:50.000
อ่านี่เป็นสิ่งที่ทุกคนคุ้นเคยกันใน
ใน physical world ครับ

00:01:50.000 --> 00:01:54.300
ซึ่งห้องสมุดก็มีอะไร มีมี Data
Data คืออะไร หนังสือถูกป่ะ

00:01:54.300 --> 00:01:58.500
อยู่ตามชั้นอยู่ตามอะไร
ทีเนี้ยเราก็จะเกิดคำถามว่า โอเค

00:01:59.100 --> 00:02:02.500
ถ้าเราอยากจะไปหาหนังสือสักเล่มนึง
สมมุติไปหา อ่า

00:02:02.500 --> 00:02:05.900
อะไรนะ
Designing Data-Intensive Application ที่พี่กานต์พูดตะกี้

00:02:05.900 --> 00:02:11.700
เราจะไปหาที่ชั้นไหนยังไงครับ ถ้าใคร
(เดาะลิ้น) อายุเยอะหน่อย

00:02:11.700 --> 00:02:14.400
เออต้องขออนุญาตครับ (หัวเราะ)
อาจจะคุ้นเคยกับสิ่งนี้

00:02:15.100 --> 00:02:20.300
อันนี้ อันนี้ขอเช็กคร่าวๆ
มีใครไม่เคยเห็นสิ่งนี้ไหมครับ โอเค

00:02:20.300 --> 00:02:23.000
แปลว่าเราอาจจะอยู่กันคนละยุคกันจริงจริง (หัวเราะ)

00:02:23.000 --> 00:02:27.500
ครับครับสิ่งนี้มันเป็นเหมือน
เป็นเหมือนเป็นเหมือน Index Card Catalog ในห้องสมุดเนาะ

00:02:27.500 --> 00:02:32.100
คือ
คือก่อนที่มันจะเริ่มมีระบบคอมพิวเตอร์เข้ามาในในชีวิตประจำวันของเราเยอะๆ เนี่ย

00:02:32.100 --> 00:02:34.100
การหาหนังสืออยู่ในห้องสมุดเนี่ย

00:02:34.100 --> 00:02:38.300
อ่าการที่เราจะเดินหาตามชั้นสมมุติห้องสมุดมันใหญ่มากแล้วมันก็ใช้เวลาเยอะนะครับ

00:02:38.300 --> 00:02:45.800
มันก็เลยจะถูกย่อตัว Index Card ตัวนี้อยู่อยู่ที่มุมมุมหนึ่งในห้องสมุดอาจจะเป็นตู้ที่มันมีชั้น Stack อะไรอย่างเงี้ย

00:02:45.800 --> 00:02:52.000
แล้วก็จะมีตัวอักษรบอกว่าโอเคอะไรอยู่ตรงไหนนะครับซึ่งในตัว Index Card เนี่ยมันจะมี

00:02:52.000 --> 00:02:57.700
มันจะมีดีเทลคร่าวๆ ก็คือแบบว่า เฮ้ย
มันเป็นหนังสืออะไร ใครเขียนนะ

00:02:57.700 --> 00:03:03.100
เสร็จแล้วมันก็จะมีบอกว่าไอ้ตัวหนังสือตัวนี้หรือหรือ Material ที่เราต้องการหาเนี่ย

00:03:03.100 --> 00:03:07.500
มันอยู่ในเซคชั่นไหน ชั้นไหนของห้องสมุด

00:03:07.500 --> 00:03:13.200
อ่าตัวนี้ซึ่งถามว่าพอเรามาดูอย่างงี้เนี่ยมันช่วยอะไร ถ้าเรามองแบบฟิสิคอลเนาะ

00:03:13.200 --> 00:03:17.500
มันช่วยให้เราประหยัดเวลาแทนที่เราจะต้องไปเดินหาแบบตามชั้น เฮ้ยชั้นนี้อยู่ที่ไหน

00:03:17.500 --> 00:03:20.200
หมวดไอทีอยู่ตรงไหน
หมวด Data Engineering อยู่ตรงไหนเนี่ย

00:03:20.200 --> 00:03:22.900
เรามาดูตรงนี้ก่อน เราก็รู้ชั้น เราจะรู้

00:03:22.900 --> 00:03:27.900
เราจะรู้มุม เราจะรู้ชั้น
แล้วเราก็จะไปหยิบเลขถูก เอ้ยไปหยิบได้ถูกเล่ม

00:03:27.900 --> 00:03:31.200
อ่านี่คือ physical world ที่เราคุ้นเคยกันเนาะ

00:03:32.200 --> 00:03:39.100
ทีนี้กลับมาที่ตัวงาน Data ของเราเนี่ย ในยุคแรกๆ
เนี่ยตัวระบบ Data มันยังไม่ซับซ้อนครับ

00:03:39.100 --> 00:03:44.100
จริงๆ มันก็ซับซ้อนแหละ
แต่ว่าสิ่งที่มันอยู่มันอยู่ในสิ่งที่เรียกว่า Data Warehouse เนาะ

00:03:44.100 --> 00:03:47.100
อ่าซึ่งแต่ก่อนมันก็จะเป็นซอฟต์แวร์ก้อนเดียว

00:03:47.100 --> 00:03:51.800
อ่าอาจจะสมมติว่ามันเป็นตัว RDBMS สักตัวหนึ่งที่มันใหญ่มากๆ นะครับ

00:03:51.800 --> 00:03:55.500
ซึ่งเราก็จะคุ้นเคยกับหน้าตัวหน้าการ Query เนาะ

00:03:55.500 --> 00:04:02.500
แล้วเราก็จะคุ้นเคยกับอินเตอร์เฟสว่าเอ้ยเราใช้ SQL ในการ Query ตัว Data ที่เรามีอยู่เนี่ยขึ้นมาได้ในตัว

00:04:02.500 --> 00:04:09.300
ในตัว
ตัว Data ที่เราจัดการอยู่นะครับซึ่งตัวคอมโพเนนต์ตัวนี้หรือ Data Warehouse ตัวนี้เนี่ย

00:04:10.100 --> 00:04:14.300
ความสะดวกสบายของมันน่ะก็คือเรารู้แค่ SQL

00:04:14.300 --> 00:04:18.500
เรารู้ว่า Data เราอยู่ที่ไหน
เราสามารถ Select จากตัวจุดที่เรารู้ได้เลย

00:04:18.500 --> 00:04:21.300
เราไม่จำเป็นต้องจำว่าเอ้ยอะไรมันอยู่ตรงไหนเนาะ

00:04:21.300 --> 00:04:25.900
เบื้องหลังจริงๆ ของ Warehouse เนี่ย
ถ้าเราไปดู Architecture ของของตัว RDBMS เนี่ย

00:04:26.700 --> 00:04:31.900
มันจะประกอบด้วยคอมโพเนนต์ยุบยับเนาะแต่จะมีคอมโพเนนต์ตัวนึงชื่อว่า Catalog Manager นะครับ

00:04:31.900 --> 00:04:37.500
หรือหรืออีกชื่อหนึ่งถ้าจะไปดูตัว Architecture ของตัว Database System เราเรียกว่า Data Dictionary นะครับ

00:04:37.500 --> 00:04:40.200
ตัวนี้จะเป็นตัว Map ว่าตัวเนื้อไฟล์จริงๆ อ่ะ

00:04:40.900 --> 00:04:43.300
อ่าตัวนั้นน่ะมันมี Structure ของ Data เป็นยังไง

00:04:43.300 --> 00:04:48.200
ตัว Database ชื่ออะไร
แล้วก็แต่ละคอลัมน์อ่ะมันเป็น Type ไหนอะไรอย่างเงี้ย

00:04:48.200 --> 00:04:50.000
จะถูก Define ไว้ในสิ่งที่เรียกว่า Data Dictionary

00:04:50.000 --> 00:04:52.900
ซึ่งอยู่ในสิ่งที่เรียกว่า Catalog Manager เนาะ

00:04:52.900 --> 00:04:58.800
อ่าอันนี้คือยุคที่เป็นตัวอ่าผมเรียกว่า Monolithic Data Warehouse ก็คือยังเป็นก้อนใหญ่ๆ

00:04:58.800 --> 00:04:59.300
ก้อนนึงอยู่

00:04:59.900 --> 00:05:09.100
ทีนี้เนี่ยอย่างที่ทุกคนรู้กันอาจจะสักประมาณตอนนี้ปี 2025 ใช่ไหมย้อนกลับไปประมาณปี 2010 เราเริ่มมีปัญหาการ Scaling

00:05:09.600 --> 00:05:14.600
อ่าเราเริ่มมีปัญหาการ Scaling ว่าโอเคไอ้ก้อนใหญ่ๆ
ก้อนนี้มันเริ่มเอาไม่อยู่แล้ว

00:05:14.600 --> 00:05:19.000
เพราะ Data ในยุคที่มันเป็นเว็บเนี่ย มันไหลมาเยอะมาก

00:05:19.000 --> 00:05:22.900
ไม่ว่าจะเป็นสมมติทำระบบบริษัทเอ็นเตอร์ไพรส์ใหญ่ๆ อย่างเงี้ย ทำระบบเซลล์

00:05:22.900 --> 00:05:27.100
ทำหน้าเว็บขายของ ทำนู่นทำนี่
เราจะเริ่มมี Data ไหลเข้ามาในระบบเยอะๆ นะครับ

00:05:27.100 --> 00:05:31.400
ซึ่งตัว Monolithic Data Warehouse ก้อนโตๆ
เนี่ย ไม่ว่าจะขยาย CPU

00:05:31.400 --> 00:05:35.800
ขยาย RAM ขยายฮาร์ดดิสก์ยังไงเนี่ย
การที่มันระบบเป็นก้อนก้อนเดียวเนี่ย มันก็เริ่มเอาไม่อยู่แล้ว

00:05:36.300 --> 00:05:41.900
เพราะฉะนั้นมันเลยเกิดสิ่งที่ทุกคนอาจจะเริ่มคุ้นเคยกันดีในยุคนี้นะครับ ก็คือ Cloud

00:05:42.500 --> 00:05:45.600
อ่า เริ่มมีการสเกลเป็น Distributed เป็น Cloud อย่างเงี้ย

00:05:45.600 --> 00:05:51.500
แล้วเกิดสิ่งที่เรียกว่า Cloud Data Platform ขึ้นนะครับ ซึ่งพอเรามองย้อนไปเนี่ย

00:05:52.500 --> 00:05:55.600
เอ่อ ตะกี้เราคุ้นเคยกับ Structure
ของตัว Data Warehouse เนาะ

00:05:55.600 --> 00:05:57.900
คนที่ทำงานกับ Data ก็เลยเริ่มคิด Structure

00:05:57.900 --> 00:06:13.200
ว่าเอ้ย เราจะทำยังไงดีนะที่เราจะทำการประมวลผล Data อยู่บน Cloud โดยใช้คอมโพเนนต์ที่มันทำให้เราใกล้เคียงกับสิ่งที่เราเคยทำได้มากที่สุดครับ มันก็เลยเกิดเป็น Building Block ตัวนี้ครับ ขึ้นมาเป็นตัว Cloud Data Platform

00:06:14.100 --> 00:06:18.700
อ่า ซึ่งสมมุติถ้าเราคิดถึงการที่เราจะทำงานกับ Data อย่างเงี้ย

00:06:18.700 --> 00:06:21.400
ในใจเราจะเริ่มคิดแล้ว
เฮ้ย มันต้อง มันต้องมีคอมโพเนนต์อะไรบ้างนะ

00:06:21.900 --> 00:06:23.400
เอ่อ หลักๆ เนี่ย

00:06:23.900 --> 00:06:28.300
โดยส่วนใหญ่จากที่ประสบการณ์คุยกับหลายคนมา หรืออ่านในคอมมูนิตี้มาเนี่ย

00:06:28.300 --> 00:06:32.100
คนจะเริ่มโฟกัสกับ 2 อย่าง
2 อย่างแรกสุดเลยนะครับ

00:06:32.100 --> 00:06:36.600
ซึ่งจริงๆ มันก็สำคัญนะ เออ
ก็คือเราโฟกัสกับตัวคอมพิวท์

00:06:37.300 --> 00:06:40.700
อ่า ซึ่งคือ CPU กับ RAM เนาะ รีซอร์ทต่างๆ
ที่เราต้องใช้ในการประมวลผล

00:06:40.700 --> 00:06:42.500
อีกส่วนหนึ่งที่เราจะคิดก็คือตัว Storage

00:06:43.200 --> 00:06:46.600
อ่า เราจะคิดถึง 2
2 คอมโพเนนต์นี้ก่อนเสมอเลย ซึ่ง

00:06:46.600 --> 00:06:52.600
ซึ่งมันก็ไม่ผิดเนาะ
แต่ว่าอีกจุดหนึ่งที่สำคัญก็คือ แล้วเราจะใช้ Data ตัวนั้นยังไง

00:06:52.600 --> 00:06:58.000
อ่า มันจะเกิดคำถามว่าเรามี CPU--
เรามีคอมพิวเตอร์เครื่องหนึ่งอ่ะ เอาไว้ประมวลผลแล้วอ่ะ

00:06:58.000 --> 00:07:02.600
แต่พอประมวลผลเสร็จแล้วอ่ะ เราจะเอาตัวประมวลผลตัวเนี้ยให้คนอื่นใช้ยังไงนะครับ

00:07:02.600 --> 00:07:03.700
ซึ่งอันนี้เป็นจุดที่

00:07:03.700 --> 00:07:04.100
ที่

00:07:04.100 --> 00:07:11.700
ที่ค่อนข้างจะสำคัญในจุดนี้ อ่า แต่ก่อนอื่น ก่อนในยุคที่เป็น Cloud เนี่ย ก่อนที่จะไปถึงยุคที่มันมีแค็ตตาล็อกเนี่ย

00:07:12.800 --> 00:07:17.600
อยากจะให้เห็นโลกก่อนว่าโลกที่มันไม่มีแค็ตตาล็อกเนี่ย หน้าตามันเป็นยังไง

00:07:17.600 --> 00:07:20.100
อ่า ทุกคนอาจจะรู้จักเทอมๆ นี้

00:07:20.100 --> 00:07:24.200
อ่า ในยุคนี้น่าจะเป็น Common Word แล้วก็คือสิ่งที่เรียกว่า Data Lake เนาะ

00:07:24.200 --> 00:07:27.900
อ่า อย่างที่ อย่างที่เกริ่นไปตะกี้ก็คือในยุค Cloud เนี่ย

00:07:28.800 --> 00:07:31.900
เรามี Data เยอะมากเนาะ มันจะถูกฟีดดิ้งเข้ามาผ่านการ Inject เข้ามา

00:07:31.900 --> 00:07:34.800
ผ่านการซิงค์ Integrate เข้ามาเยอะมากอยู่ในสิ่งที่เรียกว่า Data Lake

00:07:35.400 --> 00:07:40.500
เสร็จแล้วเนี่ย Data มันกองอยู่ตรงเนี้ยเยอะมาก แล้วเราจะต้องใช้มัน

00:07:40.500 --> 00:07:48.200
อ่ะ ทีนี้เนี่ย การที่เราไม่มีวิธีการการจัดการมัน สมมุติเราเอามากองกันแล้ว เออ ทุกระบบ เดฟ เดฟ

00:07:48.200 --> 00:07:50.700
เอ่อ รีพอร์ต เอ่อ
อนาลิสต์อะไรอย่างเงี้ย เอามากองไว้ตรงนี้

00:07:51.500 --> 00:07:58.200
ถ้าไม่มีการจัดการให้มันดีๆ
สิ่งที่เกิดขึ้นก็คือ แทนที่เราจะได้วาดฝันว่า โอ้ เรามี Data เยอะมาก

00:07:58.200 --> 00:08:03.600
แล้วเราจะมี Data Warehouse ที่เราสามารถคิวรี่ แบบที่เราเคยทำได้ในสมัยที่เรามี

00:08:03.600 --> 00:08:09.300
Data Warehouse เป็นก้อนๆ เนี่ย มันจะเกิดการกรอง Data
ออกมาเยอะเป็น เขาเรียกว่าอะไร Garbage in

00:08:09.900 --> 00:08:14.300
ครับ ซึ่งเราก็จะเกิดคำถามว่า เอ๊ะ แล้วเราจะใช้
Data ตัวนี้ยังไงเนาะ เออ

00:08:15.300 --> 00:08:18.500
ซึ่งสถานะเนี้ย ในการที่เรามี Data

00:08:18.500 --> 00:08:22.700
Lake
แล้วเราใช้งานมันไม่ได้อ่ะ สิ่งเนี้ยในทางเทคนิคเราเรียกว่า Data Swamp

00:08:23.400 --> 00:08:26.600
ครับ Data Swamp เนี่ย มันเป็นสเตจของตัว Data

00:08:26.600 --> 00:08:34.200
Lake
ที่เราเอาข้อมูลไปใช้ไม่ค่อยได้อ่ะ หรือใช้ยากอะไรอย่างเงี้ย เราไม่รู้ว่าเราจะหาข้อมูลตัวนั้นยังไงอ่ะ ยกตัวอย่างเช่น

00:08:34.200 --> 00:08:39.000
เฮ้ย ถ้าสมมติเราอยากได้ Log สมมติมี Traffic
งานเข้า เราทำเว็บอีคอมเมิร์ซเนาะ สมมติ

00:08:39.000 --> 00:08:46.400
แล้วเราอยากรู้ว่า เฮ้ย มีการ มีคนเอามีคนเข้าเว็บไซต์เราเท่าไหร่ วันนี้เดือนนี้มียอดขายเท่าไหร่ เดือนนี้จริงๆ

00:08:46.400 --> 00:08:52.400
เดฟก็เอา Data มากรองให้ Data Lake
แล้วนะ แต่ว่าเราไม่มีวิธีการจัดการมัน เราก็จะไม่รู้จะใช้งาน Data

00:08:52.400 --> 00:09:08.800
ตัวนั้นยังไงอ่ะ เออ Data
อยู่ตรงนั้นแหละ แต่เรา เรายังไม่ได้ทำเอามาพาสเอามาทำนู่นนั่นนี่ในการจัดการให้มันเป็นระบบนะครับ ซึ่งอันเนี้ยเป็นไซน์ที่สำคัญมากในการที่สมมติถ้าเราอยู่ในยุค Cloud เนี่ย จะให้มองไว้ เพราะว่ามันจะช่วยป้องกันปัญหาที่ก่อนที่มันจะเริ่มโต

00:09:08.800 --> 00:09:14.000
เรา เราสามารถหยุดมันได้ อ่านะครับ ซึ่ง

00:09:14.000 --> 00:09:22.500
Data Swamp
เนี่ย เป็นสเตจที่ทุกคนก็ไม่อยากเจอเนาะ อ่า เพราะฉะนั้นมันก็เลยเกิดคอมโพเนนต์ขึ้นมาในยุค ในยุคคลาวเหมือนกันอีกตัว ซึ่งก็คือสิ่งที่เราจะคุยกันวันนี้ก็คือ

00:09:22.500 --> 00:09:23.900
Data Lake เอ้ย Data Catalog

00:09:24.600 --> 00:09:37.900
ครับผม อ่า ในการจัดการว่าเราจะใช้ข้อมูลแต่ข้อมูลยังไง ทีนี้เนี่ย ผมพูดเร็วไปไหมนะ ไม่เร็วนะ โอเคครับ ทีนี้เนี่ย ก่อนที่จะไปคุยกันเรื่อง

00:09:37.900 --> 00:09:40.600
Data Catalog
ต่อเนี่ย อยากให้รู้จักกับประเภทของ Data

00:09:40.600 --> 00:09:48.100
Catalog ก่อนนะครับ โอเค คือถ้าเราเอาคำว่า Data
Catalog ไปเสิร์ชใน Google

00:09:48.100 --> 00:09:54.000
ตอนนี้ในปี 2024 ตอนนี้ปี 2025
เนาะ เราจะเจอว่า โอ้โห มันมี มันมี Tooling

00:09:54.000 --> 00:09:58.600
หลายชื่อหลายตัวอยู่ในสารสนเทศในการทำตัว

00:09:58.600 --> 00:10:06.700
Cloud Data Platform
เยอะมาก เยอะไปหมด เยอะจนเรารู้สึกว่า เฮ้ย เราจะใช้ตัวไหนดีวะ เออ ซึ่งตัว Data

00:10:06.700 --> 00:10:08.600
Catalog เนี่ย ถ้าเรามามองประเภทมันจริงๆ

00:10:08.600 --> 00:10:13.600
เนี่ย มันสามารถแบ่งกลุ่มได้เป็น 2 ประเภทใหญ่ๆ นะครับ ตัวแรก

00:10:13.600 --> 00:10:20.800
อ้อ ก่อนอื่น ไอ้คำ Catalog
อันที่ผมเล่าไปแล้วเนาะ ก็คือมันเป็นคำที่โหลมากครับ เราพูดกับบุคคลที่ 1

00:10:20.800 --> 00:10:22.500
บุคคลที่ 2 บุคคลที่ 3 ทุกคนอาจจะเข้าใจว่า

00:10:22.500 --> 00:10:30.200
Catalog
ไม่เหมือนกันเลยก็ได้ อ่า เพราะฉะนั้นนั่นคือสาเหตุว่าทำไมเราต้องมาคุยกันว่ามันมีประเภทอะไรบ้างนะครับ

00:10:30.200 --> 00:10:33.000
ประเภทแรกเราเรียกว่า Technical Catalog

00:10:33.000 --> 00:10:38.800
นะครับ Technical Catalog
เนี่ย หน้าที่หลักของมันก็คือทำการ Track ตัว Table Metadata

00:10:39.400 --> 00:10:44.500
นะครับว่า Table
เรามีหน้าตาเป็นยังไง เอ่อ มีสกีม่าเป็นยังไง มี

00:10:44.500 --> 00:10:45.900
Database อะไรบ้าง แล้วมันจัด Hierarchy

00:10:45.900 --> 00:10:50.600
กันยังไง อยู่ตรงโลเคชั่นไหนนะครับ ซึ่งหัวใจสำคัญมันก็คือเป็นตัว

00:10:50.600 --> 00:11:00.800
Source of Truth ของตัวเนื้อ Data
ของเราว่ามันอยู่ที่ไหนนะ อ่านะครับ ตัวนี้เป็นตัวแรก ซึ่งมี มี ถ้าจากดูรูปใหญ่ๆ

00:11:00.800 --> 00:11:07.200
ตะกี้เนาะ มันสามารถแบ่งมาอยู่ในนี้ได้อีกหลายตัวมาก อีกกลุ่มนึงซึ่ง เอ่อ ผมว่าถ้าเราเสิร์ชด้วยคำว่า

00:11:07.200 --> 00:11:12.100
Data Catalog
เราจะเจอสิ่งนี้มากกว่าสิ่งนั้น เราเรียกว่า Federated Catalog นะครับ

00:11:12.600 --> 00:11:17.600
Federated Catalog เนี่ย หรือในอีกชื่อนึงอาจจะเป็นชื่อ
Business Catalog แต่ผมไม่ค่อยอยากเรียกว่า

00:11:17.600 --> 00:11:19.400
Business Catalog เนาะ Federated Catalog

00:11:19.400 --> 00:11:23.900
Federated คืออะไร Federated
คือการที่เอามารวมรวมกันจากหลายๆ แหล่งนะครับ ตัว

00:11:23.900 --> 00:11:27.600
Federated Catalog เนี่ยจะทำการ
Track ในเลเวลที่

00:11:27.600 --> 00:11:33.900
Business มอง อ่า ตัว Technical Catalog
อะ เราจะมองในมุมของของเครื่องมือเนาะ เอ่อ มองมุม Engineer

00:11:33.900 --> 00:11:38.400
ว่าเออเครื่องมือมันเชื่อมถึงกันยังไง แต่มุม Federated
Catalog เนี่ย เราจะมองในมุมของ Business

00:11:38.400 --> 00:11:41.600
ว่าโอเคตัวฝั่ง Business เนี่ยเราจะมอง

00:11:41.600 --> 00:11:46.100
Data
อะไร เราจะมองหาอะไร ซึ่งมันจะประกอบด้วยตัวความสามารถไอ้

00:11:46.100 --> 00:11:52.100
Capability เนี่ย ในมุมอีกมุมหนึ่ง เช่น ตัว Data Governance
ในการจัดการ Access Control หรือว่าตัว

00:11:52.100 --> 00:12:00.600
Document
และการสืบค้นเพื่อให้มันง่ายขึ้นนะครับ อ่า ซึ่งต้องบอกว่าวันนี้เนี่ยด้วยความที่เรื่อง

00:12:00.600 --> 00:12:04.700
Data Catalog
มันใหญ่มากเนาะ วันนี้เราจะโฟกัสที่ Technical Catalog

00:12:04.700 --> 00:12:12.500
นะครับ ด้วยเวลาที่เรามีจำกัดอีก 18 นาที อ่ะ ทีนี้เนี่ยถ้ามาดูว่าตัว Catalog

00:12:12.500 --> 00:12:17.600
เนี่ยมันทำงานยังไง อ่ะ อ่า ตะกี้เราเห็นก้อนคอมโพเนนต์เล็กๆ

00:12:17.600 --> 00:12:20.600
ตะกี้เนาะ ในภาพของตัว Data Platform

00:12:21.600 --> 00:12:26.000
ต้องย้อนกลับไปเลยว่าจุดเริ่มต้นมันน่ะ ในยุคที่มันเริ่มออกมาเป็นตัว

00:12:26.000 --> 00:12:31.200
Distributed เนี่ย อ่า มันเกิดสิ่งที่เรียกว่า
Hive Metastore ขึ้นนะครับ

00:12:31.200 --> 00:12:40.700
Hive Metastore
เกิดขึ้นตอนไหน ต้องบอกว่าในยุคนี้มีใคร เอ่อ ไม่รู้จัก Hadoop ไหมครับ

00:12:40.700 --> 00:12:47.300
ติ๊กต็อก ติ๊กต็อก แปลว่ารู้จักกันทุกคน อ่านะครับ Hadoop เนี่ยมันเกิดมาตอนประมาณช่วงปี

00:12:47.300 --> 00:12:52.100
2010 กว่าๆ
เนาะ เออมันเกิดปัญหาว่าตอนนั้นคำคำที่บูมมากก็คือคำว่า Big Data

00:12:53.400 --> 00:12:57.800
ตอนนั้นเนี่ยมันเกิดปัญหาว่าโอเคคอมพิวเตอร์เครื่องนึงไอ้ที่เราเกริ่นกันก่อนหน้านี้ว่า Data

00:12:57.800 --> 00:13:01.900
Warehouse
ก้อนก้อนหนึ่งมันเริ่มมันเริ่มไม่ไหวละ แล้วคอมพิวเตอร์มันแพงมากตัว

00:13:01.900 --> 00:13:17.100
CPU
อะไรมันแพงมากในการที่จะสเกลขึ้นมาเป็นระบบระบบหนึ่ง ก็เลยเกิดเฟรมเวิร์คขึ้นมาครอบคลุมก็คือตัว Hadoop เนาะ ซึ่งมันทำให้เราใช้คอมพิวเตอร์เครื่องถูกๆ เนี่ยในการกระจายโหลดของการประมวลผลเนี่ยไปอยู่หลายๆ ตัวได้นะครับ ตัว Hadoop เนี่ยมันจะมี Stack คร่าวๆ ก็คือมันจะมีตัว

00:13:17.100 --> 00:13:21.600
HDFS
อยู่ข้างล่างเนาะ อันนี้ไม่แน่ใจเห็นเมาส์ผมไหม ก็คือมี HDFS

00:13:21.600 --> 00:13:27.700
เป็นตัว เป็นตัวสตอเรจเนาะ ถ้าเราเทียบกับภาพคลาวด์ตะกี้ แล้วก็มีตัว Yarn เป็นตัวจัดการรีซอร์ส แล้วก็จะมีตัว

00:13:27.700 --> 00:13:37.200
MapReduce
ที่เป็นเฟรมเวิร์คเนี่ย ไว้คอยเขียนโปรแกรมในการเอาไปประมวลผลบนบน Hadoop นะครับ ทีเนี้ยในยุคแรกๆ ของ Hadoop เนี่ย มันเกิดปัญหาว่าตัว

00:13:37.200 --> 00:13:55.000
MapReduce เอ่อ API
ของมันเนี่ยมันเขียนยาก เพราะว่าคนที่จะเขียนโปรแกรมกับ Hadoop ได้ถามว่าต้องเขียนยังไง ก็เขียนภาษา Java แล้วถามว่าคน Dev ที่เป็นอะไรนะ อะนาไลสต์ สมมติเราจะเขียน Java อย่างเงี้ย ในการเอาไปข้อมูลไปวิเคราะห์ เขียนเป็นโปรแกรม Java แล้วก็รู้สึกว่าโอ้โห ตอนแรกแม่งอยู่ใน

00:13:55.000 --> 00:13:59.900
Data Warehouse
เขียน SQL กันสวยงามสวยงาม มันต้องไปเขียน Java มานั่งทำโปรแกรมแบบ Reduce

00:13:59.900 --> 00:14:12.200
อะไรอย่างเงี้ย มันเริ่มมีความเป็นซอฟต์แวร์เอ็นจินีระลิกจัดๆ ละ มันก็เริ่มไม่สะดวกนะครับ ในช่วงถัดมาเนี่ยฝั่ง Facebook ก็เลยบอกว่าโอเคมันเริ่มลำบากไปละ เราก็เลยสร้าง Hive ขึ้นมาครอบตัว

00:14:12.200 --> 00:14:16.900
MapReduce Framework
ตัวนี้อีกทีนึง ซึ่งตัว Hive เนี่ยจะเป็นทำตัวเป็น

00:14:16.900 --> 00:14:18.800
Data Warehouse ที่อยู่บน Distributed

00:14:18.800 --> 00:14:32.000
Framework
ซึ่งก็คือ Hadoop เนาะ ในการทำให้เราสามารถคิวรี่โดยใช้ท่าแบบทำเป็น SQL ที่เราเคยทำได้อยู่บน Hadoop ถามว่าข้อดีคืออะไร ข้อดีคือเราได้พลังการประมวลผลในระดับระดับ

00:14:32.000 --> 00:14:38.500
Data
ที่ใหญ่มากในระดับ Hadoop แต่เราก็ยังมีอินเทอร์เฟซที่เราใช้งานง่ายที่เป็น เอ่อ SQL อินเทอร์เฟซในการทำงานกับ

00:14:38.500 --> 00:14:45.800
Data
นะครับ ซึ่งถ้าเราไปดูอาร์คิเทคเจอร์ของ Hive เนี่ย ถ้าคุณภาพตัว Data Warehouse

00:14:45.800 --> 00:15:03.300
ตะกี้เนาะ จะเห็นว่ามันแยกส่วนของของตัวที่เป็นรีซอร์สกับ อ่า ดิสก์กับตัวคอมพิวออกจากกันนะครับ แต่ว่าอันนี้อาจจะไม่ต้องลงดีเทลมาก แต่ว่าสิ่งที่อยากจะให้เห็นก็คือเราจะรู้ได้ไงว่าตัว

00:15:03.300 --> 00:15:09.900
Data
ตัวนั้นมันอยู่ที่ไหนนะครับ มันก็เลยมีคอมโพเนนต์คอมโพเนนต์หนึ่งซึ่งมันมีลูกศรชี้เข้าชี้ออกเยอะมาก สิ่งนั้นคือ

00:15:09.900 --> 00:15:18.700
Metastore
ตัวนี้วงกลมสีน้ำเงินตัวนี้เป็นคอมโพเนนต์ที่เกิดขึ้นมาในยุคนั้นนะครับ ซึ่งตัว

00:15:18.700 --> 00:15:23.600
Metastore เนี่ยทำหน้าที่หลักๆ
เนี่ยก็คือจัดการตัว Abstraction

00:15:23.600 --> 00:15:33.600
อย่างที่ผมบอกก็คือแทนที่เราจะมานั่งนั่งเปิดไฟล์อ่านทำเขียนโปรแกรมกับตัว Hadoop อินเทอร์เฟซ HDFS อย่างเงี้ย สิ่งที่เราทำก็คือตัวเนี้ยมันจะจัดการสร้าง

00:15:33.600 --> 00:15:41.900
Abstraction ครอบความเป็น Table
ในในมายด์ SQL อะไรอย่างเงี้ยขึ้นมาให้ เพื่อให้เราสามารถคิวรี่ได้ แล้วก็จัดการในการทำตัว

00:15:41.900 --> 00:15:45.700
Data Discovery ในการหาว่าเฮ้ยตัว Data
เนี้ยมีอะไรบ้าง จัดเป็น

00:15:45.700 --> 00:15:55.900
Catalog เป็น Collection
ไว้เพื่อให้เราสามารถสืบค้นได้นะครับ ตัวเนี้ยคือ คือ คือความสามารถของมันนะครับ ซึ่งถ้าไปมองมองใน

00:15:55.900 --> 00:15:58.000
Stack ย้อนกลับมาเนาะ ใน Stack ใหญ่ๆ

00:15:58.000 --> 00:16:09.200
เนี่ยตัวเนี้ยคอคอจริงๆ
มันมีแค่นั้นเลย ก็คือทำหน้าที่ในการเก็บว่าอะไรมันอยู่ตรงไหน แล้วจะเข้าถึงได้ยังไงนะครับ เสร็จแล้วเนี่ยพอมันโฟกัสมากๆ เนี่ย

00:16:09.200 --> 00:16:13.700
มันก็มีคนมาเชื่อมกับมันอยู่ใน
ใน Stack รอบตัวมัน ยกตัวอย่างเช่น

00:16:13.700 --> 00:16:16.900
ตัวคอมพิว--
คอมพิวเตอร์เอนจินอย่างเช่น Spark หรือ Hive อะไรอย่างเงี้ย

00:16:16.900 --> 00:16:20.300
ซึ่งถ้าใครใช้ Spark ยุคนี้เนาะ
ก็จะมีบางคนแบบว่า

00:16:20.300 --> 00:16:23.400
เฮ้ย
ทำไมจะต้องเซ็ตตัว Hive Metastore อีกนะ เราไม่ได้ใช้ Hive นะ

00:16:23.400 --> 00:16:26.500
เพราะว่า Spark เนี่ยมันไม่รู้ว่าอะไรมันอยู่ตรงไหน

00:16:26.500 --> 00:16:29.900
อะ มันต้องมีคนคอยบอกว่าอะไรมันอยู่ตรงไหน
ซึ่งก็คือตัว Hive Metastore

00:16:29.900 --> 00:16:32.600
หรือว่าตัว Presto เนี่ย
ถ้าสมมติไปเก็บของไว้เนี่ย

00:16:32.600 --> 00:16:38.600
บางทีมันก็ไม่รู้ ก็ต้องพึ่งตัว
ตัว Hive Metastore ในการแบบว่าบอกว่า เฮ้ย อะไรมันอยู่ตรงไหนนะครับ อะ

00:16:39.300 --> 00:16:45.300
แต่ว่ามันก็ไม่ได้คิดแค่นั้นอย่างเดียว อย่างเช่น
ความสามารถในการจัดการ access control อย่างเงี้ย

00:16:45.800 --> 00:16:48.800
เอ่อ
ตัว Hive มันก็มีระดับนึง แต่ว่าคนที่จัดการจริงๆ

00:16:48.800 --> 00:16:52.900
ก็เอ็กเทนอ่านความรู้ที่ได้จากตรง Hive Metastore เนี่ยไปอยู่ในฝั่ง

00:16:52.900 --> 00:16:55.000
Apache Ranger อะไรอย่างเงี้ย หรืออย่างเช่น

00:16:55.000 --> 00:17:01.900
เอาข้อมูลใน Metastore เนี่ยไปทำ Data Lineage เนี่ย ก็ไปอยู่ในฝั่งตัว Apache Atlas นะครับ อะ

00:17:01.900 --> 00:17:07.700
อันนี้คือภาพรวมคร่าวๆ
เนาะ ซึ่งพอเรามาดูตัวก้อนของ Hive Metastore จริงๆ อะ

00:17:07.700 --> 00:17:09.800
จริงๆ คอมโพเนนต์มัน มันง่ายมากเนาะ ถ้าใคร

00:17:10.598 --> 00:17:15.300
ถ้าใครเคยเขียนเว็บมาบ้างเนาะ จะรู้จัก เอ่อ
สิ่งที่เรียกว่าอะไรนะ Three Tier Architecture เนาะ

00:17:15.300 --> 00:17:17.800
อ่า มันก็จะมีแบบเป็นดาต้าเบส เป็นแบ็คเอนด์

00:17:17.800 --> 00:17:20.300
เป็นฟรอนต์เอนด์อะไรอย่างเงี้ยที่
ที่เราคุ้นเคยกันเนาะ

00:17:20.300 --> 00:17:24.900
ตัว Hive Metastore Program จริงๆ
เนี่ยมันประกอบไปด้วยแค่ 3 ชั้นอย่างงี้เลยครับ

00:17:24.900 --> 00:17:28.000
ชั้นแรกเนี่ยก็คือตัว Metastore
Metastore Service

00:17:28.000 --> 00:17:34.000
ตัวเนี้ย สีเหลืองๆ ตัวเนี้ย
ซึ่งถูกเขียนในตัว Thrift Framework เนาะ

00:17:34.000 --> 00:17:38.400
อ่า
ซึ่งเป็น Interface อีกลูปแบบหนึ่ง ซึ่งสมัยนี้อาจจะหาคนเขียนได้ยากแล้วนะครับ

00:17:38.400 --> 00:17:42.800
เป็น Interface ไว้ให้คุยกับตัว component อื่นๆ
นะครับ แล้วก็จะมีตัวฝั่ง database

00:17:42.800 --> 00:17:48.300
ซึ่งตัวเนี้ยจะเก็บตัว metadata
อย่างที่บอกเราเก็บอะไร เราเก็บตัว table

00:17:48.900 --> 00:17:54.900
เราเก็บตัว field ว่าเอ๊ย มันมีอะไรเป็นแบบไหน
เสร็จแล้วตัวสุดท้ายที่เรามาคุยกันเนี่ยก็คือตัว

00:17:54.900 --> 00:17:57.600
client ซึ่งเอาไว้ในการ interact
กับตัว metastore

00:17:57.600 --> 00:18:00.800
service ซึ่งก็คุยผ่านตัว Thrift
protocol อีกทีนึงนะครับ อะ

00:18:01.400 --> 00:18:03.000
ดูเข้าใจง่ายๆ

00:18:03.800 --> 00:18:09.300
นะครับ
ทีนี้ถ้าเราเจาะลึกเข้าไปในตัวดาต้าเบสว่าตัว Hive Metastore เนี่ย

00:18:09.300 --> 00:18:10.900
สุดท้ายแล้วมันเก็บอะไรบ้างใน table

00:18:10.900 --> 00:18:16.900
มันมีบอกที่ทำเอาดาต้าเบสของ Hive เนี่ย มา
มาแกะตัว Schema ให้ดูเป็นแผนผังอีกทีนึง

00:18:16.900 --> 00:18:18.400
เราจะเห็น table แบบยุบยับเต็มไปหมดเลย

00:18:18.400 --> 00:18:24.300
แต่ถ้าเราอ่านชื่อมันดีๆ เนี่ยจะเริ่มเห็นว่ามันคือองค์ประกอบที่ทำให้เรามีสิ่งที่เรียกว่าตัว

00:18:24.300 --> 00:18:30.000
table กับดาต้าเบสที่เราคุ้นเคยกันได้ ยกตัวอย่างเช่น
พอเราแยกตัว metadata object ออกมาเนี่ย

00:18:31.100 --> 00:18:34.200
3 กลุ่มหลักๆ ที่เราต้องใช้ในการ Query มีอะไรบ้าง

00:18:34.200 --> 00:18:39.300
เราอยากรู้เนาะว่าตัวดาต้าเบสมีดาต้าเบสอะไรบ้าง เราอยากรู้ว่า table เนี่ย

00:18:40.000 --> 00:18:42.500
ใน table หนึ่งเนี่ยมันมีคอลัมน์อะไรบ้าง

00:18:43.100 --> 00:18:47.500
ตัวดาต้าเบสไหนเป็นเจ้าของ
Storage มันเป็นอะไร ก็คือตัว type ของ field เนาะ

00:18:47.500 --> 00:18:51.800
เสร็จแล้วตัว location ของไฟล์ของ table เหล่านั้นเนี่ยมันอยู่ที่ไหนนะครับ

00:18:51.800 --> 00:18:58.700
แล้วก็ส่วนสุดท้ายคือ partition อันนี้
อันนี้ต้องสืบย้อนกลับไปนิดนึงว่าความเป็นยุค Hadoop เนี่ย

00:18:59.600 --> 00:19:02.500
เอ่อ ตัวไฟล์อ่ะมันยังอยู่ในระดับ Hierarchy อยู่

00:19:02.500 --> 00:19:08.600
หมายความว่าเราเก็บตัวไฟล์เป็น
เป็น Hierarchy ตัวดาต้าอะไรอย่างเงี้ย แล้วการที่เราจะ access ได้เนี่ย

00:19:08.600 --> 00:19:12.200
มันก็จะผ่านชั้นตัว folder folder folder ซ้อนเข้าไปนะครับ

00:19:12.200 --> 00:19:17.400
ก็เลยต้องมีสิ่งที่เรียกว่า partition ขึ้นมาด้วย
เดี๋ยวตอนตัวอย่างอาจจะได้เห็นครับ

00:19:18.200 --> 00:19:20.900
ทีนี้ตะกี้มันเป็น abstraction เนาะ
เรามาดูตัวอย่างของจริงกันดีกว่า

00:19:21.500 --> 00:19:25.200
พอตอนสมมติเรา create table ตัวเนี้ย

00:19:25.200 --> 00:19:29.000
พอเรา
พอเราสั่ง create table อันนี้ทุกคนน่าจะคุ้นเคยตัว SQL ตัวนี้เนาะ

00:19:29.000 --> 00:19:31.200
เออ นะครับ
ถ้าทำงาน data น่าจะคุ้นเคยกันอยู่แล้ว

00:19:31.700 --> 00:19:34.600
พอเราสั่ง create table ผ่านตัว Client มันเนี่ย

00:19:34.600 --> 00:19:38.400
Client เนี่ยจะไปสั่งให้ Metastore Service เนี่ยเก็บข้อมูลลงในตัว

00:19:38.400 --> 00:19:42.400
อ่า
ดาต้าเบสแต่ละ table นะครับ ซึ่งตะกี้ก็อย่างที่เราบอกไปมันมีทั้งดาต้าเบส

00:19:42.400 --> 00:19:46.400
มีทั้งตัว table แล้วก็จะมีตัว partition เนาะ อะไรอย่างเงี้ย

00:19:46.400 --> 00:19:49.700
เก็บเป็น type ว่าโอเคมี field อะไรบ้างนะครับ

00:19:49.700 --> 00:19:57.200
ซึ่งตรงตัวไม่มีอะไร ตะกี้ผมพูดไปนิดนึงแล้วเรื่องการที่มันเก็บว่า โอเคมันเป็น

00:19:57.800 --> 00:20:00.900
เป็นชั้นตัว folder ยังไงเนาะ

00:20:00.900 --> 00:20:05.900
อ่าซึ่งเป็นชั้นๆ
อันนี้ก็เลยต้องเก็บข้อมูลลงในตัว Metastore

00:20:07.800 --> 00:20:14.600
อาจจะงงนิดนึงตรงนี้ ทีนี้ตอน Read เนี่ย ถามว่าตอน Read
Read ยังไง เนื่องจากความที่มันเก็บข้อมูลลงเป็น

00:20:14.600 --> 00:20:18.100
เป็น table directory แต่ละ table เนาะ ในตัว
ในตัวชั้น Storage ของมัน

00:20:19.000 --> 00:20:22.900
ทุกครั้งที่มันถาม Query ขึ้นมา
สิ่งที่เกิดขึ้นก็คือตัว Query Engine น่ะ

00:20:22.900 --> 00:20:26.300
ไม่ว่าจะเป็นตัว Hive เป็น Spark อะไรอย่างเงี้ย จะวิ่งไปถาม data

00:20:26.300 --> 00:20:29.500
Metastore ก่อนเสมอว่า เฮ้ย

00:20:30.200 --> 00:20:34.400
เราอยากจะ Query ตัวเนี้ย
สมมติในนี้มันเป็น Employee Tracker Coffee Log ตัวเนี้ย

00:20:34.400 --> 00:20:39.200
อยากถามว่าไอ้ table ตัวเนี้ย
มันมี field อะไรบ้าง Field นั้นมี

00:20:39.200 --> 00:20:42.500
เอ่อ มี type เป็นอะไร
Location ของไฟล์มันอยู่ที่ไหนนะ

00:20:42.500 --> 00:20:45.800
เสร็จแล้วถ้าสมมติเรา
เรา Query สมมติเราชอบ Query เป็น

00:20:45.800 --> 00:20:51.900
เป็น timestamp เนาะ ซึ่งหลายๆ
ครั้งในงาน data เราแบ่งงานเป็น partition ตัวนี้ก็จะบอกอีกว่า folder มันอยู่ตรงไหน

00:20:51.900 --> 00:20:54.900
เสร็จแล้วพอเราได้ข้อมูลจากตรงนี้มามากอะ ได้ครบแล้วเนี่ย

00:20:55.500 --> 00:21:01.300
ตัว Query Engine เนี่ยก็จะวิ่งไปอ่านตัวไฟล์แต่ละ path ซึ่งอาจจะอยู่ในตัว Object Storage หรือว่าตัว

00:21:01.300 --> 00:21:07.300
อ่า HDFS ได้นะครับ
อันนี้เป็นหลักการทำงานของมัน ซึ่ง อ่า

00:21:07.300 --> 00:21:09.200
พอถึงจุดนี้ก็รู้สึกว่ามันฟังดูดีเนาะ

00:21:09.200 --> 00:21:12.500
มันฟังดูดีว่าเออมันก็ตรงไปตรงมา
นี่แบบไปถาม ไปถามอะไรนะ

00:21:12.500 --> 00:21:16.800
ไปถามบรรณารักษ์ว่าอะไรอยู่ตรงไหนแล้วก็ อ่า
ไปหยิบของได้ของกลับมานะครับ

00:21:17.300 --> 00:21:19.800
แต่มันมี limitation ในยุคนี้อยู่นะครับ

00:21:20.300 --> 00:21:25.300
Limitation ยุคนี้ก็คือ
อย่างแรกตัว Interface ของ Metastore เองเนี่ย

00:21:25.300 --> 00:21:28.500
มันเขียนด้วย Thrift
ถามว่าในยุคนี้มีใครเขียนโปรแกรมด้วย Thrift ไหมครับ

00:21:29.300 --> 00:21:31.400
ไม่มีเนาะ ทุกคนรู้จักแต่ HTTP

00:21:31.900 --> 00:21:37.200
ทุกคนรู้จักแต่ REST Protocol ทุกคนรู้จักอะไรอาจจะ
อาจจะแรงขึ้นก็คือ gRPC

00:21:37.200 --> 00:21:41.400
อะไรอย่างเงี้ย
เพราะฉะนั้น Thrift Interface ในยุคนี้เนี่ยมันค่อนข้างจะแบบเริ่ม

00:21:41.400 --> 00:21:45.600
เริ่มจะหาคนดูแลยากและจะหาคน Extend ได้แล้วอีกจุดหนึ่งที่อาจจะเป

00:21:45.600 --> 00:21:49.300
ข้อจำกัดของตัว Hive Metastore คือ
ทุกครั้งที่มัน query อ่ะ

00:21:49.800 --> 00:21:52.400
มันต้องไปถามตัว RDBMS

00:21:52.400 --> 00:21:55.500
ทุกอย่าง ทุกอย่างยกเว้นตัว Data

00:21:55.500 --> 00:21:58.400
ทุกอย่างหมายถึงอะไร ตัว Column Definition

00:21:58.400 --> 00:22:03.500
Table อยู่ที่ไหน Location อยู่ตรงไหนอะไรอย่างเงี้ย
มันต้องไปถามตรง RDBMS

00:22:03.500 --> 00:22:06.000
ตัว Database ที่มันเป็นตัวเก็บ Metadata โหลดหนักมาก

00:22:06.000 --> 00:22:09.200
ซึ่งถ้าสมมติเราต้อง query เยอะๆ หรือกับเราอยากสแกนด้วยว่า

00:22:09.200 --> 00:22:12.700
เฮ้ย
ทั้งหมดเนี่ยมันมีเก็บข้อมูลอยู่เท่าไหร่เนี่ย

00:22:12.700 --> 00:22:18.600
ตัว Database ตัวเนี้ยไม่ว่าจะสเกลเท่าไหร่มันก็จะเริ่มเหนื่อยมากจนเริ่มจะเป็นคอขวดในระบบนะครับ

00:22:18.600 --> 00:22:24.200
แล้วก็จริงๆ แล้วตัว Thrift API เนี่ยมันสามารถต่อตรงได้ซึ่งอาจจะไม่ค่อยปลอดภัยเท่าไหร่เนาะอันนี้

00:22:26.000 --> 00:22:30.800
ทีนี้เนี่ยพอเห็นว่าไอ้ Metadata เนี่ยมันเหนื่อยมากๆ เนาะ เออ

00:22:31.500 --> 00:22:34.800
Netflix ก็เลยบอกว่า โอเค เรา
เราจะไม่อยู่กับมันละ เรา

00:22:34.800 --> 00:22:39.100
เราอยู่กับมันมานานพอละ เราจะแก้ปัญหามัน
มันก็เลยรู้จักสิ่งที่เรียกว่า เอ้ย

00:22:39.100 --> 00:22:41.800
มันก็เลยเกิดสิ่งที่เรียกว่า open table format

00:22:41.800 --> 00:22:49.500
ซึ่งหนึ่งในตัวที่เกิดขึ้นมาใน Netflix ก็คือ Iceberg
ครับในนี้มีใครไม่รู้จัก Iceberg ไหมครับ

00:22:50.300 --> 00:22:52.200
โอเค แปลว่าส่วนใหญ่รู้จักนะครับ

00:22:52.200 --> 00:22:54.100
ไม่แปลกใจเพราะนี่มันงาน Data Engineer เนาะ

00:22:54.100 --> 00:22:56.900
เออ (หัวเราะ)
เราไม่รู้จัก Iceberg ก็อาจจะแปลกๆ หน่อยครับ

00:22:56.900 --> 00:23:01.700
ตัวในยุค Iceberg เนี่ยถ้าเราไปเสิร์ชตัว Architecture มันจริงๆ เนี่ย

00:23:01.700 --> 00:23:06.800
มันจะเริ่มต่างจาก Hive แล้ว
พอเรามองดูเนี่ยไอ้สิ่งที่มันชูโรงมาเป็นแถวแรกสุดเลยอะ

00:23:07.400 --> 00:23:13.500
คือสิ่งที่เรียกว่า Iceberg Catalog นะครับ
ตามด้วยตัว Metadata Layer และตัว Data Layer

00:23:14.000 --> 00:23:15.100
นะครับ อ่า

00:23:16.000 --> 00:23:17.400
เดี๋ยวเรามาเจาะดูทีละตัวกัน

00:23:18.500 --> 00:23:19.700
ตัว Iceberg Catalog เนี่ย

00:23:20.600 --> 00:23:24.700
ถ้าเรามองดูเนาะ เฮ้ย มันก็ต่างจากมัน
มันก็เหมือน Hive Metastore เนาะ

00:23:24.700 --> 00:23:26.400
แต่ถ้าเราดูในอินดีเทลจริงๆ เนี่ย

00:23:27.100 --> 00:23:29.800
ตัวเนี้ยมันจะลดโหลดบางอย่าง

00:23:30.600 --> 00:23:34.800
สิ่งที่มันเก็บเนี่ยมันจะเก็บแค่ Metadata pointer

00:23:34.800 --> 00:23:39.500
หมายความว่าอะไร
หมายความว่าแทนที่จะเก็บตัว Table Definition ทั้งหมด อย่างเช่น เรา

00:23:39.500 --> 00:23:42.700
Table เราเนี่ยมี DDL เอ่อ
มีฟิลด์หน้าตาแบบไหน

00:23:42.700 --> 00:23:45.100
มีคอลัมน์อะไรบ้างอย่างเงี้ยเก็บใน Iceberg Catalog

00:23:45.100 --> 00:23:49.800
ไม่
Iceberg Catalog บอกว่าเราเก็บแค่ Location ของมันนะครับ

00:23:49.800 --> 00:23:56.600
เสร็จแล้วพอเรารู้ Location ของตัว Metadata เนี่ยในเลเวลที่สองเนี่ย ตัว Metadata เก็บอะไร

00:23:56.600 --> 00:24:03.100
ตัว Metadata เก็บรายละเอียดของ Table ตรงนั้นทั้งหมด
รายละเอียดนั้นมีอะไรบ้าง รายละเอียดนั้นคือ

00:24:03.100 --> 00:24:09.400
เรามีไฟล์เก็บผ่านอยู่ที่ไหน
เรามี Schema หน้าตาเป็นยังไงบ้างอะไรอย่างเงี้ย

00:24:09.400 --> 00:24:14.500
ไอ้รายละเอียดที่เราเคยเก็บอยู่ในตัว Hive
Metastore เนี่ย มันถูก offload

00:24:14.500 --> 00:24:19.000
ออกมาอยู่ในตัว Metadata Layer ซึ่ง อ่า

00:24:19.700 --> 00:24:23.200
พอมัน offload ตรงนี้เนี่ย การสเกล
การสเกลตัว อ่า

00:24:23.900 --> 00:24:29.300
ความสามารถของไฟล์ ความสามารถของการทำ Schema Evolution
อย่างเงี้ย มันเกิดขึ้นได้ง่ายขึ้นแล้ว Core

00:24:29.300 --> 00:24:33.000
Code มันไม่ได้อยู่ที่ตัว Hive Metastore
หรือตัว Database ของมันอีกแล้วนะครับ

00:24:33.000 --> 00:24:38.800
ส่วนสุดท้ายเนี่ยก็คือตัว Data File
ซึ่งจะมีสิ่งที่เรียกว่า Manifest File เป็นตัวประกบไว้เนาะ

00:24:38.800 --> 00:24:45.800
ตัวเนี้ยก็จะเป็นตัวคอยบอกย่อยอีกทีนึงว่าตัว Data File
เราเนี่ย Type มันเป็นอะไร อ่า นะครับ

00:24:45.800 --> 00:24:49.900
ซึ่งพอมาดูตัว Iceberg เนี่ย Iceberg

00:24:49.900 --> 00:24:54.400
จริงๆ แล้วตัว Catalog มีหลายตัว แต่ตัวหนึ่งที่
Iceberg ชูขึ้นมาก็คือสิ่งที่เรียกว่า

00:24:54.400 --> 00:24:58.800
Iceberg REST Catalog นะครับ Iceberg REST Catalog
เนี่ยมันเป็นเหมือน standard ที่

00:24:58.800 --> 00:25:02.800
Iceberg
สร้างขึ้นมาว่าการจะทำ Catalog เนี่ยในการคุยกับตัว Iceberg Table เนี่ย

00:25:03.400 --> 00:25:06.900
มันต้องคุยกันด้วย อ่า ฟอร์แมตอะไรบ้างนะครับ

00:25:06.900 --> 00:25:10.000
ซึ่งคอมโพเนนต์ ถ้าเรา
ถ้าเราคุ้นเคยกับภาพตัว Hive Metastore ตะกี้เนาะ

00:25:10.600 --> 00:25:14.500
หน้าตามันก็จะมาแนวเดียวกันเลยก็คือตัว Iceberg

00:25:14.500 --> 00:25:20.300
Catalog ซึ่งตะกี้เราพูดถึงว่า Thrift มันมีปัญหาเนาะใน
Hive Metastore Iceberg บอกว่า Iceberg

00:25:20.300 --> 00:25:24.100
ลองไปใช้ที่ Thrift
เราจะใช้อะไรที่คนเขาเอาไว้ implement ง่ายๆ

00:25:24.100 --> 00:25:29.200
เพราะฉะนั้นก็เลยเกิดสิ่งที่เรียกว่า REST Catalog
Specification ขึ้นมานะครับ แล้วก็คุยกันผ่านตัว

00:25:29.700 --> 00:25:33.600
HTTP Service ที่ อ่า
ทุกคนอาจจะเข้าใจกันอยู่แล้ว

00:25:34.100 --> 00:25:34.200
อะ

00:25:34.800 --> 00:25:38.300
แล้วก็ยังมีมรดกตกทอดออกมาอยู่ก็คือ

00:25:38.300 --> 00:25:43.800
อ่า
เราจะต้องเก็บข้อมูลตัวบางอย่างอยู่ในตัว Database ของตัว Iceberg REST Catalog

00:25:43.800 --> 00:25:49.700
ซึ่งเดี๋ยวเราไปลงดีเทลต่อไปนะครับ
แล้วก็มีตัว Client ที่คุยกันผ่านตัว REST Interface

00:25:49.700 --> 00:25:52.000
ไปที่ Iceberg REST Catalog เนาะ อ่า

00:25:53.500 --> 00:25:55.300
ตะกี้เราพูดถึงอันนี้ไปนิดนึงแล้วก็คือ

00:25:55.300 --> 00:26:01.700
แทนที่เราจะเป็นสเปคของ Thrift ซึ่งค่อนข้างจะแบบล็อก vendor มากแล้วเราไม่รู้ว่าเฮ้ยข้างในมันมีอะไรมีอะไรบ้างนะ

00:26:01.700 --> 00:26:04.000
ตัว Iceberg บอกว่า Iceberg เราทำ REST Catalog

00:26:04.000 --> 00:26:07.200
specification ให้
แล้วก็ถ้าใครอยากทำตัว Connector

00:26:07.200 --> 00:26:10.200
เอ้ยทำตัว Catalog เนี่ยก็
implement ตามนี้เลยนะครับ

00:26:10.200 --> 00:26:15.200
ซึ่งถ้าใครเป็นโปรแกรมเมอร์แล้วอ่าน Specification
เป็นก็จะรู้ว่าโอเคมันมีแค่ input output

00:26:15.200 --> 00:26:18.200
ที่เราแค่ต้องเสิร์ฟออกมาตาม specification

00:26:18.200 --> 00:26:22.300
ส่วนเราจะเป็น implement ด้วยภาษาอะไรเป็น
Python เป็น Rust เป็นอะไรก็แล้วแต่

00:26:23.100 --> 00:26:27.800
ก็แค่ทำตามนี้ก็พอนะครับ อีกจุดหนึ่งที่น่าสนใจของตัว

00:26:27.800 --> 00:26:30.500
Iceberg Catalog ก็คือตัว Metadata
Object อย่างที่บอก

00:26:31.000 --> 00:26:35.000
ถ้าเราย้อนกลับไปดูภาพ ภาพแรกตรงนี้เนาะ
Iceberg Catalog เนี่ย

00:26:36.000 --> 00:26:38.900
ตรงนี้มันบอกว่าเราเก็บแค่ Metadata Pointer

00:26:38.900 --> 00:26:44.600
หมายความว่ายังไง พอเราไปดูตัวสกีมาจริงๆ
ที่ตัวดาต้าเบสของตัว Iceberg Catalog มันเก็บไว้อะ

00:26:45.200 --> 00:26:47.200
สิ่งที่มันสนใจมันสนใจแค่ 2 อย่างเองก็คือ

00:26:47.900 --> 00:26:52.800
มันมี namespace อะไรบ้าง
Namespace เนี่ยในภาษาที่เราเข้าใจกันก็คือดาต้าเบสเนาะ อ่า

00:26:52.800 --> 00:26:59.000
อีกตัวหนึ่งที่เราสนใจเนี่ยก็คือตัว Iceberg Table
ก็คือตัว Table จริงๆ ซึ่งตัว Table เนี้ย

00:26:59.900 --> 00:27:04.000
เราสนใจแค่ว่ามันอยู่กับ namespace ไหน อ่า ชื่ออะไร

00:27:04.600 --> 00:27:10.300
แล้วสิ่งที่สนใจจริงๆ คือ
Metadata file มันน่ะอยู่ที่ไหนนะครับ ซึ่งอาจจะเป็นผ่านใน

00:27:10.300 --> 00:27:15.900
HDFS ผ่านใน S3 ผ่านใน Google
Storage อะไรอย่างเงี้ยก็ว่าไปนะครับ

00:27:17.600 --> 00:27:20.200
ทีนี้มาดูเทียบกันว่าจังหวะการเขียนเป็นยังไง

00:27:20.900 --> 00:27:24.900
จังหวะการเขียนสมมุติเราสร้าง create table คล้ายๆ
กับตอนที่เราทำ Hive Metastore ตะกี้เนาะ

00:27:26.000 --> 00:27:32.800
พอมันเขียนเนี่ยสิ่งที่มันเซฟลงในตัวดาต้าเบสมันเซฟแค่ว่า โอเค เราเกิด DB Table หนึ่งนะ

00:27:32.800 --> 00:27:39.800
DB Table หนึ่งมีการมี Metadata file อ่ะอยู่ที่นี่
อยู่ที่อาจจะเป็น VOS-- เอ่อ อาจจะเป

00:27:40.500 --> 00:27:43.200
S3 แล้วก็เป็น path something อะไรอย่างเงี้ย

00:27:43.200 --> 00:27:50.300
แล้วก็เป็นไฟล์ .json ที่เราอาจจะไป inspect ได้นะครับ เสร็จแล้วมันก็จะสร้างตัวโฟลเดอร์ขึ้นมาในตัว object storage จริงๆ

00:27:50.300 --> 00:27:59.000
แล้วก็เกิดตัว Metadata file ขึ้นมาเป็นเวอร์ชันแรกนะครับ ซึ่งตัว Iceberg Catalog มันพอยต์ไปอยู่นะครับ อ่านี่คือการ create table เนาะ

00:27:59.000 --> 00:28:00.700
ทีนี้จังหวะที่มัน read บ้างล่ะ

00:28:01.600 --> 00:28:06.500
จังหวะที่มัน read สมมติเรามีดาต้าแล้วเนี่ย
สิ่งที่เกิดขึ้นตามจังหวะก็คือ โอเค

00:28:06.500 --> 00:28:09.800
ตัว Client เนี่ยวิ่งไปถามตัว Iceberg Catalog มันว่า Table นี้

00:28:10.700 --> 00:28:12.500
อ่า Metadata file มันอยู่ที่ไหนนะ

00:28:12.500 --> 00:28:16.700
มันก็จะจิ้มไปว่าโอเคอยู่ที่ Metadata นะ
เสร็จแล้วพอวิ่งไปที่ Metadata ปุ๊บ

00:28:16.700 --> 00:28:21.200
Metadata ก็จะบอกว่าตัว manifest file ของตัว Data file เราอยู่ที่ไหน

00:28:21.200 --> 00:28:27.600
มันก็จะวิ่งไปตามขั้น
ถามว่าภาพนี้มันดูเหมือนไม่มีอะไร แต่จริงๆ แล้วสิ่งที่เกิดขึ้นน่ะ

00:28:27.600 --> 00:28:30.900
ไอ้ตัวโหลดใน system ของ Iceberg Catalog ตรงนี้มันน้อยมาก

00:28:30.900 --> 00:28:33.900
สิ่งที่มันถามก็แค่ถามว่าอะไรมันอยู่ตรงไหน แบบจุดจุดเดียว

00:28:34.700 --> 00:28:38.100
รายละเอียดของ Table เช่น
เรารู้ว่าคอลัมน์มันอยู่ที่ไหน

00:28:38.100 --> 00:28:40.400
Location ของตัว Data file อยู่ตรงไหนอย่างเงี้ย

00:28:40.400 --> 00:28:45.700
รวมถึงเวอร์ชันของดาต้ามันถูกออฟโหลดไปอยู่ข้างๆ
ใน Metadata layer หมดเลยนะครับ

00:28:45.700 --> 00:28:50.900
นี่คือ
นี่คือวิวัฒนาการที่เกิดจากยุค Hive Metastore ขึ้นมาเป็น Iceberg Catalog อ่า

00:28:52.100 --> 00:28:58.100
ครับซึ่งตัว advantage เมื่อกี้ผมน่าจะเล่าไปหมดแล้ว ผมขอข้ามแล้วกันนะครับ ตึ๊งตึ๊ง

00:28:59.400 --> 00:29:03.600
พูดถึงอนาคตบ้างซึ่งตะกี้ทุกคนจะเริ่มเข้าใจแล้วว่าจริงๆ

00:29:03.600 --> 00:29:07.100
แล้วตัว
ตัว Catalog เนี่ยมันก็เริ่มพอจะทำงานยังไงเนาะ อ่า

00:29:08.700 --> 00:29:13.700
ทีนี้เนี่ยพอ Catalog มันทำงานพื้นฐานได้ละ คนก็เริ่มแบบว่า โอ๊ย

00:29:13.700 --> 00:29:15.500
มันก็ไม่ได้ซับซ้อนขนาดนั้นนี่หว่า เรา

00:29:16.000 --> 00:29:22.000
เราเริ่มจะมียูสเคสว่าเอามันไปใช้กับอะไรบ้างดีนะครับ ถ้าเราตามเทรนด์ใน

00:29:22.000 --> 00:29:24.700
ในตัว Data Engineering community มาสักพักเนาะ

00:29:24.700 --> 00:29:27.300
เราจะเริ่มเห็นว่าตัว Open Table Format

00:29:27.300 --> 00:29:32.000
เนี่ยมันค่อนข้างจะ dominate ช่วงนี้หนักมากนะครับ
เราทุกคนต้องปรับตัวอยู่กับมันนะครับ

00:29:32.700 --> 00:29:39.000
เทรนด์แรกเกี่ยวกับ Data Catalog
ที่อยากจะให้รู้ก็คือมันจะเริ่มเกิดสิ่งที่เรียกว่า

00:29:39.000 --> 00:29:42.000
Format Agnostic Catalog Format
Agnostic คืออะไร

00:29:42.000 --> 00:29:47.300
อ่า ในช่วงที่เราดูตรงเนี้ย
มันจะมีบางตัวที่บอกมันว่า

00:29:47.300 --> 00:29:52.200
เคเราชอบทำงานกับไฟล์ format นี้
เราชอบทำงานกับไฟล์ format นี้ที่อยู่ใน Data Lakehouse

00:29:52.200 --> 00:29:58.500
แต่ทุกคนก็รู้ว่าหลายรี--
หลาย need ในปัจจุบันมันก็มี requirement แต่ละทีมไม่เหมือนกันเนาะ

00:29:58.500 --> 00:30:00.600
ทีมนี้อยากได้ อ่า performance ดีๆ

00:30:00.600 --> 00:30:04.800
ในการ query ข้อมูล
ทีมนี้อยากได้แค่แบบเป็นทำ multiply struct อะไรอย่างเงี้ย

00:30:04.800 --> 00:30:11.200
ซึ่งพอ requirement need มันไม่เหมือนกันเนี่ย มันก็เลยเกิด
อ่า ตัว Catalog เกิด Open Fa-- เอ่อ

00:30:11.200 --> 00:30:13.300
Open Format ขึ้นมาหลายๆ ไฟล์นะครับ

00:30:13.300 --> 00:30:14.500
ซึ่งไอ้ format

00:30:14.500 --> 00:30:14.900
Agnostic

00:30:14.900 --> 00:30:21.800
ตัวนี้มันเข้ามาแก้ปัญหาในจุดนี้ก็คือแทนที่เราจะมี 1 Catalog ต่อ 1 ไฟล์ Open Format type เนี่ย

00:30:22.300 --> 00:30:25.400
เรามี Catalog ตัวนี้ที่มัน interop กับตัว

00:30:26.000 --> 00:30:31.300
ตัวไฟล์ type หลายหลายแบบได้เลยนะครับ ซึ่งเพื่อให้มั่นใจได้ว่าเรามี

00:30:31.800 --> 00:30:33.600
เรามีอะไรนะ ไฟล์ format ที่เหมาะสมกับแต่ละ

00:30:33.600 --> 00:30:33.800
use

00:30:33.800 --> 00:30:34.100
case

00:30:34.100 --> 00:30:35.000
แล้วก็ตัว

00:30:35.000 --> 00:30:40.300
specification
ค่อนข้างจะเปิดกว้างเพื่อจะให้เรา extend มากยิ่งขึ้นนะครับ ซึ่งตัวอย่างของตัว

00:30:41.100 --> 00:30:44.300
อ่า Format Agnostic Catalog
ตัวนี้ก็คือตัว Unity Catalog เนาะ

00:30:44.300 --> 00:30:48.500
ซึ่งตอนนี้ support หลากหลายมากกับตัวอย่างเช่น อาเช่ กาวิททีโน

00:30:48.500 --> 00:30:54.700
หรือว่าตัว XTable
เองก็น่าจะกำลังคิดอยู่ตรงนี้อยู่ว่าเป็นตัว Catalog ที่ support ในการ inter

00:30:54.700 --> 00:30:59.400
interprocess ตัว Open Table Format
นะครับอีกกลุ่มหนึ่งนะครับ

00:31:00.400 --> 00:31:04.300
เอ่อ ประมาณช่วงเดือนที่แล้วผม
ผมไปเจอบทความความหนึ่งชื่อว่า

00:31:05.000 --> 00:31:09.800
Rise of Single Node Processing นะครับ มัน
มันพูดถึงเทรนด์ในช่วงนี้ว่า เฮ้ยทำงาน Data Engineer

00:31:09.800 --> 00:31:12.500
เรา เราไม่ค่อยอยากจะ เขาเรียกอะไรนะ

00:31:12.500 --> 00:31:18.400
setup ตัว cluster ในการประมวลผลขึ้นมาเยอะแล้ว เพราะเทคโนโลยีในการ computer engine เนี่ยมัน

00:31:18.400 --> 00:31:20.400
มันดีขึ้นมากแล้ว ยกตัวอย่างเช่น ไอ้

00:31:20.900 --> 00:31:24.100
MacBook ตัวนี้ เอาจริงๆ มันก็แรงเนาะ ถูกไหม

00:31:24.100 --> 00:31:26.600
มัน มันไม่เหมือนคอมสมัยก่อนที่แบบแรม 4 GB

00:31:26.600 --> 00:31:30.600
ซีพียูแบบกระจิ๋วหลิว อะไรอย่างเงี้ย
แล้วเราประมวลผลดาต้า ไม่ได้

00:31:30.600 --> 00:31:37.800
คอมสมัยนี้มันแรงพอที่เราจะทำอะไรในเครื่องได้แล้วมันก็เลยเกิด Turing ที่ทำให้เราประมวลผลในเครื่องได้ที่เป็น Single Processor อย่างเช่นตัว

00:31:37.800 --> 00:31:41.700
DuckDB
หรือตัว Apache Arrow หรือตัว Polars อย่างเงี้ย

00:31:41.700 --> 00:31:52.500
อ่า ซึ่งพอเกิด movement ตัวนี้ขึ้นมา สิ่งที่เกิดขึ้นคือความเป็นแค็ตตาล็อกอะ แทนที่เราจะต้อง maintain เป็น component แยกอะ มันจะเริ่ม shift ไปหาฝั่งที่เป็น Processor มากขึ้น

00:31:52.500 --> 00:31:59.400
ก็คือให้มันอยู่ในเครื่องนี้เลย โดยการ pre-load ตัว อ่า แค็ตตาล็อกหรือ knowledge ในการ accessing ดาต้าเข้าไปนะครับ

00:31:59.400 --> 00:32:04.600
ซึ่งมันก็ช่วยลดความซับซ้อนในการ maintain component หลายๆ component ที่อยู่ใน Cloud Data Platform มากขึ้น

00:32:04.600 --> 00:32:10.300
แต่อย่างที่บอก พอเราออฟโหลดสิ่งเนี้ยเข้าไปอยู่ในฝั่ง User มากขึ้นเนี่ย การจัดการตัว

00:32:10.300 --> 00:32:12.200
access control หรือว่าแบบ security

00:32:12.200 --> 00:32:17.900
อะไรอย่างเงี้ย มันก็เริ่มมีความ challenge อยู่นะครับ ตัวนี้เป็น เป็นเทรนด์อีกเทรนด์หนึ่งที่กำลังมาของแค็ตตาล็อก

00:32:17.900 --> 00:32:22.800
เทรนด์สุดท้ายที่อยากจะพูดถึงครับ ก็คือตัว
Orchestrator Integrate นะครับ

00:32:23.400 --> 00:32:26.700
คือถ้าเรามองในมุม Data Platform เนาะ

00:32:26.700 --> 00:32:31.200
ทุกคนเนี่ยอยากทำงาน
ตะกี้พี่กานต์พูดถึงว่า ถ้าอยากให้มันทำงานซ้ำๆ มันก็ต้องมี Cron เนาะ

00:32:31.900 --> 00:32:35.900
แต่ถ้างงานในดาต้าจริงๆ
เราก็จะมี Orchestrator เนาะ Airflow หรือนู่นนั่นนี่

00:32:35.900 --> 00:32:39.900
หรือที่เราใช้กันนะครับ ซึ่งตัว Orchestrator

00:32:39.900 --> 00:32:42.700
เนี่ยก็เริ่มมี movement เหมือนกัน
แทนที่เราจะทำงานเป็น

00:32:42.700 --> 00:32:45.600
เป็นนักค้าแบบว่า ทำ A ไป B ไป C อะไรอย่างเงี้ย

00:32:45.600 --> 00:32:50.400
เราจะเริ่มมองทำงานกับดาต้าในมุมของสิ่งที่เรียกว่า Asset มากยิ่งขึ้นนะครับ

00:32:50.400 --> 00:32:55.000
ซึ่งทั้งๆ ที่ตัว Orchestrator
มันรู้อยู่แล้วว่ามันจะคุยกับใครอะไรยังไงอ่ะ

00:32:55.000 --> 00:32:58.900
มันก็ยกระดับตัวเองขึ้นมาว่า เฮ้ย
เรากุมความรู้ของแค็ตตาล็อกตัวนี้ไว้ด้วยนะ

00:32:58.900 --> 00:33:01.000
อยากรู้อะไรว่าอะไรมันเชื่อมกับอะไรตรงไหนเนี่ย

00:33:01.000 --> 00:33:04.400
มาดูที่เรานะครับ ถามว่าทำอย่างงี้แล้วมันดียังไง

00:33:05.500 --> 00:33:09.900
ดาต้าแค็ตตาล็อกส่วนใหญ่เนี่ย มันจะแยก component
ออกไปเป็นต่างหากตัวหนึ่งเนาะ

00:33:09.900 --> 00:33:15.700
แล้วต้องการที่จะทำให้มันมี value
ขึ้นมา เราต้องทำการส่งดาต้าให้มัน อาจจะจะเป็นการ

00:33:15.700 --> 00:33:21.100
push model หรือ pull model ก็ได้
แต่การที่เรา move ตัวแค็ตตาล็อกตัวนี้มาอยู่ในตัว Orchestrator

00:33:21.100 --> 00:33:22.500
ซึ่งทุกคนต้องทำงานกับมันอยู่แล้วอ่ะ

00:33:23.000 --> 00:33:27.200
มันทำให้ความรู้อยู่ตรงเนี้ย
แล้วการเกิดขึ้นของดาต้า

00:33:27.200 --> 00:33:31.900
ดาต้าควอลิตี้เป็นยังไงอย่างเงี้ย
มันถูกจัดการอยู่ในตัว Orchestrator ทีเดียวเลยนะครับ

00:33:31.900 --> 00:33:38.600
ซึ่งมันก็ลดความซับซ้อนไว้อีกเนาะนะครับ
ซึ่งถามว่าตัวเนี้ย ถามว่าเกิดขึ้นมากแค่ไหน เอ่อ

00:33:38.600 --> 00:33:41.000
ผมไม่รู้ ผมไม่รู้ Orchestrator ตัวอื่นเนาะ

00:33:41.000 --> 00:33:45.500
แต่ตัวอย่าง Dagster หรืออย่างเช่นตัว Airflow ที่ทุกคนใช้กันเนี่ย

00:33:45.500 --> 00:33:47.300
Dagster ก็จะมีสิ่งที่เรียกว่า Asset เนาะ

00:33:47.300 --> 00:33:50.300
ตัว Airflow ก็จะมีสิ่งที่เรียกว่า Asset ตัวเนี้ยเป็นตัว drive ตัว

00:33:50.300 --> 00:33:54.900
movement
นี้ขึ้นมาว่า โอเค เราย้ายแค็ตตาล็อกมาอยู่ที่ฝั่งของ Orchestrator

00:33:54.900 --> 00:34:00.800
นะครับ อ่ะ ทีนี้จริงๆ
ของเกินเวลา ขออภัยนะครับ (หัวเราะ)

00:34:01.800 --> 00:34:05.500
จริงๆ
อ่ะ ที่ผมยกตัวอย่างเมื่อตะกี้ มัน มันยังไม่หมดของแค็ตตาล็อกเลยครับ

00:34:05.500 --> 00:34:10.300
มันเป็นแค่ตัวคอร์ความสามารถของแค็ตตาล็อกเลยว่าอะไรมันอะไรอยู่ตรงไหนนะครับ จริงๆ

00:34:10.300 --> 00:34:14.000
มันมีเรื่องอีกเยอะมากที่ไม่ได้พูดถึงซึ่ง

00:34:14.000 --> 00:34:24.300
เอ่อ ก็หวังว่าอันนี้อาจจะเป็นจุดเริ่มต้นที่ ที่คนเราไป เขาเรียกไปมองมุม มุมแค็ตตาล็อกตัวนี้มากยิ่งขึ้นว่ามันควรจะทำอะไรได้ ทำอะไรไม่ได้นะครับ

00:34:24.300 --> 00:34:31.100
แล้วก็สิ่งที่อยากจะฝากไว้อันสุดท้ายของทอล์คนี้คือ คือตัว ตัว ตัว Data Catalog เนี่ย

00:34:31.900 --> 00:34:35.000
ถ้าสมมุติเราอยู่ในบริษัทเนาะ ลอง ลองคิดภาพตัวบริษัท

00:34:35.000 --> 00:34:40.400
บริษัทเนี่ย เวลาเราเข้าไปเนี่ย ให้มองดูว่าตัว Adoption ของดาต้าเราเป็นเลเวลไหน

00:34:40.400 --> 00:34:47.199
อะ บริษัทเราเป็น Brownfield หรือเปล่า ที่มีการทำ Governance หนักมาก มีทุกอย่างพร้อม มี Processing เรียบร้อยแล้ว

00:34:47.199 --> 00:34:56.100
หรือว่าเราเข้าไปเป็น Data Engineer คนแรกที่อยู่ในบริษัท แล้วเราไม่รู้ว่าจะทำอะไรยังไงขึ้นมา อะไรอย่างเงี้ยนะครับ ความรู้ที่เรามีในการทำแค็ตตาล็อกตัวเนี้ย

00:34:57.600 --> 00:35:01.900
ในวันนี้ที่ผมเล่าไปเนี่ย มัน serve สอง
สองคน สองคน สองกลุ่มเนี้ยต่างกัน

00:35:02.400 --> 00:35:06.300
อ่า อย่างเช่นสมมุติเราอยู่ในโลกที่มัน Brownfield มากเนาะ

00:35:06.300 --> 00:35:08.700
เออ เรามี Governance หนักมาก เรามีนู่นนั่นนี่หนักมาก

00:35:08.700 --> 00:35:14.600
ถามว่าถ้าสมมุติ Governance เราเริ่มช้า หรือตัว Data Catalog ของ ของตัวหลักเรามันเริ่มโหลดมากๆ

00:35:14.600 --> 00:35:18.900
อย่างเงี้ย
เราจะทำยังไงให้มันเร็วขึ้นในสภาวะที่องค์กรมันใหญ่มากๆ อย่างเงี้ย

00:35:18.900 --> 00:35:23.100
การที่เรารู้ว่าแค็ตตาล็อกมันทำงานยังไง หรือว่าเราจะเลือกใช้ สร้างมันยังไงอย่างเงี้ย

00:35:23.700 --> 00:35:25.200
ตัวเนี้ยจะทำให้มัน essential ยิ่งขึ้น

00:35:26.500 --> 00:35:28.900
หรืออย่างเช่นถ้าอยู่ใน Greenfield อย่างเงี้ย

00:35:28.900 --> 00:35:32.400
โอเค เราไม่รู้อะไรเลย เราเป็น Data Engineer คนแรกในบริษัท เราจะทำยังไง

00:35:32.400 --> 00:35:37.300
การที่เรารู้จักแค็ตตาล็อกเนี่ย มันทำให้รู้ว่า โอเค จุดเริ่มต้นที่ Data Citizen เลเวลแรก

00:35:37.300 --> 00:35:42.800
เลเวลแรกคือใคร
คือ Engineer ที่เราทำงานด้วยเนี่ย เขาจะใช้ดาต้ายังไงเนี่ย มันจะมีประโยชน์ยังไงบ้างนะครับ

00:35:42.800 --> 00:35:45.400
นอกจากที่เราจะรู้ว่าเราจะเลือก Compute Engine ยังไง

00:35:45.400 --> 00:35:51.800
เราจะเลือก Storage ตัวไหนนะครับ ตัวนี้ก็น่าจะหวังว่าจะช่วยให้ อ่า กลุ่มคนที่อยู่ในสองโลกนี้เนาะ

00:35:51.800 --> 00:35:53.800
เข้าใจ เข้าใจกับ Data Catalog มากยิ่งขึ้น

00:35:54.500 --> 00:35:56.800
ครับผม ประมาณนี้ครับ ขอบคุณครับ

00:35:56.800 --> 00:35:59.100
ขอเสียงปรบมือให้พี่แมนหน่อยค่ะ

00:35:59.800 --> 00:36:02.900
(เสียงปรบมือ) ขอบคุณพี่แมนมากๆ นะคะ
