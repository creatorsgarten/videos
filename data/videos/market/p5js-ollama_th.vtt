WEBVTT

00:00:00.100 --> 00:00:02.600
ทอล์กสุดท้ายเป็นเรื่องเกี่ยวกับ P5

00:00:02.600 --> 00:00:10.300
JS กับ Ollama นะฮะ ก็ทำ Drawing Game ด้วย P5
JS และ Ollama, ขอเสียงปรบมือให้โบ๊ทด้วยฮะ

00:00:10.300 --> 00:00:12.600
(เสียงปรบมือ)

00:00:12.600 --> 00:00:13.900
ครับ ก็ (กระแอม)

00:00:14.700 --> 00:00:29.100
ขออภัยด้วยนะครับ เพราะว่าวันนี้เสียงอาจจะไม่ได้มี เพราะว่าได้รับฝุ่นเยอะมากครับ ก็สวัสดี ผู้ชมในห้องนะครับ แล้วก็อาจจะมีไปดูใน--

00:00:29.100 --> 00:00:33.800
ในคลิปย้อนหลังใน YouTube
นะครับ ก็ยินดีต้อนรับเข้าสู่ Section

00:00:33.800 --> 00:00:43.600
AI Guessing Image Game
นะครับ ก็ทำเป็นเล็กๆ น้อยๆ ครับ ผมเองก็ ไม่ค่อยมีความครีเอทีฟมากเท่าไหร่ แต่ว่า เราเองเราได้แบบ

00:00:43.600 --> 00:00:53.400
inspiration
จากตอนที่เรายังเป็นเด็กเนาะ แบบว่าเวลาเราเล่นเกมทายภาพ ก็คือเราวาดภาพแล้วก็ทายกับเพื่อนอะไรประมาณนี้ครับ ก็จริงๆ text ของเราที่เราจะใช้เนี่ย ก็น่าจะเป็นตัว p5.js นะครับ แล้วก็ในฝั่งของ Ollama

00:00:53.400 --> 00:00:58.800
text ของเราที่เราจะใช้เนี่ย ก็น่าจะเป็นตัว p5.js
js นะครับแล้วก็ในฝั่งของ Ollama

00:00:58.800 --> 00:01:06.800
นะครับ เดี๋ยวเรามาดูกันว่ามันจะเป็นยังไงนะครับ ก่อนอื่นก็ขอแนะนำตัวกันก่อนนะครับ ชื่อ โป๊ดนะครับ

00:01:06.800 --> 00:01:08.400
ชรันธร ลิ้มสีโลครับ ตอนนี้เป็น

00:01:09.000 --> 00:01:13.100
Microsoft Student and Master
ครับ ก็เป็น student

00:01:13.800 --> 00:01:16.900
tech lead ของประเทศไทยครับ แล้วก็ ตอนนี้ก็

00:01:16.900 --> 00:01:20.000
intern อยู่ที่ เซเว่นพีช ในตำแหน่งของ Data

00:01:20.000 --> 00:01:28.400
Engineer
นะครับ คราวนี้เนี่ย คือหลังๆ มานี้ผมเองก็จะทำในเรื่องของพวก small language

00:01:28.400 --> 00:01:32.000
model มากขึ้น แล้วก็ มาทำพวก possibility

00:01:32.000 --> 00:01:34.500
possibility ต่างๆ อย่างเป็นพวก multimodal

00:01:34.500 --> 00:01:36.200
หรือว่าจะเป็นในเรื่องของ listening

00:01:36.200 --> 00:01:41.700
นะครับ ซึ่งในเคสวันเนี้ย อาจจะ Bring ในตัวของ
multimodal มาเล่นกันนะครับ

00:01:42.300 --> 00:01:45.500
คอนเทนต์หลักๆ เนี่ย ก็เราจะมาพูดในตัวของ

00:01:46.100 --> 00:01:48.000
work inspiration ที่ผมได้มานะครับ

00:01:48.000 --> 00:01:57.000
แล้วก็ ผมก็จะเล่าว่า ในกลไกต่างๆ เนี่ย ที่เกิดขึ้น ในตัวที่ผมจะเดโม่ตัวนี้

00:01:57.000 --> 00:02:03.900
มันมีกลไกยังไงบ้างนะครับ
แล้วก็ มี Demo เนี่ย จะให้ลองเล่นนะครับ

00:02:03.900 --> 00:02:06.700
จากนั้นก็จะมี Take away แล้วก็ตัว forsacia

00:02:06.700 --> 00:02:11.200
นะครับ ก็หลักๆ แล้วนะครับ เราก็เห็นได้เลยครับว่า

00:02:11.200 --> 00:02:17.900
ตัว inspiration ของผมเนี่ย
ผมได้มาจากตัวเกมนึงของ Google น่ะครับ ที่ชื่อว่า

00:02:17.900 --> 00:02:22.800
Quick Draw
เนาะ ซึ่ง เขาก็จะให้โจทย์มาว่าให้เราวาดอะไร ใช่ไหมครับ

00:02:22.800 --> 00:02:24.700
แล้วทีเนี้ย เวลาเราวาดเนี่ย ตอนละ

00:02:24.700 --> 00:02:29.800

ตอนแรกเราก็จะวาด อาจจะไม่ได้เป็นทรงที่เขาต้องการ ใช่ไหมครับ มันก็ค่อยๆ

00:02:29.800 --> 00:02:39.200
interpret
ไปเรื่อยๆ ว่า เรากำลังวาดอะไรอยู่ จนสุดท้ายเนี่ย พอเราวาดให้มันได้รูปอย่างที่ เขาต้องการเนี่ย มันก็จะ

00:02:39.200 --> 00:02:58.000
interpret
ว่า สมมุติว่าเขาต้องการว่า เขาอยากได้เป็น หมีเนาะ จากนั้นเนี่ย เราวาด แรกๆ เราอาจจะ วาดแล้วไม่ได้เป็นหมีอะครับ แต่ว่า พอผลสุดท้ายเนี่ย พอเราประกอบร่างเสร็จปึ๊บ มันก็กลายเป็นหมีในที่สุดนั่นเองนะครับ

00:02:58.000 --> 00:03:05.000
คราวนี้เนี่ยคำถามคือ แล้วมันเรียนรู้ได้ยังไงว่า มันกลายเป็นหมีในที่สุดได้นะครับ

00:03:05.000 --> 00:03:07.700
ซึ่งจริงๆ แล้วเนี่ย มันมีพวก dataset

00:03:07.700 --> 00:03:13.600
ที่มัน combine together แล้วก็เอาไปเทรนเป็นโมเดลนะครับ ซึ่งตัว dataset

00:03:13.600 --> 00:03:15.800
ที่ว่าเนี่ย มันชื่อว่า Quick, Draw

00:03:15.800 --> 00:03:20.700
Dataset
ก็เอามาจากตัวชื่อของเกมนั่นเองนะครับ ก็ ทาง Google

00:03:20.700 --> 00:03:33.500
Creative
เขาก็ได้ collect พวก Drawing ต่างๆ ที่ผ่านจากการวาดของ แต่ละคนนะครับ แล้วก็เซฟมา แล้วก็เอามาเทรนมาเรื่อยๆ นะครับ

00:03:33.500 --> 00:03:37.400
เดี๋ยวมาดูกันว่า
แต่ละภาพเนี่ย มันเป็นยังไงนะครับ

00:03:37.400 --> 00:03:43.600
ถ้าสมมุติว่าในกรณีที่ โจทย์มันให้มาว่าให้เราวาดเป็นเครื่องบิน ใช่ไหมครับ

00:03:43.600 --> 00:03:51.200
ดังนั้นเนี่ย คนเราเนี่ย หลายล้านคนเนี่ย เขาก็วาดเครื่องบิน มันจะ ไม่ได้แบบเหมือนกันอะครับ

00:03:51.200 --> 00:04:07.500
มันก็วาดต่างกัน บางคน เครื่องบินมันก็ แบบ ปีกมันอาจจะแหลม บางคนวาดปีกอาจจะมน ใช่ไหมครับ มันก็มีการ เก็บข้อมูลไปเรื่อยๆ ครับ แล้วก็กลายเป็นสิ่งที่เรียกว่า

00:04:07.500 --> 00:04:15.100
neural network
นะครับ คราวนี้เนี่ย หลักการทำงานว่า เฮ้ย ทำไมมันถึงดีพีกกันอย่างนี้นะครับ มันเรียกว่าตัว

00:04:15.100 --> 00:04:17.200
convolutional neural network นะครับ

00:04:17.200 --> 00:04:23.300
ก็จริงๆ เอาสั้นๆ ก็คือ CNN
นะครับ ก็มันก็จะเริ่มจาก สิ่งที่เห็นก็คือตัว input

00:04:23.300 --> 00:04:30.800
นะครับ input
เราเป็นรูปภาพที่เราวาดนะครับ หรือว่าเป็นอะไรก็ได้ครับ แล้วก็มาใช้ผ่านตัวสิ่งที่เรียกว่า

00:04:30.800 --> 00:04:36.700
convolution แล้วก็บวกกับ ReLU นะครับ
จากนั้นเนี่ย มันก็ทำการ Pooling กับ ไอ้ภาพ ไอ้

00:04:37.400 --> 00:04:40.800
Big Map ใหญ่ แล้วมันเป็น Big Map
เล็งเนี่ย ตรงเนี้ย everything

00:04:40.800 --> 00:04:45.900
ตรงเนี้ย มันก็ทำเป็นซ้ำๆ แล้วกลายเป็นพิกเซล พิกเซลนะครับ มันก็จะ ใช้สิ่งที่เรียกว่า

00:04:45.900 --> 00:04:52.000
future learning
นั่นเองนะครับ จากนั้นเนี่ย พอมันทำไปเรื่อยๆ เนี่ย มันก็ต้องมา classify ครับ

00:04:52.000 --> 00:04:56.800
แล้ว classify
ไปที่สุดเนี่ย มันก็จะแยกว่า เอ้ย มันเป็น car เป็น truck เป็น

00:04:56.800 --> 00:05:01.500
van หรืออะไรก็แล้วแต่
พอเช็คแต่ละพิกเซลแล้ว พิกเซลแต่ละพิกเซลเนี่ยมัน

00:05:01.500 --> 00:05:04.000
connect กันเนี่ย มันจะได้รู้แล้วก็

00:05:04.000 --> 00:05:14.600
classify
ออกมาว่า อ๋อนี่มันเป็นสิ่งนี้นะ อันนั้นเป็นสิ่งนั้นนะ อะไรประมาณนี้นะครับ คราวนี้เนี่ย ในยุคปัจจุบันเนี่ย เรา อาจจะไม่ต้องเทรนโมเดลครับ

00:05:14.600 --> 00:05:24.200
เพราะว่าเราเห็นได้ว่าตัวของการทำโมเดลเนี่ย มันค่อนข้างที่จะยาก แล้วก็ใช้ทรัพยากรในการเทรนค่อนข้างที่จะเยอะเนาะ

00:05:24.200 --> 00:05:26.600
และยุคนี้ก็จะเป็นยุคที่ generative

00:05:26.600 --> 00:05:31.500
AI ค่อนข้างที่จะมาเยอะมากนะครับ
แล้วก็แน่นอนว่าพวก multimodal

00:05:32.300 --> 00:05:38.500
พวก language model
ที่สามารถที่จะ รับเสียง รับภาพอะไรพวกเนี้ย มันมาเยอะขึ้นนะครับ

00:05:38.500 --> 00:05:43.600
ซึ่งมันมาทั้งในรูปแบบของ compuntary
แล้วก็มาเป็นในรูปแบบของ open source

00:05:43.600 --> 00:05:47.300
แต่ถ้าสมมุติว่าเราเอง เราอยากจะที่จะเล่นแบบ

00:05:47.300 --> 00:05:50.600
local
แบบว่าไม่ต้องใช้อินเทอร์เน็ตอะไรพวกเนี้ยครับ

00:05:50.600 --> 00:05:55.800
เราสามารถที่จะใช้พวก notebook
ของเรา แล้วก็โหลดโมเดลมาจากตัว hacking face หรือว่า Ollama

00:05:55.800 --> 00:06:00.800
นั่นเองนะครับ เดี๋ยวถัดๆ ไปเดี๋ยวก็จะอธิบายว่า ในหลักการของ Ollama

00:06:00.800 --> 00:06:02.900
เนี่ย มันใช้กันยังไงนะครับ

00:06:02.900 --> 00:06:07.700
คราวนี้ ตัวโมเดลที่ผมจะใช้ในวันนี้ก็คือ จะเป็นตัวของ LLaVA นะครับ

00:06:08.200 --> 00:06:11.600
หรือมันย่อมาจาก Large Language
Vision Assistant นะครับ ก็

00:06:12.400 --> 00:06:21.200
base on research ของ Microsoft
นะครับ ก็หลักๆ เนี่ย ก็จะดีพีค หรือว่ารับตัวรูปภาพมาก่อน ใช่ไหมครับ แล้วก็

00:06:21.200 --> 00:06:23.900
project มันก็ใช้พวก

00:06:25.100 --> 00:06:30.000
Feature learning คล้ายๆ กับ CNN
นั่นเองนะครับ แล้วก็ อ่า พอจากนั้นมันก็

00:06:30.000 --> 00:06:34.000
classify ไว้ให้เป็นตัว text
generation ในเบสของ

00:06:34.900 --> 00:06:39.100
language model
นะครับ ซึ่งความฉลาดมันก็ พอๆ กับ

00:06:39.100 --> 00:06:45.300
GPT-4 นะครับ แต่ไม่ได้ถึงขนาด GPT-4o
หรือว่าอาจจะมาถึงแบบยุค

00:06:45.300 --> 00:06:52.700
10103
อะไรประมาณนี้นะครับ แต่ก็เป็นตัวที่เป็น open source นั่นเองนะครับ

00:06:53.400 --> 00:06:55.900
อีกอันนึงก็คือ Ollama ครับ ก็จะเป็น Docker

00:06:55.900 --> 00:07:01.800
ที่เอาไว้รันโมเดลนะครับ คราวนี้เนี่ยไอ้ตัว
Ollama ข้อดีคือมันสามารถรันแบบ

00:07:01.800 --> 00:07:09.600
local
ได้ แล้วก็เราเองเราไม่ต้องใช้อินเทอร์เน็ตในการรันนั่นเองนะครับ มันก็เลยเป็นอะไรที่เรารู้สึกว่า

00:07:09.600 --> 00:07:20.400
custom
ได้ง่าย แล้วก็ เราเองเราไม่ต้องใช้อินเทอร์เน็ต เพราะว่าเราเองเราเจอปัญหาว่าถ้าสมมุติว่าในกรณีที่อินเทอร์เน็ตเนี่ยมันไม่มี หรือว่า

00:07:20.400 --> 00:07:22.400
unstable อะไรพวกนี้ครับ Ollama

00:07:22.400 --> 00:07:28.100
สามารถที่จะช่วยหาคำตอบให้กับพวกเราได้ครับ จริงๆ มันก็จะมีพวก

00:07:28.100 --> 00:07:32.800
indication ต่างๆ ก็จะเป็นแบบว่าเราสามารถ
integrate กับ search engine

00:07:32.800 --> 00:07:37.600
API
อะไรประมาณนี้ แล้วก็สามารถที่จะไปเสิร์ชข้อมูลจากข้างนอกได้นะครับ

00:07:37.600 --> 00:07:45.100
แล้วก็ที่สำคัญก็คือ มันสามารถที่จะ สามารถทำในรูปแบบอื่นๆ ได้ แค่เรามีโมเดล

00:07:45.100 --> 00:07:45.500
generative

00:07:45.500 --> 00:07:45.900
AI

00:07:45.900 --> 00:08:01.600
ภายในเครื่องนั่นเองครับ คราวนี้เนี่ยไซซ์ที่เอามาลงอะครับ คือมันอาจจะไม่ได้มีขนาดใหญ่เป็นแบบ ร้อยพันล้านพารามิเตอร์ หรือเป็นหมื่นพันล้านพารามิเตอร์ ไม่ได้ขนาดนั้นนะ เพราะว่า ไอ้ตัวเครื่องเนี่ยมันค่อนข้างที่จะ

00:08:01.600 --> 00:08:07.000
รับตัวไซซ์ของโมเดลค่อนข้างที่จะน้อยอ่ะครับ
แล้วก็สเปคเราก็ไม่ได้ถึงแบบ super

00:08:07.000 --> 00:08:09.000
computer หรือระดับ server base นะครับ

00:08:10.500 --> 00:08:15.400
ก็ในหลักทำงานจริงๆ
ก็ในอื่นไอ้อาร์คิเทคเจอร์ครับ

00:08:15.400 --> 00:08:23.100
ก็สามารถที่จะแบบว่า เราสามารถโหลดโมเดลผ่านจากตัวของ Hugging Face หรือ Marketplace ของตัวของเราครับ

00:08:23.100 --> 00:08:25.900
แล้วก็ทำการพูลตัวโมเดลออกมานะครับ

00:08:25.900 --> 00:08:29.800
เดี๋ยวผมอาจจะเปิดตัวของมันให้ดูว่ามันเปิดยังไงนะครับ

00:08:29.800 --> 00:08:33.400
แล้วก็สามารถที่จะรันผ่านตัว local machine ได้นะครับ

00:08:34.900 --> 00:08:44.200
คราวนี้เนี่ยมันก็จะทำการเสิร์ฟ ก็คือทำการเปิด Server เพื่อให้แอปพลิเคชันตัวอื่นสามารถจะใช้ได้นะครับ

00:08:44.200 --> 00:08:48.200
แล้วก็ ใช้ผ่าน Client ปกตินะครับ

00:08:49.100 --> 00:08:54.200
คราวนี้เนี่ยหลักการจริงๆ ก็คือพอเราอัปโหลดรูปภาพปุ๊บใช่ไหมครับ

00:08:54.200 --> 00:08:57.900
ก็คือเอารูปภาพแปะในโฟลเดอร์ใช่ไหมครับ แล้วก็รัน Command

00:08:57.900 --> 00:09:02.300
ใช่ไหมครับ แบบว่า ลองถามได้ไหมว่า เออ

00:09:03.800 --> 00:09:11.300
พอเราแปะรูปภาพตรงนี้แล้ว
เราก็ถามว่าใครวาดรูปภาพนี้อะไรประมาณนี้ครับ แล้วก็ไอ้ตัว LLaVA ครับ

00:09:11.300 --> 00:09:16.100
ก็ทำการประมวลผล แล้วก็ Deep Pick มา แล้วก็ Generate เป็นคำตอบออกมานะครับ

00:09:16.100 --> 00:09:24.800
ว่ามันก็เป็นรูปภาพของโมนาลิซ่านะ
แล้วก็วาดด้วย วาดโดย เลโอนาร์โด ดา วินชี อะไรประมาณนี้นะครับ

00:09:25.700 --> 00:09:32.900
แล้วก็ วันนี้สิ่งที่เราจะมาโชว์เนี่ยคือ เราเองอะ

00:09:32.900 --> 00:09:38.900
เราก็พยายามวาดภาพครับ
แล้วก็กดอัปเข้าไปนะครับ แล้วก็ submit

00:09:38.900 --> 00:09:44.700
ไป
แล้วให้ตัว LLaVA ประมวลผล แล้วก็ตอบมาว่ามันเป็นสิ่งนี้นั่นเองนะครับ

00:09:44.700 --> 00:09:51.700
ก็ ประมาณนี้ครับว่า ผมต้องการอย่างนี้ เพราะว่าเราเองเราแบบ

00:09:51.700 --> 00:09:59.100
มันเป็นอะไรที่น่าสนใจ แบบว่าบางทีถ้าเราสมมติว่าเราสร้างเกมๆ หนึ่งมาปุ๊บเนี่ย

00:09:59.100 --> 00:10:01.600
เราเองเราไม่สามารถที่จะ imagine

00:10:01.600 --> 00:10:11.400
ได้ว่าแบบ เฮ้ย เราจะใช้เกมแบบนี้ เราอยากได้สเปคแบบนี้ แต่ว่าเราไม่รู้ว่าไซส์ของเกมอะมันประมาณไหนใช่ไหมครับ

00:10:11.400 --> 00:10:46.500
แต่ว่าไอ้ข้อดีตรงนี้ เราสามารถที่แบบว่า สมมติว่าเราร่างภาพปึ๊บ มันเหมือนเป็นการหาคำตอบว่า อย่างน้อยเนี่ย มันเหมือนมีข้อมูลมันถูกเทรนในตัว Llama มาแล้วอะครับ ว่าภาพที่เราเคยเห็น แต่เราไม่ชัวร์ข้างนอกที่เราเห็นเนี่ยมันคืออะไรนั่นเองนะครับ ก็เดี๋ยวเรามาสู่ในช่วงของเดโม เดี๋ยวเรามาดูตัวโค้ดกันว่า หลักการทำงานในเรียกโฮลของผมที่เก็บไว้อะ มันมีอะไรบ้างนะครับ.

00:10:51.300 --> 00:10:51.600
โอเค

00:10:53.000 --> 00:11:00.000
สักครู่นะครับ.

00:11:01.200 --> 00:11:06.100
ครับ เข้ามาในเรียกโพลครับ
ก็จริงๆ มาดูที่ Index ก่อนเนาะ

00:11:06.100 --> 00:11:08.300
Index เนี่ยจริงๆ ก็จะมี

00:11:08.300 --> 00:11:13.700
ผมเองครับผม
จะเซ็ตว่าเป็น Photo Box ที่เอาไว้วาดภาพนะครับ

00:11:13.700 --> 00:11:23.200
แล้วก็ ไอ้เรื่องของ Front End ตรงนี้ ผมเองก็ทำตรงนี้ไว้นะครับ ก็มันก็จะมีประมาณนี้นะครับ

00:11:23.200 --> 00:11:29.400
เดี๋ยวอย่างนี้เดี๋ยวเราจะไปดูว่าไอ้หลักการทำงานข้างในเนี่ย ใน Source Code เนี่ยมันมีอะไรบ้างนะครับ

00:11:30.000 --> 00:11:38.100
สมมติใน index.js นะครับ
ก็เราเองเราก็จะทำกับ โอ้ ตัวเล็กมากเลย.

00:11:39.900 --> 00:11:50.500
ครับ
ก็ เราเองเราก็จริงๆ เนี่ย มันจะมีตัว Import ตัว P5 มานะครับ แล้วก็ Generate ตัว Ollama นะครับ ก็หลักๆ ก็จะเป็นอย่างนี้เนาะ

00:11:50.500 --> 00:12:01.600
จากนั้นเนี่ยเราก็จะเห็นเลยครับว่า Provider ที่เราเซ็ตเนี่ย เราเซ็ตทั้งจากที่เป็นของ อ่าตัว

00:12:01.600 --> 00:12:04.700
set
เนี่ย ก็จะมีทั้งเป็นตัวของ Ollama แล้วก็ OpenAI

00:12:04.700 --> 00:12:07.600
สำหรับใครที่อยากจะใช้ตัว GPT-4o นะครับ

00:12:08.200 --> 00:12:24.400
ก็ ผมก็เซ็ตพร้อมไว้นะครับ เป็น Constant ไปเลย เป็น Selection ไปว่า Get What This Image Is อะไรประมาณนี้ครับ แล้วก็ มีเซ็ตว่า ใครวาดภาพนี้ หรืออะไรพวกนี้ หรือว่าเราจะทำอะไรต่อกับมันนะครับ

00:12:25.200 --> 00:12:32.900
แล้วก็ Sketch อะไรพวกนี้ก็แล้วแต่ครับ ก็จะเป็นการเซ็ตตัวของ Canvas อ่ะครับ

00:12:32.900 --> 00:12:39.500
ว่า เราก็จะทำเป็น Color Picker แล้วก็เราก็เซ็ตไอ้ตัว Generating เป็น false นะครับ

00:12:39.500 --> 00:12:50.500
แล้วก็ เซ็ต Path Color เอ่อ Path Color ตรงนี้ครับ หรือ Brush Size ตรงนี้ มันจะเป็นค่า Constant เริ่มต้นเวลาเราเปิดโปรแกรมนะครับ

00:12:50.500 --> 00:12:56.000
แล้วก็มันก็เซ็ตเป็น Back แล้วก็
ไซต์อยู่ที่ 20 นั่นเองครับ

00:12:56.000 --> 00:13:04.700
พอมาถึง Canvas นะครับ ก็เราเซ็ตว่า Width ก็ประมาณ 600 High ก็ประมาณ 600 นั่นเองนะครับ

00:13:04.700 --> 00:13:20.100
เราเองเราทำเป็น 2D ครับ
แล้วก็ จากนั้นเนี่ยตัวของ Setup นะครับ ก็คือ พร้อม ก็คือ Select ตัวพร้อมที่เราให้ไว้ใช่ไหมครับ จากนั้นเนี่ยตัวพร้อมมันก็ส่งไปที่ตัว Provider นั่นเองครับ

00:13:20.100 --> 00:13:29.500
จากนั้นเนี่ยไอ้ตัว Provider ตรงนี้ครับ พวกพร้อม Receive จากนั้นเนี่ยมันจะไปทำงานในฝั่งของ Generate.js นั่นเองนะครับ

00:13:29.500 --> 00:13:39.500
ซึ่ง เราก็นั่นแหละครับ ก็เป็นหลักการประมาณนี้ แล้วก็ถ้ามีปัญหามันมีปัญหาปุ๊บเนี่ย มันก็ต้องขึ้นว่า

00:13:39.500 --> 00:13:41.000
Error อะไรประมาณนี้ครับ

00:13:41.700 --> 00:13:49.600
ก็ หลักๆ ตัวโค้ดก็จะ มีประมาณนี้ครับ
แล้วก็มีการเซ็ตตัว Mouse Track อะไรประมาณนี้นะครับ

00:13:49.600 --> 00:13:54.000
ก็เพื่อให้ตัวของ Canvas มันใช้ได้ง่ายขึ้นนะครับ

00:13:55.400 --> 00:14:01.800
คราวนี้มาฝั่งของ Generate ครับ
ผมเองผมใช้อิมพอร์ตตัว Ollama ที่มันเป็นตัว Local นะครับ

00:14:01.800 --> 00:14:12.600
แล้วก็ตัว OpenAI นะครับ
คราวนี้เนี่ย ไอ้ตัวฝั่งของ Generation ของ OpenAI แล้วก็ จริงๆ อะ เราเองเราสามารถที่จะใช้แบบ OpenAI เพียวๆ ไปเลยก็ได้ครับ

00:14:12.600 --> 00:14:26.000
แต่ว่าเราเองเราค่อนข้างที่จะ ใช้ ใช้ Ollama เพียวไปด้วยนะครับ เพราะว่า หลังๆ มาเนี่ย เราสามารถที่จะใช้ตัว OpenAI API เนี่ย ในการใช้ตัวของ Ollama ได้นะครับ

00:14:26.000 --> 00:14:31.500
คราวนี้เนี่ย ในตัวของ Generate OpenAI เองเนี่ย เราก็เลยเซ็ตเลยครับว่า

00:14:31.500 --> 00:14:41.500
Provider เป็น OpenAI แล้วก็ เป็น OpenAI ตรงนี้เราใส่ Question อักทิ้งไว้ เพราะว่าเราเองเราไม่ได้ใช้ครับ

00:14:41.500 --> 00:14:51.100
แล้วก็อีกอันนึงก็จะเป็นตัวของ Local Code เอ่อ 11434 ขีด V1 เอ้ย จริงๆ 11434 อันนี้เตรียม Trivia นะครับ

00:14:51.100 --> 00:14:53.800
จริงๆ อะ มันย่อมาจาก Llama นะครับ

00:14:53.800 --> 00:14:58.600
Llama ก็คือ LLM
อะไรประมาณนั้นนะครับ

00:14:58.600 --> 00:15:01.300
อันนี้ อันนี้ผมก็เพิ่งรู้เหมือนกันนะฮะ

00:15:01.300 --> 00:15:12.700
(หัวเราะ)
แล้วก็ อ่า เราก็เซ็ตเป็น Client-side compression ปกติครับ ว่าพอเราได้ เอ่อ พอตัว User ปุ๊บ เรารับตัวอีเมลแล้วก็พร้อมเป็น Text ก็ประมาณนั้นนะครับ

00:15:12.700 --> 00:15:28.400
แล้วก็ตรงนี้ พอตรงของ Generate ของตัว Ollama เองนะครับ ก็เรา Select โมเดลเป็น Lava นะครับก็ตามนั้นนะครับ แล้วก็สมมุติว่าในกรณีที่เราจะ อืม เซ็ตพวก เอ่อ Learning rate อะไรพวกนี้ ประมาณนี้ครับ

00:15:28.400 --> 00:15:32.900
พวก Number of prediction หรือ Temperature ก็สามารถเซ็ตตรงนี้ได้นะครับ

00:15:32.900 --> 00:15:38.800
อืม คราวนี้มาดูในฝั่งของ Ollama กันนะครับ
ก็ Ollama เนี่ย มันก็จะเป็นประมาณนี้

00:15:40.300 --> 00:15:42.200
ผมเอง ผมเปิดที่ตัว Terminal ก่อน

00:15:43.700 --> 00:15:44.100
มา!

00:15:45.000 --> 00:15:49.900
เข้าไปเทิร์นที่ Terminal ครับ
แล้วก็จากนั้นเรารันกับสิ่งที่เรียกว่า Ollama ครับ

00:15:50.800 --> 00:15:51.000
ปึ๊บ

00:15:52.100 --> 00:16:02.000
Ollama มันก็จะมีหลายๆ Command ใช่ไหมครับ
แล้วเราก็สามารถที่จะลิสต์โมเดลได้นะครับ อุปส์.

00:16:04.200 --> 00:16:06.100
แล้วก็ทำการลิสต์ออกมาครับ

00:16:06.100 --> 00:16:09.800
นั่นเองนะครับ ก็ผมเอง ผมได้ทำการโหลดตัว

00:16:09.800 --> 00:16:13.300
Lava เรียบร้อยครับ ว่ามีไซซ์อยู่ประมาณ
4.7 GB นะครับ

00:16:14.100 --> 00:16:29.600
คราวนี้เนี่ย เวลาผมเดโมปุ๊บเนี่ย ผมก็จะทำการ
npm นะครับ (เสียงเคาะโต๊ะ)

00:16:33.700 --> 00:16:37.300
โอเค จากนั้นเนี่ย เราก็คลิกเข้าไปครับ

00:16:38.200 --> 00:16:38.700
โอเค

00:16:39.200 --> 00:16:43.400
คราวนี้มันก็ได้มาเป็นตัว Canvas มาแล้วนะครับ

00:16:43.400 --> 00:16:49.100
คราวนี้เนี่ย เราสมมติว่าเราลองวาดอะไรสักอย่าง
เช่น ปึ๊บ ปึ๊บ ปึ๊บ ปึ๊บ ปึ๊บ

00:16:49.900 --> 00:16:50.900
ปึ๊บ ปึ๊บ ปึ๊บ ปึ๊บ

00:16:51.700 --> 00:16:57.600
ผมเอง
ผมก็วาดไม่ค่อยดีแต่ลอง Ask ดูครับว่ามันมีอะไรนะครับ

00:16:58.300 --> 00:17:05.000
ก็ให้ลองทายว่าเราลองวาดอะไรใช่ไหมครับ
จากนั้นเนี่ยมันก็รอประมวลผลอยู่ข้างในเครื่องอะครับ

00:17:11.000 --> 00:17:14.500
อะ มันสามารถดีพิกว่าอันนี้เป็นบ้านนะครับ

00:17:14.500 --> 00:17:16.900
จริง ๆ เราสามารถที่จะเลือกได้เลยครับว่า

00:17:16.900 --> 00:17:32.500
เราจะถามอะไรกับมันนะครับ
แล้วก็ถ้าเราอยากจะเปลี่ยนคำถามก็สามารถที่ไปเปลี่ยนตรงไอ้ index.js ได้นะครับ ก็สามารถเปลี่ยน Prompt ตรงนี้ได้นะครับ

00:17:32.500 --> 00:17:44.400
ก็ อืม ประมาณนี้ แล้วก็สามารถที่จะเปลี่ยนสี
มีใครอยากจะลองเล่นไหมครับ (หัวเราะ) ระวัง ระวัง

00:17:44.400 --> 00:17:48.500
เฮ้ย เล่นแบบดี ๆ ไม่แกล้ง ไม่แกล้ง
อะ เล่นยังไงครับ

00:17:48.500 --> 00:17:50.600
ก็ เอ่อ จริง ๆ ก็

00:17:50.600 --> 00:17:51.700
ให้มันเซ็นใหม่ก่อนเนาะ

00:17:51.700 --> 00:17:52.900
ให้เคลียร์ก่อน

00:17:52.900 --> 00:17:53.400
อ้าา

00:17:53.400 --> 00:17:56.900
แล้วก็เราสามารถที่จะเลือก คำถามกันได้

00:17:56.900 --> 00:18:00.700
อ้า Name a painter
Who could be the creator of this artwork?

00:18:01.400 --> 00:18:07.700
เอ่อ ไอ้...นึก Painter อันนึงได้ แต่ว่าไม่
ไม่ค่อยเหมาะกับสถานที่ตรงนี้เท่าไหร่ (หัวเราะ)

00:18:07.700 --> 00:18:14.000
เปลี่ยนกัน Guess what this image is
เออ วาดอะไรดี

00:18:16.500 --> 00:18:18.200
แล้วก็มีรถถัง มันวาดยังไงวะ

00:18:20.400 --> 00:18:23.700
รถถัง... อะ ปืนก็ได้.

00:18:26.700 --> 00:18:29.000
แล้วก็มีธงชาติ

00:18:29.000 --> 00:18:30.000
เปลี่ยนสีได้นะฮะ

00:18:30.000 --> 00:18:30.400
เฮ้ย

00:18:32.400 --> 00:18:33.300
สีแดง

00:18:36.000 --> 00:18:39.300
สีขาวแล้วก็สีน้ำเงิน

00:18:44.300 --> 00:18:45.600
แล้วก็ยังไงฮะ

00:18:45.600 --> 00:18:47.400
แล้วก็กด Ask ครับ

00:18:48.400 --> 00:18:50.500
อันนี้จะ จะเพิ่มมือด้วยไหมฮะ

00:18:50.500 --> 00:18:51.500
ได้ฮะ

00:18:51.500 --> 00:18:52.800
โอเค โอ๊ย โอ๊ย โอ๊ย โอ๊ย โอ๊ย

00:18:52.800 --> 00:18:55.500
มือมา Ask เลย

00:18:55.500 --> 00:18:58.000
เดี๋ยวเปลี่ยนเป็นปืนใหญ่

00:19:00.700 --> 00:19:01.000
อะไร

00:19:01.000 --> 00:19:03.500
อะไร อันนี้มันปกติธรรมชาติไงคนดี คนดี

00:19:03.500 --> 00:19:05.800
อะ ลอง Ask ดูครับ

00:19:05.800 --> 00:19:06.400
เฮ้ย

00:19:06.400 --> 00:19:10.300
(หัวเราะ)

00:19:10.300 --> 00:19:17.900
ครับ ก็มันก็จะรอประมวลผล อ่า
ในเครื่องรักชาติครับ รักชาติ

00:19:17.900 --> 00:19:23.800
(ปรบมือ)

00:19:23.800 --> 00:19:27.300
ซึ่งไอ้ตัวโมเดลของไอ้ Microsoft Lava เองเนี่ย

00:19:27.300 --> 00:19:32.700
มันเองมันก็ดีพิกพยายามที่แบบเซฟความเป็น Safety ของมันอยู่

00:19:32.700 --> 00:19:35.100
มัน มันก็ใช้ตัว Responsible AI อยู่ด้วย

00:19:35.100 --> 00:19:39.600
ก็มันเองมันอะ มันก็เลยแบบไม่รู้ว่าเรากำลังถือปืนอยู่อะ (หัวเราะ)

00:19:40.400 --> 00:19:52.900
แต่ แต่ว่าถ้าสมมติว่า อะ ผมลองเคลียร์ดู อ่า ลอง
ลองวาดอะไรที่มันดาร์ก ๆ อย่างเช่น

00:19:57.800 --> 00:19:58.700
อะ ลองดู

00:19:59.900 --> 00:20:02.900
อ้า กด Ask

00:20:05.400 --> 00:20:17.300
อ้า มัน อย่างน้อยมันรู้ว่านี่มัน Toy กัน
ถ้าแบบ Machine gun จริง ๆ โดน

00:20:20.500 --> 00:20:27.800
(หัวเราะ) นึกว่าไปแล้ว

00:20:28.600 --> 00:20:31.100
(หัวเราะ) โอเคครับ ก็เออประมาณนี้นะครับ

00:20:31.100 --> 00:20:39.000
ก็เออสำหรับใครที่สนใจก็สามารถที่จะสแกน QR Code แล้วก็เอาไปลองเล่นได้นะครับ

00:20:39.000 --> 00:20:44.000
ก็ตอนแรกของเราเองเราก็ไม่รู้ว่าเอ๊ะเราจะทำอะไรดีกับ Small Language Model เนาะ

00:20:44.000 --> 00:20:46.500
แต่ว่าพอมันเป็น Multi-modal ปุ๊บมันก็

00:20:46.500 --> 00:20:54.200
เออมันน่าสนใจดีว่า เออเราสามารถลองที่จะวาดรูปแล้วก็ต่อ แล้วก็มาลองถ่ายภาพกันได้นะครับ ก็

00:20:55.000 --> 00:20:58.300
อื้ม ประมาณนี้ครับ แล้วก็มี Key Takeaway ว่า

00:20:58.900 --> 00:21:05.800
เอ่อ
สิ่งที่ได้มาจากตรงนี้คือเราเองเราได้ความเป็น Multi-modal Model

00:21:05.800 --> 00:21:11.300
แล้วก็ Creativity เนี่ย
เราสามารถที่จะ Bring Possibilities ต่าง ๆ ในการทำอะไรต่าง ๆ

00:21:11.300 --> 00:21:16.400
มากขึ้นนะครับ แล้วก็จริงๆ
แล้วเนี่ยตัว Multi-modal Model

00:21:16.400 --> 00:21:20.500
เนี่ยสามารถที่จะจริง ๆ
สามารถช่วยหลาย ๆ อย่างได้นะครับ

00:21:20.500 --> 00:21:24.600
แล้วก็จริงๆ
เนี่ยเราเห็นแบบ Use case พวก Project Astra ของ Google

00:21:24.600 --> 00:21:31.200
เองก็สามารถที่จะช่วยคนพิการได้นะครับ
แล้วก็ในเรื่องของ Perception และ Creativity เนี่ย

00:21:31.200 --> 00:21:35.300
เราเองเรารับรู้ในสิ่งต่าง ๆ
ที่เกิดขึ้นในรอบตัวเรา

00:21:35.300 --> 00:21:39.700
แล้วเราก็สามารถที่จะจินตนาการต่อไปได้นะครับ ฉะนั้นเนี่ย

00:21:39.700 --> 00:21:43.300
สุดท้ายเนี่ย เราเองเราลองเอา Creativity แล้วบวกกับ

00:21:43.300 --> 00:21:47.400
AI
แล้วก็บวกกับความมั่นยั่งยืนก็คือตัว Sustainability เนี่ย

00:21:47.400 --> 00:21:49.900
มันก็จะกลายเป็น Small Language Model ในที่สุด

00:21:49.900 --> 00:21:57.400
เพราะว่าคือในยุคที่ AI
เนี่ยมันมีบทบาทกับชีวิตของพวกเรามากขึ้นเนี่ย

00:21:57.400 --> 00:22:03.600
มันเองมันก็เป็นตัวช่วยของเราได้มากยิ่งขึ้นนั่นเองครับ แล้วก็เราเองเรารู้สึกว่า

00:22:03.600 --> 00:22:09.400
ณ
วันนี้เราอาจจะไม่ต้องเบสออน ChatGPT หรือว่าเราไม่ได้เบสแบบตัวใหญ่ๆ

00:22:09.400 --> 00:22:18.600
นะครับ
เราเองเรารู้สึกว่าตัวที่มันเป็นตัว Small เองมันก็มี possibility ที่สามารถที่จะ create อะไรกับมันก็ได้เช่นเดียวกันนะครับ

00:22:18.600 --> 00:22:21.900
ก็จริงๆ แล้วเนี่ยไอ้ตัวข้อมูลพวกเนี้ย

00:22:21.900 --> 00:22:26.200
ไอ้ตัว Sustainability กับเรื่องของ Small Language Model เนี่ย เราสามารถที่จะ

00:22:27.400 --> 00:22:29.700
สามารถต่อยอดอะไรต่อไปก็ได้ครับ แล้วก็

00:22:30.200 --> 00:22:33.800
เอ่อ
ตัวผมเองก็จะเอามาต่อยอดเรื่องราวต่อไปเนี่ย

00:22:33.800 --> 00:22:39.100
เดี๋ยวผมก็จะมาแชร์ในพาร์ทของงาน Force Asia ในวันที่ 14 อ่า

00:22:39.100 --> 00:22:42.800
มีนาคม ก็เป็นวันศุกร์นั่นเองครับ
ก็สามารถที่จะ

00:22:42.800 --> 00:22:46.400
เข้าไปจอยเซสชันนี้ใน Force Asia ได้นั่นเองครับ

00:22:46.400 --> 00:22:53.000
แล้วก็ทั้งหมดเป็นเซสชันของผมในวันนี้ครับ
แล้วก็ขอบคุณทุกๆ คนมากๆ เลยครับ ขอบคุณครับ

00:22:53.000 --> 00:22:55.800
(ปรบมือ)
