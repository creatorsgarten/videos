import { anthropic } from '@ai-sdk/anthropic'
import { google } from '@ai-sdk/google'
import { generateObject } from 'ai'
import 'dotenv/config'
import fs from 'fs'
import subtitle from 'subtitle'
import yargs from 'yargs'
import { z } from 'zod'
import { serializeVtt } from '../serializeVtt'

const argv = await yargs(process.argv.slice(2))
  .strict()
  .help()
  .option('subtitlePath', {
    describe: 'Path to the subtitle file (.vtt)',
    type: 'string',
    demandOption: true,
  })
  .option('skip', {
    describe: 'Skip first N segments',
    type: 'number',
    default: 0,
  })
  .option('limit', {
    describe: 'Limit processing to N segments (to save on tokens)',
    type: 'number',
    default: undefined,
  })
  .parse()

const subtitlePath = argv.subtitlePath
if (!subtitlePath) {
  throw new Error('Subtitle path is required')
}

if (!fs.existsSync(subtitlePath)) {
  throw new Error(`Subtitle file not found: ${subtitlePath}`)
}

// Parse VTT file to JSON
function vttToJsonObject(vtt: string) {
  const parsed = subtitle.parseSync(vtt)
  const cues = parsed.filter((x) => x.type === 'cue').map((x) => x.data)
  const cueToIds = new Map<subtitle.Cue, string[]>()
  let nextId = 1

  const segments = []
  for (const cue of cues) {
    const start = cue.start / 1000
    const text = cue.text
    if (!text.trim()) {
      continue
    }
    const lines = text.split('\n').map((x) => x.trim())
    const ids: string[] = []
    for (const line of lines) {
      const id = `${nextId++}`
      segments.push({ id, text: line })
      ids.push(id)
    }
    cueToIds.set(cue, ids)
  }

  return { segments, cueToIds, parsed }
}

// Initialize Anthropic client
if (!process.env.ANTHROPIC_API_KEY) {
  throw new Error('ANTHROPIC_API_KEY environment variable is required')
}

const modelProvider: string = 'google'
const model =
  modelProvider === 'google'
    ? google('gemini-2.0-flash-exp')
    : anthropic('claude-3-7-sonnet-20250219')

// Define Zod schema for subtitle segments
const SegmentSchema = z.object({
  id: z.string(),
  text: z.string(),
})

const SegmentsSchema = z.object({
  segments: z.array(SegmentSchema),
})

async function improveSubtitles(segments: z.infer<typeof SegmentSchema>[]) {
  console.log(`Processing ${segments.length} subtitle segments...`)

  const improvedSegments = await generateObject({
    model: model,
    schema: SegmentsSchema,
    prompt: `I need your help to improve subtitle text quality. 

The original transcript was generated by an automatic speech recognition system, which has some issues:
1. Words are often misspelled
2. Numbers are written as words instead of digits (e.g. "twenty three" should be "23")
3. Technical terms may be incorrectly transcribed
4. Punctuation may be missing or incorrect
5. Sentence fragments may be unclear

Please correct these issues while maintaining the original meaning. Keep proper names and technical terms intact.

Examples of improvements (key is the original text, value is the improved text):
${JSON.stringify({
  โอรามะ: 'Ollama',
  หนึ่งร้อยยี่สิบสาม: '123',
  โอเพ่นเอไอ: 'OpenAI',
  'gpt four o': 'GPT-4o',
  'แอล แอล เอ็ม': 'LLM',
  สองจุดห้า: '2.5',
  เพอร์ฟอร์แมนซ์: 'Perfomance',
})}

Words that are transliterated from English should be corrected to the original English word and NOT translated to Thai. For example, "ฟรีดอม" should be "freedom" and NOT "เสรีภาพ".
However, some loan words that are very commonly used in Thai language can be left as is, such as "โมเดล" or "ลิงก์", unless it is part of a proper name.

Sometimes, the speaker will say "um" or "uh" as a filler word. These should be removed from the text.

Important rules:
- Return exactly ${segments.length} segments in the same order
- Each segment must have the same 'id' as the original
- Do not merge or split segments
- Do not omit any segments
- Preserve technical terminology but fix misspellings

Original subtitle segments:
${JSON.stringify({ segments }, null, 2)}

Please return the improved segments with the same structure. Each segment should have the same 'id' but with improved 'text' content.`,
    temperature: 0.2,
    maxTokens: 8000,
  })
  console.log(improvedSegments.usage)

  return improvedSegments.object
}

// Main execution
const vttContent = fs.readFileSync(subtitlePath, 'utf-8')
const { segments: allSegments, cueToIds, parsed } = vttToJsonObject(vttContent)
console.log(`Found ${allSegments.length} subtitle segments`)

// Apply skip and limit if specified
const skippedSegments = argv.skip ? allSegments.slice(argv.skip) : allSegments
const segments = argv.limit
  ? skippedSegments.slice(0, argv.limit)
  : skippedSegments
if (argv.skip) {
  console.log(`Skipped first ${argv.skip} segments`)
}
if (argv.limit) {
  console.log(`Limited to ${argv.limit} segments`)
}

// Process segments through an LLM
const improvedSegments = await improveSubtitles(segments)
console.log('Improved subtitle segments:')
console.log(JSON.stringify(improvedSegments, null, 2))

// Reconstruct VTT file with improved segments
const idToOriginalSegments = new Map(
  allSegments.map((segment) => [segment.id, segment]),
)
const idToImprovedSegment = new Map(
  improvedSegments.segments.map((segment) => [segment.id, segment]),
)
const result = serializeVtt(
  parsed.flatMap((node): subtitle.Cue[] => {
    if (node.type !== 'cue') return []
    const cue = node.data
    const ids = cueToIds.get(cue)
    if (!ids) return [cue]
    return [
      {
        ...cue,
        text: ids
          .map(
            (id) =>
              idToImprovedSegment.get(id)?.text ??
              idToOriginalSegments.get(id)?.text,
          )
          .join('\n'),
      },
    ]
  }),
)
fs.writeFileSync(subtitlePath, result)
